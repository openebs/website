[{"id":1,"title":"Repeatable OpenEBS Mayastor deployments and benchmarks","author":"OPENEBS","author_info":"No author information","date":"22-03-2021","tags":["tutorials","openebs"],"content":"\n## Introduction\n\nOpenEBS is one of the most popular Storage-related projects in CNCF, and the newest addition to OpenEBS - Mayastor, is a missing piece that has been absent from the Kubernetes stack for a long time - Kubernetes-native, high performance, distributed Software Defined Storage or what is increasingly called Container Attached Storage (CAS).\n\nAs the lead developers of OpenEBS Mayastor, we want to be sure our message of an extremely high performing CAS is not only exciting, but also honest and easy to check. We want every interested user to be able to quickly and easily bring OpenEBS Mayastor up, properly tuned and ready for testing with whatever workload the user prefers to try.\n\nIn order to deliver on that promise, we have started a [“Demo Playground” project, open sourced on Github](https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground).  Contributions and feedback are welcome.\n\n\n## OpenEBS\n\nOpenEBS is a project with multiple storage engines, with each engine providing the user with different feature sets as well as different usage and performance characteristics. The currently available options can roughly be split into two categories:\n\n* LocalPV: Excellent for workloads that deal with storage resilience at the application level, creating and managing their own replicas and capable of sustaining the loss of a single or multiple nodes, such as  Cassandra, and requiring very good storage performance, especially latency-wise.\n* Replicated storage  (cStor, Jiva) - for workloads that are less performance-sensitive and some of the more advanced storage features such as synchronous data replication, snapshots, clones, thin provisioning of data, high resiliency of data, data consistency, and on-demand increase of capacity or performance.\n\nAdvanced features come at the cost of higher latency and lower performance, and yet, technology keeps advancing and trying to get the best of both worlds.\n\n\n## OpenEBS Mayastor\n\nOpenEBS Mayastor delivers on the promise of exciting new technology, utilizing NVMe (not just the disks, but the protocol and standards), NVMEoF, SPDK and io_uring. NVMes inside our servers deliver amazing speeds and latencies, huge numbers of IOPS, and using old SCSI or FC protocols only waste resources introducing overheads. Harnessing SPDK and NVMEoF OpenEBS Mayastor achieves speeds that are close to in-host NVMes, without compromising on workload mobility, resilience, flexibility, and enterprise features.\n\nStill, all this exciting tech needs some proper care before it behaves as it should, and we still have a ways to go before it autotunes and autoconfigures itself just right with the help of Kubernetes and workload operators; and yet, as a user willing to take Mayastor for a spin, there should be no reason to wait, if the tuning and preparation can be automated now.\n\n\n## Introducing: the Automation Playground\n\nThe Automation Playground provides an easy onramp for trying out OpenEBS Mayastor in a cloud or self-hosted environment and attempts to keep the installation process correct, standardized, and consistently reproducible, yet both simple and flexible.\n\nThe Playground utilizes popular and familiar software in order to apply the desired state configuration, as well as following a familiar Jenkins-pipeline-like approach.\n\nThe entire process is split into stages, with each stage extensible, replaceable and skippable, if need be, and each stage is called from a simple bash script, where each step is a function, easily copied into a CI engine as a pipeline stage.\n\nThe user experience is as simple as editing a single variables file in order to define the benchmark setup variables and running up.sh. The script will then iterate over the predefined stages, relying on the outcomes of each stage to run the next one\n\nVariables are used to define such things as the setup name (prefixed in all the provisioned resources), user access credentials, Kubernetes installation types, provisioning details, and of course, OpenEBS Mayastor tuning as well as the benchmark itself. For more details, please see the vars file at https://github.com/mayadata-io/deployment-automation-playground/blob/main/demo-playground/vars\n\n\n## Stages\n\nEach software lifecycle consists of several stages - provisioning, deployment, operations, and teardown.\n\nSince we are flexible here, each stage can be skipped if it isn’t required in a given setup.\n\nWhen running a benchmark on a set of self-hosted bare metal machines, the provisioning stage is not needed.\n\nIf Kubernetes is already installed, the Kubernetes installation stage can be skipped.\n\nWhen running the Demo Playground on a host that has direct access to the machines executing the benchmark, the VPN stage can be skipped.\n\nThe only truly essential stages are node preparation and the actual OpenEBS Mayastor workload playbooks that will be installed.\n\n\n#### Stage 1: Provisioning\n\nAt this step, we use Terraform to create a separate environment for the benchmark. Currently, the supported provisioning options are Azure and AWS EC2, with GCP support not too far behind. As a reminder, contributions (and feedback) are welcome.\n\nTerraform is used to create a separate VPC (in EC2) or Resource Group (in Azure), where networking is configured, and VMs are provisioned as per the definitions in the vars file.\n\nThe nodes provisioned are of three varieties\n\n* Master nodes (for Kubernetes Masters)\n* Worker nodes (Kubernetes workers that will be running the workload - make sure these are powerful enough and include fast networking if you want to be able to stress Mayastor)\n* Storage nodes (Kubernetes workers that will be running Mayastor). These instances should have fast local NVMe disks, which means LXs_v2 on Azure, m5d/m5ad/m5dn/i3 on AWS or n1/n2_standard with added Local-SSDs on GCP.\n\nWhen provisioning is complete, an Ansible inventory file is generated by Terraform, to be used in later stages. The inventory contains all the node IPs split into groups and adjusted for the various Kubernetes installers in use.\n\nIf the provisioning stage is skipped, the user must provide the inventory.ini file in the workspace directory, with the file containing the [mayastor_clients] (non-storage workers) and [mayastor_storage] (storage nodes) groups.\n\n#### Stage 2: Start VPN\n\nThis is a small stage, only required when the host executing Demo Playground is not inside the same subnet as the cluster nodes. The stage starts sshuttle after creating a script in the workspace directory. Sshuttle is described as a “poor man’s VPN” - an easy to use package that will tunnel all traffic for a given subnet through an SSH tunnel to a Bastion host.\n\nDuring provisioning, the first Kubernetes Master host has designated the Bastion and will be used for this purpose, effectively working as a VPN concentrator for the Demo Playground setup, placing the executor host in the same subnet as the Kubernetes nodes.\n\n#### Stage 3: Kubernetes setup\n\nAt this step, the Playground will deploy a pre-configured version of Kubernetes on the hosts as described in the inventory. If Provisioning was skipped, this means that the inventory file will have to be expanded with groups that are pertinent to the Kubernetes deployment in use; otherwise, the inventory generated in the Provisioning stage will contain all the required groups.\n\nCurrently two installation types are supported with more planned:\n\n* Kubespray - a well known Ansible based feature rich Kubernetes installer\n* K3S - a simplified and downsized Kubernetes distribution, which can be perfect for a small demo setup. This is also installed via Ansible.\n\nAt the end of the step, the script will extract the KUBECONFIG credentials file from a Master node and place it under workspace/admin.conf. If this stage is skipped, the user will have to extract and add this file manually.\n\n#### Stage 4: Node preparation\n\nIn order to run OpenEBS Mayastor as well as other OpenEBS storage engines, some prerequisites need to be applied to the Kubernetes workers, both the storage and client nodes.\n\nThis includes making sure the iSCSI and NVMeo-TCP client packages are present, installing and enabling the various Linux kernel modules, enabling hugepages, and so on. Some of these settings might require a host restart.\n\nThe stage is implemented as an Ansible playbook, which allows it to reach into the hosts directly in order to prepare them, performing some actions a Kubernetes pod has limited access to.\n\nAt this point, we should have a working Kubernetes setup, with the different worker nodes prepared for using Mayastor either as storage hosts or storage clients.\n\n## Playbooks\n\nActually, the proper stages end at Node Preparation, and then the playbooks take over.  The vars file contains a PLAYBOOKS variable, which lists all the playbooks the Playground will apply in sequence.\n\nCurrently, there is one playbook relevant to testing Mayastor - mayastor.yml\n\nBut the script will attempt to run any playbooks mentioned from the deployments directory one after another.\n\nThe Mayastor playbook follows the Mayastor installation instructions, creating the Kubernetes manifests and applying them to the setup, so that all the relevant Mayastor pods, DaemonSets, StorageClasses, Pools etc. are created in the Mayastor namespace, PVCs are created and ready to be used by the user’s workload.\n\nThe Mayastor playbook also contains an optional FIO test, which will create an FIO pod using the first created PVC and run a quick 1-minute benchmark.\n\n## Conclusion\n\nThe Demo Playground project is still in very early stages, and we invite everyone to use, contribute and expand upon it. The goal here is to give the user interested in giving OpenEBS Mayastor a try, a ready tool that does the job in an open, honest, consistent, and reproducible manner.\n\nThe project’s flexibility allows for anyone to add in additional playbooks, which will deploy and run different workloads on top of Mayastor, and we intend to expand upon it, adding some workloads of our own beyond the basic FIO benchmark.\n\nPlease visit us at https://mayadata.io and give the Demo Playground a spin at https://github.com/mayadata-io/deployment-automation-playground/tree/main/demo-playground.\n\nYou can also find my colleagues and me spending time on the Kubernetes #OpenEBS slack, or at a [Discord room](https://discord.com/invite/zsFfszM8J2) set up to focus mostly on open source collaboration with Mayastor developers (Rusticians may be especially interested), and on the Data on Kubernetes community where a huge variety of users of Kubernetes for data are sharing their perspectives (https://dok.community/.","slug":"repeatable-openebs-mayastor-deployments-and-benchmarks"},{"id":2,"title":"How are TikTok, Flipkart, KubeSphere, and others using OpenEBS for Local Volumes","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"12-03-2021","tags":["solutions","tutorials","chaosengineering"],"content":"\n**How to select the right local volume for your workloads?**\n\nWe have recently seen a massive increase in the usage of different flavors of OpenEBS Local PV. We estimate by looking at container pulls for underlying components combined with some call home data for those users of OpenEBS that enable the capturing of metrics that the weekly new deployments of OpenEBS for LocalPV increased by nearly 10x during 2020. This can be attributed to the fact that more and more cloud native Stateful applications are moving into Kubernetes\n\n![kg-image](https://admin.mayadata.io/content/images/2021/03/Local-PV-Deployment.PNG)\n\nSome of the prominent users of OpenEBS Local PV include the CNCF, Optoro, ByteDance / TikTok, Flipkart, and many more. You can always read more about OpenEBS users on the OpenEBS.io website and on the GitHub project page here: https://github.com/openebs/openebs/blob/master/ADOPTERS.md.\n\nWhile Kubernetes provides native support or interfaces for consuming Local Volumes, the adoption of OpenEBS for LocalPV management suggests that some capabilities are missing that are desired by users. At a high level, dynamic provisioning and the simplicity of deleting Local Volumes are two reasons often given for the preference of some users for the use of OpenEBS LocalPV.\n\nIn this blog, I outline the various types of Local Storage that users have in their Kubernetes clusters and introduce the various flavors of OpenEBS Local PV being used.\n\nBefore getting into the flavors of OpenEBS Local PV, it might be worthwhile to know what Kubernetes offers or means by a Local Volume.\n\n*A [Kubernetes Local Volume](https://kubernetes.io/docs/concepts/storage/volumes/#local) implies that storage is available only from a single node. A local volume represents a mounted local storage device such as a disk, partition, or directory.*\n\nSo, it stands to reason - as the Local Volume is accessible only from a single node, local volumes are subject to the availability of the underlying node. If the node becomes unhealthy, then the local volume will also become inaccessible, and a Pod using it will not be able to run.\n\nHence, Stateful Applications using local volumes must be able to tolerate this reduced availability, as well as potential data loss, depending on the durability characteristics of the underlying disk.\n\nAs it happens, many of the Cloud Native Workloads - are distributed in nature and are typically deployed as StatefulSets with multiple replicas. These can sustain the failure or reduced availability of a single replica. MinIO, Redis, PostgreSQL, Kafka, Cassandra, Elastic are just some examples that are deployed using Local Volumes. For these applications - performance and consistent low latency, and ease of management are more important than the resiliency of a node to failures.\n\nAs the large SaaS provider, [Optoro](https://github.com/openebs/openebs/blob/master/adopters/optoro/README.md) puts it:\n*The vast majority of applications are able to better handle failover and replication than a block level device. Instead of introducing another distributed system into an already complex environment, OpenEBS's localPVs allow us to leverage fast local storage. … OpenEBS has allowed us to not introduce a complicated distributed system into our platform. The adoption has been smooth and completely transparent to our end users.*\n\n## Limitations of Kubernetes LocalPV\n\nKubernetes expects users to make Persistent Volumes (PVs) available that it can then associate with PVCs during scheduling. Kubernetes does not help with dynamically creating these PVs as the applications are launched into the cluster.\n\nThis pre-provisioning can become an issue when companies have more than two people or teams managing the Kubernetes clusters, and the Application teams depend on the Kubernetes cluster administrators for provisioning the Volumes.\n\nWe have seen that cluster administrators are challenged by the following aspects:\n\n(a) The type of storage available on the Kubernetes nodes varies depending on how the Kubernetes nodes are provisioned. Available storage types include:\n\n* Nodes have only OS disks with large space that can be used for provisioning Local Volumes.\n* Nodes have one or two additional devices (SSDs or Disks) attached that can be used for provisioning Local Volumes.\n* Nodes have 8 to 16 high-performing NVMe SSDs.\n\n(b) And then, there is a matter of capacity available from the Local Storage and how to manage this to enable the freedom of developers and other consumers of capacity while retaining a level of oversight and assistance by centralized teams:\n\n(c) First, the platform or other centralized team may not know exactly what the capacity a particular team or workload needs - and the developer or data scientist may not know either. Dynamic provisioning within quotas means that users can keep moving without opening a ticket or having a conversation.\n\n(d) Secondly, there are many common operations tasks that need to be performed. Just because the applications are resilient does not mean these tasks entirely disappear. Administrators still would like to safeguard the data with best practices from years of experience in dealing with data such as:\n\n* Enforcing Capacity Limits/Thresholds\n* Securing the Volumes\n* Carving out the Local Volumes from well known or familiar file systems like LVM, ZFS, XFS, and so forth\n* Encrypting the Volumes\n* Enforce compliance with BCP by taking regular snapshots and full backups\n\nThis is where Kubernetes itself stops, and plugins like OpenEBS LocalPV options step into the auto-magically provision and manage the Local Volumes.\n\n## Selecting your LocalPV\n\nOpenEBS provides different types of Local Volumes that can be used to provide locally mounted storage to Kubernetes stateful workloads. The choice of the OpenEBS Local Volume depends on the type of local storage available on the node and the features required.\n\n* OpenEBS Hostpath Local PV - The use of the host path is the simplest, most used, and lowest overhead solution. This approach creates Local PVs by creating a sub-directory per Persistent Volume. This offers flexibility to create different classes of storage and allows administrators to decide into which parent or mounted directory the Persistent Volumes sub-directories should be placed. For example - a storage class for critical workloads vs. non-critical transient workloads, SSD vs. Hard Disk mounted paths, and so forth.\n* OpenEBS Raw file Local PV - The OpenEBS Raw file approach evolved out of the Hostpath approach due to considerable feedback from some OpenEBS community members. Raw file Local PV offers all the benefits of Hostpath Local PV - and in addition, Hostpath supports enforcing Capacity Quotas on Volume subdirectories by creating sparse files per volume.\n* OpenEBS Device Local PV - Device Local PV is best suited for cases where either a complete device or a partitioned device needs to be dedicated to the pod. Workloads like Cassandra or Kafka that need high throughput and low latency often use dedicated device Local PV.\n* OpenEBS ZFS and LVM Local PV - Both ZFS and LVM are selected by seasoned storage administrators that want to leverage all the good things of well-known filesystems or volume management along with the power of Local Volumes. This category offers features like full/incremental snapshots, encryption, thin-provisioning, resiliency against local disk failures by using software raid/mirror, and so forth. Incidentally, you can easily cause a fairly reasoned argument by asking users and community members, and even our own engineers to share their opinions about whether ZFS or LVM is more useful; I'm very happy that the community has progressed to the point that both solutions are now supported and widely deployed.\n\nI hope this overview of LocalPV options and OpenEBS Local has been useful. I plan to follow this with further blogs that get into the details of each flavor of the OpenEBS Local PV.\n\nIn the meantime, you can get started easily with [OpenEBS Local PV](https://docs.openebs.io/docs/next/overview.html), and the community is always available on the Kubernetes Slack #openebs channel.\n\nOr read more on what our OpenEBS users and partners have to say about Local PV. From our friends at 2nd Quadrant (now part of EDB): [Local Persistent Volumes and PostgreSQL usage in Kubernetes](https://www.2ndquadrant.com/en/blog/local-persistent-volumes-and-postgresql-usage-in-kubernetes/)\n\nAnd from one of the most broadly deployed Kubernetes distributions, Kubesphere: [OpenEBS Local PV is default Storage Class in Kubesphere](https://github.com/openebs/openebs/tree/master/adopters/kubesphere)\n\nOr, again, you can find more stories and can add your own to Adopters.MD on the OpenEBS GitHub: https://github.com/openebs/openebs/blob/master/ADOPTERS.md","slug":"how-are-tiktok-flipkart-kubesphere-and-others-using-openebs-for-local-volumes"},{"id":3,"title":"OpenEBS NDM, go-to solution for managing Kubernetes Local Storage","author":"Akhil Mohan","author_info":"Software Engineer @ MayaData, working on Cloud Native Tech.","date":"13-01-2021","tags":["openebs"],"content":"\nEver since Local Volumes have become generally available (GA) in Kubernetes 1.14, the use of Local Volumes has skyrocketed. This can be attributed to the nature of cloud-native workloads distributed in nature and can sustain node failures. The bare metal underpinning Kubernetes clusters, both on-prem and cloud, can now be configured with local storage to manage stateful workloads. Kubernetes doesn’t treat storage like a native resource on par with CPU or Memory, making it a little difficult to make Kubernetes work out of the box to create effective node-attached storage. OpenEBS NDM helps alleviate this gap by discovering the different storage types attached to each worker node and then creating Kubernetes resources called block devices.\n\nApplication or storage operators can then use the information exposed via block devices to determine how to orchestrate the workloads best.\n\nOpenEBS NDM (Node Device Manager) has been declared GA after being deployed in production for several months as part of the OpenEBS control plane. With the release of version 1.0, NDM adds out-of-the-box support for partitions, LVMs, LUKS encrypted devices, in addition to the unique identification of virtual disks within the cluster. Now offering support for partitions, a single disk can be partitioned. Each partition will be considered a separate block device used by different storage engines like cStor / local PV. NDM also tracks the movement of the devices within a cluster across the nodes.\n\n## Key Storage Problems solved by NDM\n\n* Local Storage Discovery - detecting partitions, devices used as a LUKS device or LVM device, or if it can be accessed as a raw block device.\n* Cluster-wide storage visibility\n* Detect the movement of storage devices across nodes\n* Book-keeping/storage asset management  - allocating/reserving, which type of storage should be provided to which workloads.\n\n## Getting Started with NDM\n\nLet us see how NDM helps detect the block devices in the cluster with 3 nodes, each having a completely different disk configuration. The Disk configuration of the nodes are as follows:\n\nMaster: 2 virtual disks\n\nWorker1: 3 virtual disks, one being used by LUKS and two other disks which are partitioned, several partitions are being used as PV's by the LVM.\n\nWorker 2: 4 physical disks\n\n* Deploy NDM into the Kubernetes cluster along with OpenEBS LocalPV\n\n```kubectl apply -f https://openebs.github.io/charts/openebs-operator-lite.yaml```\n\n(The latest helm charts for deploying NDM are available [here](https://openebs.github.io/node-disk-manager/))\n\n* Once deployed, check the blockdevices present in the cluster using\n\n```kubectl get bd -n openebs -o wide```\n\nSome block devices show partitions that did not exist initially. E.g., sdb1 instead of sdb. This is because NDM creates a partition on virtual disks to identify the disk uniquely. Also, block device resources are now created for LVMs and LUKS encrypted devices. All the block devices listed above will now be treated as individual devices and can be used by any storage engine.\n\n* Deploy a sample application to use the block device\n\nDownload the minio yaml and apply it. (NOTE: A node selector has been added to the minio application pod so that it gets scheduled on worker-1)\n\nkubectl apply -f [minio-official.yaml](https://gist.githubusercontent.com/akhilerm/194a1606c514d8930addcaef56f9f19f/raw/7d339e5042b4e5e958dde558f1f3509e26c214f3/minio-official.yaml)\n\nNow check the status of block devices again\n\nWe can see that the device `dm-2`, is the LUKS device, has been claimed and used by the application.\n\n* Pool movement across nodes\n\nNDM helps in seamlessly moving cStor pools from one node to another. Whenever the devices that constitute a pool are moved from one node to another (disconnecting disks from one node and reconnecting on another), the block device resource is updated with the latest information. NDM tracks this movement. cStor can use this information to migrate pools as required.\n\n* Reserving storage for workloads\n\nNDM provides a feature to reserve devices for certain workloads. E.g., Users can reserve all SSDs for a performance intensive workload. This reservation is achieved using block-device-tags. More information on using block-device-tags with LocalPV can be found [here](https://docs.openebs.io/docs/next/uglocalpv-device.html#optional-block-device-tagging).\n\n## Future Roadmap\n\n* Southbound provisioning\n* Metrics (currently in alpha)\n* API Service to interact with NDM\n* Ability to create partitions or LVM volume groups - preparing storage in general.\n\n## Interested in Contributing to NDM?\n\nNDM is an OpenEBS project, which itself is a CNCF sandbox project. [OpenEBS on GitHub](https://github.com/openebs/node-disk-manager) is a great place to join if you want to contribute to our codebase. You can also interact with us on the OpenEBS channel in [Kubernetes Slack](https://kubernetes.slack.com/?redir=%2Fmessages%2Fopenebs%2F).","slug":"openebs-ndm-goto-solution-for-managing-kubernetes-local-storage"},{"id":4,"title":"Storage is Evolving!","author":"Nick Connolly","author_info":"Nick is the Chief Scientist at MayaData and a pioneer of storage virtualization, holding patents ranging from highly-scalable algorithms through to data protection techniques.","date":"11-12-2020","tags":["openebs"],"content":"\nBefore the turn of the century, storage systems were typically controlled by dedicated firmware running on custom hardware. These proprietary systems were time-consuming to design, expensive to build, and resistant to innovation.\n\nIn 1998, Software Defined Storage was pioneered by DataCore Software with its SANsymphony suite of products, based on the realization that general-purpose computers had become fast enough to handle the demands of a high-performance storage stack. For context, this was an era when a system with more than two cores was a rarity and both memory and storage were measured in MBs! The primary protocol in use in the enterprise was SCSI, whether directly connected or accessed through a Fibre Channel network, response times were measured in the tens of milliseconds, and accessing storage over Ethernet using iSCSI was only just starting to be worked on.\n\n## The hardware environment is changing!\n\nIn the last few years, the hardware environment has changed significantly. Instead of the relentless drive for ever-increasing clock speeds, systems with over a hundred cores are now mainstream. Developing highly-performant algorithms that operate at this scale of parallelism is a complex and time-consuming process that, generally speaking, is uneconomic to pursue.  Storage media has also undergone a transformation, with SSDs based on flash memory delivering orders of magnitude better performance than spinning disks. Their response time, which can be measured in microseconds, has highlighted the inefficiencies of the decades-old SCSI protocol.\n\nNVMe is a ‘state of the art’ storage protocol for a new era. Designed from the ground up for maximum parallelism and lock-free operation, it offers up to 64k independent I/O queues each with 64k entries and a simplified command set. Connected over PCIe, it delivers low latency and high bandwidth data directly to an application, enabling it to fully utilize the capabilities of the underlying flash memory. NVMe over Fabrics (NVMe-oF) provides network access to remote storage and targets less than 10 microseconds in additional latency.\n\n## Application development is changing!\n\nRather than building the large monolithic codebases that were the norm at the turn of the century, modern development practices are based around composable architectures; containerized microservices that scale dynamically to meet performance requirements. For more background on this trend, see my [earlier post](https://www.datacore.com/blog/5-changes-that-are-reshaping-software-development/) and the excellent articles in [MayaData’s blog](https://blog.mayadata.io/). Kubernetes is rapidly becoming the control plane for the enterprise.\n\n## A New Era\n\nA new era requires a new kind of storage stack! A stack that is based around today’s technologies rather than being anchored to the last century. A stack that is portable and flexible. A stack that supports rapid innovation. That delivers the performance that applications require.\n\n## Container Attached Storage\n\nThe new category of [Container Attached Storage](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/), of which OpenEBS is the de-facto open source standard, orchestrates the storage stack with the same flexibility as the application.  Implemented as a microservices based architecture, it runs within Kubernetes and gives users the freedom to define the way that they want to access, protect, and manage their data. The days of the dedicated storage administrator are coming to an end!\n\nFor Mayastor, the latest storage engine to be added to OpenEBS, flexibility, and performance are achieved by basing the stack around the [Storage Platform Development Kit (SPDK)](https://spdk.io/), which provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications. Based on the NVMe protocol, it delivers blistering performance from today’s hardware as well as being ready for the next generation of Intel Optane based SSDs that are just becoming available. For more details, see some [recent results](https://openebs.io/blog/mayastor-nvme-of-tcp-performance/).\n\n## Microsoft Windows\n\nHowever, amid all the discussions about flexibility and portability, there is one small footnote that often goes unnoticed: ‘not supported on Windows’. It’s understandable, because most of the projects that are shaping this new era have their roots on Linux or FreeBSD, but it overlooks the sheer scale of Windows Server deployments in enterprise environments. Things are changing, with significant investments being made in Kubernetes on Windows, but it’s a slow process; one project at a time!\n\nMayaData’s mission is to enable data agility - so we were uncomfortable with our high-performance Container Attached Storage solution, OpenEBS Mayastor, not being available on Windows platforms. With that in mind, we have created the [Windows Platform Development Kit (WPDK)](https://github.com/wpdk/wpdk) to act as a foundational layer to make it easier to port the SPDK to Windows. In addition, we are working with the SPDK community to make a few changes to the code base to support this.  It is a testament to the quality of the excellent SPDK project that so few changes have been required so far.\n\nThe project also benefits from the work done by the DPDK on Windows community who has invested a significant amount of time porting the underlying [Data Plane Development Kit (DPDK)](https://www.dpdk.org/), a Linux Foundation project that consists of libraries to accelerate packet processing workloads running on a wide variety of CPU architectures.\n\n## Windows Platform Development Kit\n\nThe MayaData developed and contributed Windows Platform Development Kit has currently reached ‘alpha’. Most of the required functionality is believed to be present, unit tested, and working correctly, but there are still areas that need further development.\n\nIt is possible to build the SPDK tree, run the associated unit tests, serve an iSCSI target on Windows, and mount it as a volume.\n\nIt is anticipated that this collaboration will deliver the following benefits to Windows users:\n\n1. Enable high-performance access to NVMe storage directly from applications.\n2. Native software defined storage stacks, including OpenEBS Mayastor.\n3. Support for NVMe-oF adaptors from manufacturers such as Mellanox and Broadcom.\n\nThe Windows Platform Development Kit is open source, under a BSD-3 clause license.  Community contributions are welcomed and needed! To get started please head to https://wpdk.github.io or access the WPDK code and documentation on [GitHub](https://github.com/wpdk/wpdk).","slug":"storage-is-evolving"},{"id":5,"title":"OpenEBS on DigitalOcean Marketplace","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"3-12-2020","tags":["openebs","chaosengineering","tutorials"],"content":"\nDeploying OpenEBS on DigitalOcean can directly be done from the console. DigitalOcean provides the feature to create a cluster with OpenEBS deployed on it already. To get started, follow the below-mentioned steps:\n\nWORKFLOW:\n\nSTEP 1: Getting started\nLogin to your [DigitalOcean](https://cloud.digitalocean.com/login) account.\n\nSTEP 2: Creation of cluster\nOnce you log in, you arrive at the dashboard, click on Marketplace under DISCOVER located on the left sidebar.\n\nNext, scroll down to find OpenEBS. On clicking, you will be redirected to a page where you will find the details about OpenEBS and the Create OpenEBS button on the right side.\n\nNext, you need to provide the necessary details such as Data Center region, cluster capacity, cluster name, etc. (It is advisable to provision 3 nodes with 4vCPUs and 8 GB memory to ensure that the resources are sufficient at all times.)\n\nSTEP 3: Connecting your cluster\nCreation, resizing, and deletion can be carried out from UI, but you require command-line tools from your local machine or a remote management server to perform administrative tasks. The detailed steps to install the management tools and connect the cluster to your local machine can be found under the Overview section.\n\nTo verify, execute the following command:\n\n```$ kubectl get ns```\n\nOutput:\n```\nNAME     STATUS    AGE\ndefault  Active    13m\nopenebs  Active    13m\n```\nThe output must contain openebs ns in an Active state.\n\nNext, execute:\n\n```$ kubectl get pods -n openebs```\n\nOutput:\n```\nNAME                                                 READY     STATUS    RESTARTS AGE\nopenebs-admission-server-5c4d545647-r4vgr            1/1       Running   0        13m\nopenebs-apiserver-56f77c9965-xft68                   1/1       Running   2        13m\nopenebs-localpv-provisioner-64c67b5b89-czv8b         1/1       Running   0        13m\nopenebs-ndm-5f6nt                                    1/1       Running   0        13m\nopenebs-ndm-74njq                                    1/1       Running   0        13m\nopenebs-ndm-operator-7bc769dcff-b45bc                1/1       Running   1        13m\nopenebs-ndm-spttv                                    1/1       Running   0        13m\nopenebs-provisioner-755f465f9d-fr67l                 1/1       Running   0        13m\nopenebs-snapshot-operator-7988fc8646-zpd98           2/2       Running   0        13m\n```\nAll the pods must be in a running state.\n\nSTEP 4: Attaching BlockDevices\nTo attach BlockDevices to the created nodes, click on Volumes on the left sidebar and then click on the Add Volume button.\n\nNext, select the volume size ( provision at least 30 GB), select the node(droplet) to which it gets attached and provides a name, then click on the Create Volume button. Repeat these steps for each node (droplet).\n\nNOTE:\n\n*For cStor, choose Manually Mount and Format under Choose Configuration Options.*\n\n*For Jiva, choose Automatically Format and Mount under Choose Configuration Options.*\n\n*After the BlockDevices get attached for all the nodes, you can see an output similar to the below image.*\n\nNext, you have to provision OpenEBS volumes.  Click [here](https://docs.openebs.io/docs/next/ugcstor.html#provisioning-a-cStor-volume) to know more.","slug":"openebs-on-digitalocean-marketplace"},{"id":6,"title":"Atlassian Jira Deployment on OpenEBS","author":"Abhishek","author_info":"Abhishek is a Customer Success Engineer at Mayadata. He is currently working with Kubernetes and Docker.","date":"20-11-2020","tags":["openebs"],"content":"\n**Jira** Software is part of a family of products designed to help teams of all types manage work. Originally, **Jira** was designed as a bug and issue tracker. But today, Jira has evolved into a powerful work management tool for all kinds of use cases, from requirements and test case management to agile software development.\n\n## Requirements\n\n#### Install OpenEBS\n\nIf OpenEBS is not installed in your K8s cluster, this can be done from [here](https://docs.openebs.io/docs/next/installation.html). If OpenEBS is already installed, go to the next step.\n\n#### Configure cStor Pool\n\nIf cStor Pool is not configured in your OpenEBS cluster, this can be done from [here](https://docs.openebs.io/docs/next/ugcstor.html#creating-cStor-storage-pools). Sample YAML named **openebs-config.yaml** for configuring cStor Pool is provided:\n\n```\n#Use the following YAMLs to create a cStor Storage Pool.\n# and associated storage class.\napiVersion: openebs.io/v1alpha1\nkind: StoragePoolClaim\nmetadata:\n  name: cstor-disk\nspec:\n  name: cstor-disk\n  type: disk\n  poolSpec:\n    poolType: striped\n  # NOTE - Appropriate disks need to be fetched using `kubectl get blockdevices -n openebs`\n  #\n  # `Block devices` is a custom resource supported by OpenEBS with `node-disk-manager`\n  # as the disk operator\n# Replace the following with actual disk CRs from your cluster `kubectl get blockdevices -n openebs`\n# Uncomment the below lines after updating the actual disk names.\n  blockDevices:\n    blockDeviceList:\n# Replace the following with actual disk CRs from your cluster from `kubectl get blockdevices -n openebs`\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n#   - blockdevice-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n---\n```\n\n#### Create Storage Class\n\nYou must configure a StorageClass to provision cStor volume on the cStor pool. In this solution, we are using a StorageClass to consume the cStor Pool, which is created using external disks attached to the Nodes. Since Jira is a deployment application, it requires three replications at the storage level. So cStor volume replicaCount is 3. Sample YAML named **openebs-sc-disk.yaml** to consume cStor pool with cStor volume replica count as 3 is provided:\n\n```\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: openebs-cstor-disk\n  annotations:\n    openebs.io/cas-type: cstor\n    cas.openebs.io/config: |\n      - name: StoragePoolClaim\n        value: \"cstor-disk\"\n      - name: ReplicaCount\n        value: \"3\"       \nprovisioner: openebs.io/provisioner-iscsi\nreclaimPolicy: Delete\n```\n\n### Deployment of Jira\n\nSample Jira Yaml:\n\n```\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: jira\n      name: jira\n    spec:\n      containers:\n        - name: jira\n          image: \"doriftoshoes/jira:7.3.6\"\n          resources:\n            requests:\n              cpu: \"2\"\n              memory: \"2G\"\n          volumeMounts:\n            - name: \"jira-home\"\n              mountPath: /opt/jira-home\n      volumes:\n        - name: jira-home\n          persistentVolumeClaim:\n            claimName: demo-vol1-claim\n---\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: jira\n  name: jira\nspec:\n  ports:\n    - port: 8080\n      targetPort: 8080\n  selector:\n    app: jira\n  type: LoadBalancer\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: demo-vol1-claim\nspec:\n  storageClassName: openebs-cstor-disk\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10G\n```\n\nNext, apply both the **Jira deployment** and service to your Kubernetes cluster.\n\n```kubectl apply -f jira.yaml```\n\n#### Verify Jira Pods:\n\n#### Run the following to get the status of Jira pods:\n\n```kubectl get pods```\n\nFollowing is an example output:\n\n```\nNAME                    READY   STATUS    RESTARTS   AGE\njira-5xxxxxxxx-2xxxx    1/1     Running   0          1d12h\n```\n\nThat's it for today's blog. Thanks for reading. Please leave your questions or feedback, if any, in the comment section below.","slug":"atlassian-jira-deployment-on-openebs"},{"id":7,"title":"Provisioning Google Cloud with k8s using it’s in-house tool, KOPS","author":"Harshvardhan Karn","author_info":"Harshvardhan Karn works at MayaData Inc. He is a public speaker, has talked in few local meetups and at two major conferences. In his free time, he likes to play Guitar, Netflix.","date":"14-08-2018","tags":["Docker","Kubernetes","Openebs","Kops"],"content":"\nI am very excited for this post, as I have been working on this content for a few weeks. I might sound naive throughout this, mainly because I am, to be honest. Setting up and using a cluster in _GCP_ offers a few significant advantages over using _GKE_. For instance, using GCP gives the user the liberty to use their _custom binaries_ or a _pure Open Source Kubernetes_. Also, _GKE_ does not support modification or access to the master node, whereas a manually setup-ed k8s cluster over _VMs_ does.\n\nTo gain the full understanding of Kubernetes, some people like to get their hands dirty for a course of interval. Luckily, we have a few more tools to get a Kubernetes cluster up and running in VM instances of **Google Cloud**. I find that tools like _kubernetes-incubator/kubespray , crosscloudci/cross-cloud_ and kops, are not very straightforward to use, but _kops, kubespray_ is somewhat close. _Cross-cloud_ on the other hand, has poor documentation and is not very stable. _kops_ here stands for ‘_Kubernetes Operations._’ To be honest, I find this to be a good tool to deploy the Cluster over Google Cloud Platform (**GCP**) or Amazon Web Services (**AWS**). I certainly would not say it is the best, but this tool is documented to the extent that one can use it. The original idea of KOPS was to create user a production ready cluster in **AWS. **Allowing it to provision the GCP is luxury since GCP already provides with GKE and AWS does not.\n\n### **Requirements**\n\nThese items are required to deploy the production-ready k8s cluster in GCP:\n\n- **KOPS**\n\n  wget -O kops\n  https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '\"' -f 4)/kops-linux-amd64\n\n  chmod +x ./kops\n\n  sudo mv ./kops /usr/local/bin/\n\n- **GCloud**\n\n[https://cloud.google.com/sdk/](https://cloud.google.com/sdk/)\n\nOnce you are done installing GCloud SDK, you must run _gcloud init_. This will configure your gcloud with your existing GCP project.\n\n- **kubectl**\n\nFrom the [official kubernetes kubectl release:](https://kubernetes.io/docs/tasks/tools/install-kubectl/)\n\n    wget -O kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl\n    chmod +x ./kubectl\n    sudo mv ./kubectl /usr/local/bin/kubectl\n\n- A little patience …\n\n## Let’s Begin!\n\nA quick note: every time you create a cluster, it also creates a _Virtual Private Cloud _(**VPC**), per se. Google Cloud allows you to create only a maximum of 5 VPC’s in one project, and a total of only 5 clusters. So, to resolve this problem, we can create a **VPC **explicitly and use it as a common Network for the rest of the clusters.\n\n### Create a VPC\n\nHere I am using subnet-mode as auto, and it will create a VPC *openebs-e2e *with a subnet in every zone.\n\n    gcloud compute networks create openebs-e2e --project=openebs-ci --subnet-mode=auto\n\n### Create a Bucket\n\nKops needs a State Store to hold the configuration of our cluster. In our case, it is Google Cloud Storage Buckets. So, let’s create one empty Bucket using the following:\n\n    gsutil mb gs://openebs-dev/\n\nNow, since we are ready with the Bucket, we can populate it with our cluster’s State Store, i.e. Cluster object and InstanceGroup object.\n\n**Create the Cluster & InstanceGroup Objects in Our State Store**\n\n_kops create cluster_, creates the Cluster object and InstanceGroup object. Here, we’ll be working within kops.\n\n    PROJECT=`gcloud config get-value project`\n    export KOPS_FEATURE_FLAGS=AlphaAllowGCE # to unlock the GCE features\n    kops create cluster openebs-dev.k8s.local --zones us-central1-a\n    --state gs://openebs-dev/ --project=${PROJECT}\n    --kubernetes-version=1.11.1 --node-count 3\n\nNow we can list the Cluster objects in our kops State Store (the GCS bucket we created):\n\n    kops get cluster --state gs://openebs-dev/\n    NAME                     CLOUD        ZONES\n    openebs-dev.k8s.local    gce          us-central1-a\n\n**NB: **It is not necessary to use the same name for the Bucket and Cluster; you are free to use whatever name you wish.\n\n### Create a Cluster\n\nWe are now ready with all of the changes and the cluster configuration, so we will proceed with the creation of the cluster. _kops create cluster_ created the Cluster object and the InstanceGroup object in our State Store, but it did not actually create any instances or other cloud objects in GCE. To do that, we’ll use _kops update cluster_.\n\n_kops update cluster_ without _--yes_ will show us a preview of changes that will be made. It comes handy in case we want to see or verify the specs before creation.\n\n    kops update cluster openebs-dev.k8s.local --state gs://openebs-dev/ --yes\n\nCheers!\n\nWe have now deployed the Kubernetes cluster on GCP. If you go to the *Compute Engine *in *Google Cloud Platform, *you will find 4 new nodes, where 1 is the master and the rest are worker nodes. Just to save your day, if you are wondering why you could not find your nascent cluster inside _Google Kubernetes Engine_, this is not a mistake or error because it is not a GKE Cluster. All GzCP knows is that there are 4 VMs running in the project, which we know is a K8s cluster.\n\n## Out-of-the-Box\n\nWe are now ready with the cluster, but is it ready for the deployments? Once the kops is finished creating the cluster, we can validate its readiness using the following:\n\n    kops validate cluster --state gs://openebs-dev/\n\n\n    I0808 12:34:10.238009   25907 gce_cloud.go:273] Scanning zones: [us-central1-c us-central1-a us-central1-f us-central1-b]\n    INSTANCE GROUPS\n    NAME                 ROLE   MACHINETYPE    MIN MAX SUBNETS\n    master-us-central1-a Master n1-standard-1  1   1   us-central1\n    nodes                Node   n1-standard-2  3   3   us-central1\n    NODE STATUS\n    NAME                       ROLE   READY\n    master-us-central1-a-067f  master True\n    nodes-6rt6                 node   True\n    nodes-lvs5                 node   True\n    nodes-wbb8                 node   True\n    Your cluster openebs-dev.k8s.local is ready\n\nIf you find that the cluster not ready, wait for a few minutes as it takes some time to configure the cluster. You can even check using _kubectl_ from your control machine:\n\n     kubectl get nodes\n\nYou will see the node counts once your Cluster is up, viz. _kubelets_ are configured. If you are wondering how you got your _kubectl_ configured to this cluster, _kops_ does that for you. It exports a kubecfg file for a cluster from the state store to your _~/.kube/config_ local machine where you are running _kops_. If you want to export this config to some other path, you can the following:\n\n     kops export kubecfg openebs-dev.k8s.local\n\nI wrote an Ansible playbook for [Litmus](https://github.com/openebs/litmus/), which is actually a wrapper for all of these to bring up the cluster on GCP. You can check it out here:\n\n[https://github.com/openebs/litmus/tree/master/k8s/gcp/k8s-installer](https://github.com/openebs/litmus/tree/master/k8s/gcp/k8s-installer)\n\nThe playbook also checks the cluster availability implicitly using a python script. This will hold the playbook from termination until the cluster is ready to use. _kops validate_ works well, but **not** for **k8s version < 1.9, **up to the day of writing this post.\n\nGodspeed!\n","slug":"provisioning-google-cloud-with-k8s-using-its-inhouse-tool-kops"},{"id":8,"title":"Setting up WordPress and SQL with OpenEBS","author":"Ashish Ranjan","author_info":"An enthusiastic person when it comes to software & computers. I don't mind getting out of my comfort zone when things related to computing need to be done at the spur of the moment.","date":"14-08-2018","tags":["Openebs","Kubernetes","Cloud-Native-Storage","Open-Source","State-Department"],"content":"\n[Wordpress](https://en.wikipedia.org/wiki/WordPress) is a well-known blogging platform. New bloggers are often surprised when they find out how easy it is to get set up and start their first piece in this popular tool. In this blog, we will show how to deploy WordPress and MySQL on OpenEBS in their Kubernetes cluster.\n\n## What is OpenEBS?\n\nOpenEBS offers containerized persistent block storage using Docker containers. Those blocks are often referred to as Virtual Storage Machines (similar to K8s pods). OpenEBS seamlessly provides scalable storage volumes and manages them effortlessly. For more information, you can visit [https://openebs.io/join-our-slack-community](https://openebs.io/join-our-slack-community?__hstc=216392137.b7acacf689e0cc4579eea008f86d0c72.1579857743065.1579857743065.1579857743065.1&__hssc=216392137.1.1579857743066&__hsfp=3765904294).\n\n### Prerequisites:\n\n- A k8s cluster with at least one minion.\n- Basic knowledge of writing services, deployment in k8s.\n- Kubectl, already configured.\n- A code editor for writing a yamls.\n- Brains.\n\nLet’s get started!\n\n## Setting up OpenEBS\n\nBefore starting with WordPress, we need to set up OpenEBS. For this article, I will be using OpenEBS v0.6 (you are free to use newer versions if you wish).\n\nWhen setting up OpenEBS, you need to apply the following yamls:\n\n    kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/v0.6/k8s/openebs-operator.yaml\n    kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/v0.6/k8s/openebs-storageclasses.yaml\n\nThe first yaml is for the openebs-operator, and the second one is for openebs-storage-classes. For more information look [here](https://docs.openebs.io/?__hstc=216392137.b7acacf689e0cc4579eea008f86d0c72.1579857743065.1579857743065.1579857743065.1&__hssc=216392137.1.1579857743066&__hsfp=3765904294). After applying the above yamls, the output of kubectl get pods — all-namespaces will look like this:\n\n    $ kubectl get pods --all-namespaces\n    NAMESPACE NAME READY STATUS RESTARTS AGE\n    kube-system event-exporter-v0.2.1-5f5b89fcc8-bhv7r 2/2 Running 0 16m\n    kube-system fluentd-gcp-scaler-7c5db745fc-tb2zw 1/1 Running 0 16m\n    kube-system fluentd-gcp-v3.0.0-wqgzx 2/2 Running 0 14m\n    kube-system heapster-v1.5.3-77c6fcd568-q8txc 3/3 Running 0 15m\n    kube-system kube-dns-788979dc8f-4lgsf 4/4 Running 0 16m\n    kube-system kube-dns-autoscaler-79b4b844b9-jldbr 1/1 Running 0 16m\n    kube-system kube-proxy-gke-ashish-ranjan-default-pool-b3a38b91-cv5d 1/1 Running 0 16m\n    kube-system l7-default-backend-5d5b9874d5-hvrgb 1/1 Running 0 16m\n    kube-system metrics-server-v0.2.1-7486f5bd67-hls82 2/2 Running 0 15m\n    openebs maya-apiserver-68c98fdb76-vbslv 1/1 Running 0 1m\n    openebs openebs-provisioner-5569654c96-hmhb5 1/1 Running 0 1m\n    openebs openebs-snapshot-operator-5f7c4d9bd8-7fnfv 2/2 Running 0 1m\n\nWait until all openebs namespaced pods move into a running state. Once this is completed, we’ll start by creating a secret for sql.\n\n## Creating a Secret\n\n    kubectl create secret generic mysql-pass --from-literal=password=w0rdPres5\n\nRun the above kubectl command to create a mysql password.\n\n## Wordpress Deployment\n\nNow, let's start writing the WordPress deployment yaml. Copy and save the above into a Wordpress.yaml file and execute a kubectl apply on it. Once this is done, the output of kubectl get pods,svc,pvc — all-namespaces will look similar to this:\n\n    $ kubectl get pods,svc,pvc --all-namespaces\n    NAMESPACE NAME READY STATUS RESTARTS AGE\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-766678794-jtltg 2/2 Running 0 2m\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-2pkt4 1/1 Running 0 2m\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-htdxh 1/1 Running 0 2m\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-rdtlk 1/1 Running 0 2m\n    default pod/wordpress-7bdfd5557c-5b4nh 1/1 Running 2 2m\n    kube-system pod/event-exporter-v0.2.1-5f5b89fcc8-wprbm 2/2 Running 0 8m\n    kube-system pod/fluentd-gcp-scaler-7c5db745fc-s9mp9 1/1 Running 0 8m\n    kube-system pod/fluentd-gcp-v3.0.0-49vq6 2/2 Running 0 5m\n    kube-system pod/fluentd-gcp-v3.0.0-kfjsx 2/2 Running 0 5m\n    kube-system pod/fluentd-gcp-v3.0.0-tg5hh 2/2 Running 0 5m\n    kube-system pod/heapster-v1.5.3-76f7f5f544-z7xk9 3/3 Running 0 6m\n    kube-system pod/kube-dns-788979dc8f-2chf4 4/4 Running 0 8m\n    kube-system pod/kube-dns-788979dc8f-ls4ln 4/4 Running 0 7m\n    kube-system pod/kube-dns-autoscaler-79b4b844b9-8745z 1/1 Running 0 8m\n    kube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8866 1/1 Running 0 7m\n    kube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8fh5 1/1 Running 0 7m\n    kube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-9jjf 1/1 Running 0 8m\n    kube-system pod/l7-default-backend-5d5b9874d5-k9mn8 1/1 Running 0 8m\n    kube-system pod/metrics-server-v0.2.1-7486f5bd67-wlnlg 2/2 Running 0 6m\n    openebs pod/maya-apiserver-68c98fdb76-5bt2z 1/1 Running 0 4m\n    openebs pod/openebs-provisioner-5569654c96-4n4hp 1/1 Running 0 4m\n    openebs pod/openebs-snapshot-operator-5f7c4d9bd8-shk58 2/2 Running 0 4m\n    NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n    default service/kubernetes ClusterIP 10.55.240.1 <none> 443/TCP 8m\n    default service/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-svc ClusterIP 10.55.253.18 <none> 3260/TCP,9501/TCP 2m\n    default service/wordpress LoadBalancer 10.55.253.170 104.154.224.12 80:31392/TCP 2m\n    kube-system service/default-http-backend NodePort 10.55.243.156 <none> 80:30045/TCP 8m\n    kube-system service/heapster ClusterIP 10.55.248.200 <none> 80/TCP 8m\n    kube-system service/kube-dns ClusterIP 10.55.240.10 <none> 53/UDP,53/TCP 8m\n    kube-system service/metrics-server ClusterIP 10.55.244.66 <none> 443/TCP 8m\n    openebs service/maya-apiserver-service ClusterIP 10.55.240.121 <none> 5656/TCP 4m\n    NAMESPACE NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\n    default persistentvolumeclaim/wp-pv-claim Bound pvc-7030ae5f-9d40-11e8-afcb-42010a800179 20Gi RWO openebs-standard 2m\n\n## MySql deployment\n\nFollow the same procedure as done for WordPress deployment and execute a kubectl apply on it. The output of kubectl get pods,svc ,pvc — all-namespaces will look similar to this:\n\n    $ kubectl get pods,svc,pvc --all-namespaces\n    NAMESPACE NAME READY STATUS RESTARTS AGE\n    default pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-ctrl-b5c4f588f-lrl2l 2/2 Running 0 2m\n    default pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-rep-66d7f6fb46-2jcgx 1/1 Running 0 2m\n    default pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-rep-66d7f6fb46-j5tsk 1/1 Running 0 2m\n    default pod/pvc-082a54c8-9d41-11e8-afcb-42010a800179-rep-66d7f6fb46-q9kww 1/1 Running 0 2m\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-766678794-jtltg 2/2 Running 0 6m\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-2pkt4 1/1 Running 0 6m\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-htdxh 1/1 Running 0 6m\n    default pod/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-rep-6689868cf4-rdtlk 1/1 Running 0 6m\n    default pod/wordpress-7bdfd5557c-5b4nh 1/1 Running 4 6m\n    default pod/wordpress-mysql-bcc89f687-zlt5q 1/1 Running 0 2m\n    kube-system pod/event-exporter-v0.2.1-5f5b89fcc8-wprbm 2/2 Running 0 11m\n    kube-system pod/fluentd-gcp-scaler-7c5db745fc-s9mp9 1/1 Running 0 11m\n    kube-system pod/fluentd-gcp-v3.0.0-49vq6 2/2 Running 0 9m\n    kube-system pod/fluentd-gcp-v3.0.0-kfjsx 2/2 Running 0 9m\n    kube-system pod/fluentd-gcp-v3.0.0-tg5hh 2/2 Running 0 9m\n    kube-system pod/heapster-v1.5.3-76f7f5f544-z7xk9 3/3 Running 0 10m\n    kube-system pod/kube-dns-788979dc8f-2chf4 4/4 Running 0 11m\n    kube-system pod/kube-dns-788979dc8f-ls4ln 4/4 Running 0 10m\n    kube-system pod/kube-dns-autoscaler-79b4b844b9-8745z 1/1 Running 0 11m\n    kube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8866 1/1 Running 0 11m\n    kube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-8fh5 1/1 Running 0 11m\n    kube-system pod/kube-proxy-gke-ashish-ranjan-default-pool-f0958e58-9jjf 1/1 Running 0 11m\n    kube-system pod/l7-default-backend-5d5b9874d5-k9mn8 1/1 Running 0 11m\n    kube-system pod/metrics-server-v0.2.1-7486f5bd67-wlnlg 2/2 Running 0 10m\n    openebs pod/maya-apiserver-68c98fdb76-5bt2z 1/1 Running 0 7m\n    openebs pod/openebs-provisioner-5569654c96-4n4hp 1/1 Running 0 7m\n    openebs pod/openebs-snapshot-operator-5f7c4d9bd8-shk58 2/2 Running 0 7m\n    NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n    default service/kubernetes ClusterIP 10.55.240.1 <none> 443/TCP 12m\n    default service/pvc-082a54c8-9d41-11e8-afcb-42010a800179-ctrl-svc ClusterIP 10.55.251.84 <none> 3260/TCP,9501/TCP 2m\n    default service/pvc-7030ae5f-9d40-11e8-afcb-42010a800179-ctrl-svc ClusterIP 10.55.253.18 <none> 3260/TCP,9501/TCP 6m\n    default service/wordpress LoadBalancer 10.55.253.170 104.154.224.12 80:31392/TCP 6m\n    default service/wordpress-mysql ClusterIP None <none> 3306/TCP 2m\n    kube-system service/default-http-backend NodePort 10.55.243.156 <none> 80:30045/TCP 11m\n    kube-system service/heapster ClusterIP 10.55.248.200 <none> 80/TCP 11m\n    kube-system service/kube-dns ClusterIP 10.55.240.10 <none> 53/UDP,53/TCP 11m\n    kube-system service/metrics-server ClusterIP 10.55.244.66 <none> 443/TCP 11m\n    openebs service/maya-apiserver-service ClusterIP 10.55.240.121 <none> 5656/TCP 7m\n    NAMESPACE NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\n    default persistentvolumeclaim/mysql-pv-claim Bound pvc-082a54c8-9d41-11e8-afcb-42010a800179 20Gi RWO openebs-standard 2m\n    default persistentvolumeclaim/wp-pv-claim Bound pvc-7030ae5f-9d40-11e8-afcb-42010a800179 20Gi RWO openebs-standard 6m\n\nIf all of the pods are running, check the external IP of the WordPress load balancer. For example, in my case it is **104.154.224.12. **Open the your web browser IP if you are redirected to your WordPress setup page. Congratulations! Your WordPress is now ready for you to start your blog!\n\nHappy blogging!\n\n### Proof:\n\n![](/content/images/2020/01/wordpress.png)\n","slug":"setting-up-wordpress-and-sql-with-openebs"},{"id":9,"title":"How to start contributing to mayactl","author":"Sumit Lalwani","author_info":"Sumit Lalwani is a Software Engineer at Mayadata. He is a Kubernetes enthusiast and passionate about open source, containers, cloud, and arm. He loves to learn and code.","date":"14-08-2018","tags":["Docker","Openebs","Kubernetes"],"content":"\n## What is mayactl?\n\n- mayactl is the command line tool for interacting with OpenEBS volumes. mayactl is not used/required while provisioning or managing the OpenEBS volumes, but it is currently used while debugging and troubleshooting.\n- mayactl is the client like kubectl which requests to maya-apiserver to get specific information whereas kubectl requests to Kubernetes apiserver to get specific information.\n- mayactl helps retrieve storage related information for debugging/troubleshooting storage related issues. mayactl provides various commands to create volume, get volume details and create, list and revert snapshot and many more.\n\nTo know more about the mayactl visit:\n\n[https://docs.openebs.io/docs/next/mayactl.html](https://docs.openebs.io/docs/next/mayactl.html)\n\n## OpenEBS Architecture\n\n![](/content/images/2020/01/openebs-architecture.png)OpenEBS Architecture\nTo know about the OpenEBS visit: [https://docs.openebs.io/docs/next/introduction.html](https://docs.openebs.io/docs/next/introduction.html)\n\n### These few things are required to be installed in your system (with Ubuntu host) to run mayactl\n\n1. **Docker**\n\n- To install docker run these commands\n\n  sudo apt-get update\n  sudo apt-get install apt-transport-https ca-certificates curl software-properties-common\n  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n  sudo add-apt-repository \\\n   \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n   $(lsb_release -cs) \\\n   stable\"\n  sudo apt-get update\n  sudo apt-get install docker.io\n\n- Or you can visit the official docker website to install docker\n\n[https://docs.openebs.io/docs/next/mayactl.html](https://docs.openebs.io/docs/next/mayactl.html)\n\n2. **open-iscsi package**\n\n- To install open-iscsi package run these commands\n\n  sudo apt-get update\n  sudo apt-get install open-iscsi\n  sudo service open-iscsi restart\n\n3. **Golang**\n\n- To install golang, visit the official golang website: [https://golang.org/doc/install](https://golang.org/doc/install)\n\n4. **Minikube**.\n\n- To install minikube, run these commands:\n\n  # minikube requires virtualbox to be installed as a dependency\n\n  sudo apt-get install virtualbox virtualbox-ext-pack\n  sudo apt-get update\n\n  # minikube version 0.24.0\n\n  curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.24.0/minikube-linux-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/\n\n5. **Kubectl**.\n\n- Run these commands to install Kubectl:\n\n  curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.8.0/bin/linux/amd64/kubectl\n  chmod +x ./kubectl\n  sudo mv ./kubectl /usr/local/bin/kubectl\n\n### How do I run mayactl in a local machine for development purposes?\n\n1. Open the openebs repo ( [https://github.com/openebs/openebs](https://github.com/openebs/openebs)) and star the openebs repo.. 😄 (Not Mandatory)\n2. Fork the openebs/openebs and openebs/maya repositories into your GitHub account.\n\n- Visit and click on the fork option (both repositories)\n\n[a) openebs/openebs](https://github.com/openebs/openebs)\n\n[OpenEBS is containerized block storage written in Go for cloud native and other environments w/ per container (or pod)…](https://github.com/openebs/openebs)[github.com](https://github.com/openebs/openebs)\n\n[b) openebs/maya](https://github.com/openebs/maya)\n\n[maya — OpenEBS Maya extends Kubernetes capabilities to orchestrate CAS containers.](https://github.com/openebs/maya)[github.com](https://github.com/openebs/maya)\n\n3. Clone the openebs and maya repositories inside your gopath. Then run these commands to clone:\n\n   # if directories not present create the directories in same hierarchy\n\n   cd $GOPATH/src/github.com/openebs\n   git clone https://github.com/<your-github-username>/openebs.git\n   git clone https://github.com/<your-github-username>/maya.git\n\n4. Run the single node cluster using the minikube command.\n\n   minikube start --vm-driver=none\n\n   # To check whether minikube is configured and running\n\n   minikube status\n\n5. Install OpenEBS by executing these commands:\n\n   cd $GOPATH/src/github.com/openebs/openebs/k8s/\n   kubectl apply -f openebs-operator.yaml\n   kubectl apply -f openebs-storageclasses.yaml\n\n![](/content/images/2020/01/install-openebs-by-commands.png)kubernetes commands 6. Now we have the openebs-provisioner and maya-apiserver running as a pod in the Kubernetes (minikube) cluster.\n\n- To get the pods, run this command:\n\n  kubectl get pods\n  NAME READY STATUS RESTARTS AGE\n  maya-apiserver-7b8d5496cc-kgmnn 1/1 Running 0 3m\n  openebs-provisioner-6797d44769-phnnc 1/1 Running 2 3m\n\n7. To run/access mayactl, you will need to login/execute into the maya-apiserver pod on Kubernetes.\n\n- Find out the name of the maya api-server pod by running the following commands:\n\n  kubectl get pods\n\n  # It will access the bash shell inside the pod\n\n  kubectl exec -it <maya-apiserver-podname> /bin/bash\n\n8. Now you can run all mayactl commands as you are inside the maya-apiserver pod.\n\n- Try running these commands after exececute/login into the pod.\n\n  mayactl -help\n\nGo through the issues ([https://github.com/openebs/maya/issues](https://github.com/openebs/maya/issues)) and start modifying the mayactl code, located in $GOPATH/src/github.com/openebs/maya/cmd/mayactl, and start contributing to OpenEBS. Also, you can start contributing by writing a small unit test code in mayactl. For every PR you raise, you will also receive goodies from the OpenEBS team. 😃\n\n**How do I test the changes made in mayactl?**\n\n1. After modifying the mayactl code, go into the maya directory, i.e $GOPATH/src/github.com/openebs/maya, and run these commands:\n\n   # run this if not currently in maya directory\n\n   cd $GOPATH/src/github.com/openebs/maya\n\n   # this will create the mayactl binary into the bin folder inside maya directory\n\n   make mayactl\n\n2. After the build has been completed, copy the mayactl binary from the bin folder to the maya-apiserver pod using the command:\n\n   kubectl cp $GOPATH/src/github.com/openebs/maya/bin/maya/mayactl <maya-apiserver-podname>:/tmp/\n\n3. Login/execute into the maya-apiserver pod to run the mayactl binary.\n\n   kubectl exec -it <maya-apiserver-podname> /bin/bash\n   cd /tmp/\n\n4. Here the mayactl binary you copied is shown.\n\n- To run that binary, use the following command:\n\n  ./mayactl -help\n\nNow you can easily see the changes you made in the mayactl command line tool. You are also now ready to raise the PR’s. 😃\n\n**Reference:**\n\n- [https://www.youtube.com/watch?v=yzMEYT-yzRU](https://www.youtube.com/watch?v=yzMEYT-yzRU)\n- [https://docs.openebs.io/docs/next/introduction.html](https://docs.openebs.io/docs/next/introduction.html?__hstc=216392137.2d2e61b1b8f85b3675bfaef604437f8a.1580205967521.1580205967521.1580205967521.1&__hssc=216392137.1.1580205967522&__hsfp=2262740235)\n","slug":"how-to-start-contributing-to-mayactl"},{"id":10,"title":"\"ARMing Kubernetes with OpenEBS #1\"","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"02-08-2018","tags":["Arm64","Kubernetes","Lepotato","Owncloud","Solutions"],"content":"\n## Running stateful containers on Le Potato\n\nWhy not! It’s fun and extremely efficient! I know many people (including me) used to run ownCloud on their desktop computers. I have finally decided to retire my old desktop computer and was looking ways to keep my ownCloud instance alive and maybe even improve it a bit.\n\nFirst, I ran **ownCloud** on GKE Kubernetes cluster and came to a decison quickly that it’s not what I needed:\n\n- I am used to the speed of USB 3.0 for large uploads when needed. I wanted to keep the option of (50MB+/sec) using USB. Which means, if I choose a budget ARM SoC route, then the board should have **non-shared bandwidth** for LAN and USB.\n- 4 node GKE cluster using n1-standard-1 + 200GB storage costs ~$225/month, I would rather use Dropbox for $20/month = 240$/year (still doesn’t give me what I need).\n- **Low-power**, possibly solar-powered. I’ll share my power consumption findings in the series of blog articles.\n- Everything on **Kubernetes** is more fun, right?\n\nI was looking into [Raspberry Pi 3 Model B](http://amzn.to/2GMjYt4) option and after a quick trial realized that shared USB/Ethernet bandwidth and lack of MicroSD UHS support is not going to give me the performance I need and found the **AML-S905X-CC Le Potato** board.\n\nLibre Computer Board, code name Le Potato, is designed as a drop in hardware replacement for the Raspberry Pi 3 Model B (In fact it has the exact same form factor and port locations) and offers faster performance, more memory, lower power, higher IO throughput, 4K capabilities, open market components, improved media acceleration and removal of the vendor locked-in interfaces. This platform uses the latest technologies and is built upon proven long-term available chips. It is supported by upstream Linux and has a downstream development package based on Linux 4.9 LTS that offers ready-to-go 4K media decoding, 3D acceleration, and more.\n\nMost importantly, Le Potato has almost double the performance of RPi 3 with 2GB memory and 50% faster CPU and GPU. It also has non-shared bandwidth for LAN and USB and MicroSD UHS support. I was able to get over 70MB/s read&write performance vs ~15–20MB/s on RPi 3. I also noticed that even under heavy load Le Potato has lower power consumption compared to Rpi 3.\n\nIt sounds too good to be true, right? Since Le Potato is new, I’ve decided to run both side-to-side and publish my experience.\n\nIn this blog post, I will focus on setting up a Kubernetes on a Le Potato Clusters, install ownCloud on top, and compare it to Rpi 3.\n\n## Prerequisites\n\n### Hardware\n\n- 4 x [Libre Computer Board AML-S905X-CC (Le Potato) 64-bit (2GB)](http://amzn.to/2ptxGJS) $45\n- 4 x 32GB MicroSD Card ([Samsung 32GB 95MB/s MicroSD](http://amzn.to/2uayTe4) $9.99)\n- 4 x 128GB USB Drive ([Samsung 128GB USB 3.0 Flash Drive Fit (MUF-128BB/AM)](http://amzn.to/2psgFPC) $39)\n- 1 x Desktop Switch ([TP-link 5-Port Gigabit Desktop Switch](http://amzn.to/2u3TCQN) $29.99)\n- 1 x Active USB Hub ([Generic 7-Port USB Hub with ON/OFF Switch](http://amzn.to/2IBIZaO) $5.64)\n- 4 x short USB to Micro USB cable ([ZiBay Micro USB Short Sync Cable for Select Models/Device, 7-Inch — Pack of 5](http://amzn.to/2G8Doub) $6.99)\n- For comparison: 4 x [Raspberry Pi 3 Model B](http://amzn.to/2GMjYt4) $34.62\n\n### Optional:\n\n- Short cables make it look clean and nice:\n  6-inch CAT6 flat network cables ([5-PACK 6-inch CAT6 Network UTP Ethernet RJ45 Flat-Design](http://amzn.to/2GcT5AV) $12.48)\n- One touchscreen to access the cluster when nothing else available:\n  1x 3.5 inch TFT Touch Screen ([kuman 3.5 Inch 480×320 TFT Touch Screen Monitor for Raspberry Pi](http://amzn.to/2pwR9tt) $19.39)\n- I also build a mobile version to run in my car using this with a Tmobile line ([SIM800 Module GSM GPRS Expansion Board UART V2.0](http://amzn.to/2GLBeyE) $25.99)\n\n### Software components used\n\n- [Armbian 5.38 Ubuntu Xenial](https://dl.armbian.com/lepotato/) (for Le Potato)\n- [Raspbian Stretch Lite](https://www.raspberrypi.org/downloads/raspbian/) 2017–11–29 (for Rpi 3)\n- [Etcher](https://etcher.io/) v1.3.1\n- Kubernetes v1.9.2+\n- OpenEBS 0.5.3 arm64\n- ownCloud\n\nI will start with Le Potato and compare against Raspberry Pi 3 on my next blog.\n\n### Flash Le Potato Armbian image on SD Cards\n\n**Armbian** provides Debian and Ubuntu based builds for ARM development boards. Armbian Ubuntu is pretty much same as Ubuntu, except the desktop interface. Armbian uses the Xfce desktop environment, which is a lighter than Gnome or KDE. Its main advantage is its speed, and it’s ideal for systems with 256 MB to 512 MB of RAM. And, I plan to disable desktop anyways.\n\nDownload the [Armbian Ubuntu image](https://dl.armbian.com/lepotato/Ubuntu_xenial_next_desktop.7z) from the link [here](https://dl.armbian.com/lepotato/), extract and burn it to your SD cards using Etcher.\n![](https://cdn-images-1.medium.com/max/800/0*XI8xSg4dCl_IWvbz.png)\nPlug the SD card into your Le Potato board and power on.\n![](https://cdn-images-1.medium.com/max/800/0*ojAbBScZY7giAV7b.jpg)\nLogin as `root` and use password `1234`. You will be prompted to change this password at first login. Next, you will be asked to create a normal user account that is sudo enabled.\n\n### Prepare Armbian host\n\nAfter reboot, you will auto login to your host with the new user you have created.\n![Armbian Le Potato](https://cdn-images-1.medium.com/max/800/0*UOLgX8I0Oz9hw7I8.jpg)\nChange the hostname and set static IP by using armbian-config utility:\n\n`sudo armbian-config`\n![armbian-config utility](https://cdn-images-1.medium.com/max/800/0*s8fjc1-L-9pkDzRE.png)\nDisable swap by running the following commands:\n\n    sudo systemctl disable zram-configsudo swapoff -a\n\nAnd also comment out the reference to swap in /etc/fstab file:\n\n    sudo vi /etc/fstab\n\nAfter reboot, confirm that swap space is disabled by running the following command. It should return empty.\n\n    sudo swapon — summary\n\nInstall Golang 1.10:\n\n    wget https://dl.google.com/go/go1.10.linux-arm64.tar.gz\n    sudo tar -C /usr/local -xzf go1.10.linux-arm64.tar.gz\n    export PATH=$PATH:/usr/local/go/bin\n    mkdir go\n    export GOPATH=”$HOME/go”\n    go get github.com/kubernetes-incubator/cri-tools/cmd/crictl\n\nRepeat all the steps above on all your nodes.\n\n#### Install Docker on Armbian Ubuntu (arm64)\n\nRun the following command to install Docker on all nodes. The second line is to use Docker as a non-root user, use your username instead of mine below (murat):\n\n    curl -sL https://get.docker.com | sh\n    sudo usermod murat -aG docker\n\nSuccessful installation would look like below:\n\n    murat@kubenode1:~$ curl -sL https://get.docker.com | sh\n     # Executing docker install script, commit: 02d7c3c\n     + sudo -E sh -c apt-get update -qq >/dev/null\n     + sudo -E sh -c apt-get install -y -qq apt-transport-https ca-certificates curl >/dev/null\n     + sudo -E sh -c curl -fsSL “https://download.docker.com/linux/ubuntu/gpg\" | apt-key add -qq →/dev/null\n     + sudo -E sh -c echo “deb [arch=arm64] https://download.docker.com/linux/ubuntu xenial edge” > /etc/apt/sources.list.d/docker.list\n     + [ ubuntu = debian ]\n     + sudo -E sh -c apt-get update -qq >/dev/null\n     + sudo -E sh -c apt-get install -y -qq — no-install-recommends docker-ce >/dev/null\n     + sudo -E sh -c docker version\n     Client:\n     Version: 18.02.0-ce\n     API version: 1.36\n     Go version: go1.9.3\n     Git commit: fc4de44\n     Built: Wed Feb 7 21:11:48 2018\n     OS/Arch: linux/arm64\n     Experimental: false\n     Orchestrator: swarm\n    Server:\n     Engine:\n     Version: 18.02.0-ce\n     API version: 1.36 (minimum version 1.12)\n     Go version: go1.9.3\n     Git commit: fc4de44\n     Built: Wed Feb 7 21:09:57 2018\n     OS/Arch: linux/arm64\n     Experimental: false\n     If you would like to use Docker as a non-root user, you should now consider\n     adding your user to the “docker” group with something like:\n    sudo usermod -aG docker murat\n    Remember that you will have to log out and back in for this to take effect!\n    WARNING: Adding a user to the “docker” group will grant the ability to run\n     containers which can be used to obtain root privileges on the\n     docker host.\n     Refer to https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface\n     for more information.\n\nRepeat all the steps above on all your nodes.\n\n#### Install Kubernetes on Armbian for Le Potato\n\nRun the following command to install Kubeadm on all nodes:\n\n    curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add — && \\\n     echo “deb http://apt.kubernetes.io/ kubernetes-xenial main” | sudo tee /etc/apt/sources.list.d/kubernetes.list && \\\n     sudo apt-get update -q && \\\n     sudo apt-get install -qy kubeadm\n\nRepeat all the steps above on all your nodes.\n\n#### Initialize Kubernetes master node\n\nInitialize your master K8s node:\n\n    sudo kubeadm init — pod-network-cidr=10.20.0.0/24 — apiserver-advertise-address=10.10.0.131\n\nBy default, token expires in 24h. If you need it longer, then you can add `— token-ttl=0` to the end of the command above to generate token that does not expire.\n\nThis step may take around 10 minutes and after that, you will see a summary like below:\n\n    …\n    Your Kubernetes master has initialized successfully!\n    To start using your cluster, you need to run the following as a regular user:\n    mkdir -p $HOME/.kube\n     sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n     sudo chown $(id -u):$(id -g) $HOME/.kube/config\n    You should now deploy a pod network to the cluster.\n     Run “kubectl apply -f [podnetwork].yaml” with one of the options listed at:\n     https://kubernetes.io/docs/concepts/cluster-administration/addons/\n    You can now join any number of machines by running the following on each node\n     as root:\n    kubeadm join — token 17c6f2.bd9fa915e6a2fcfb 10.10.0.131:6443 — discovery-token-ca-cert-hash sha256:b4995d14fc8995d5ac271e49772b1cf5aa9fee48fa2729fd4ca7fefbbb0564ac\n\nRun the following:\n\n    mkdir -p $HOME/.kube\n    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n    sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nDeploy a pod network to the cluster. I used flannel, you can see your other options [here](https://kubernetes.io/docs/concepts/cluster-administration/addons/).\n\n    sudo sysctl net.bridge.bridge-nf-call-iptables=1\n    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n\nBy default, pods cannot be scheuled on the master node. If you want to be able to schedule pods on the master, e.g. for a single-machine Kubernetes cluster for development, run:\n\n    kubectl taint nodes — all node-role.kubernetes.io/master-\n\nAs soon as the pod network has been installed, you can continue by joining your nodes.\n\nTo confirm that kube-dns pod is up run the command below and check the output:\n\n    murat@kubenode1:~$ kubectl get pods — all-namespaces\n     NAMESPACE NAME READY STATUS RESTARTS AGE\n     kube-system etcd-kubenode1 1/1 Running 0 1m\n     kube-system kube-apiserver-kubenode1 1/1 Running 0 1m\n     kube-system kube-controller-manager-kubenode1 1/1 Running 0 1m\n     kube-system kube-dns-6448b967fc-bc58z 3/3 Running 0 1m\n     kube-system kube-proxy-h7p6s 1/1 Running 0 1m\n     kube-system kube-scheduler-kubenode1 1/1 Running 0 1m\n     [/cce_bash]\n\nNote: If kube-dns is stuck in the Pending state. Follow the steps below to fix it and re init your master. This issue and the solution was mentioned [here](https://github.com/kubernetes/kubernetes/issues/43815).\n\n    kubeadm reset\n    sudo nano /etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n\nRemove the `$KUBELET_NETWORK_ARGS` entry from the ExecStart, save the file, and reload systemd and kube services.\n\n    systemctl daemon-reload\n     systemctl restart kubelet.service\n\nInitialize your master K8s node again.\n\n## Join Kubernetes nodes to the cluster\n\nYou can now join any number of nodes by running the command with the token generated during the K8s master initialization:\n\n    murat@kubenode2:~$ kubeadm join — token 17c6f2.bd9fa915e6a2fcfb 10.10.0.131:6443 — discovery-token-ca-cert-hash sha256:b4995d14fc8995d5ac271e49772b1cf5aa9fee48fa2729fd4ca7fefbbb0564ac\n     [preflight] Running pre-flight checks.\n     [preflight] Some fatal errors occurred:\n     [ERROR IsPrivilegedUser]: user is not running as root\n     [preflight] If you know what you are doing, you can make a check non-fatal with ` — ignore-preflight-errors=…`\n     murat@kubenode2:~$ sudo kubeadm join — token 17c6f2.bd9fa915e6a2fcfb 10.10.0.131:6443 — discovery-token-ca-cert-hash sha256:b4995d14fc8995d5ac271e49772b1cf5aa9fee48fa2729fd4ca7fefbbb0564ac\n     [preflight] Running pre-flight checks.\n     [WARNING SystemVerification]: docker version is greater than the most recently validated version. Docker version: 18.03.0-ce. Max validated version: 17.03\n     [discovery] Trying to connect to API Server “10.10.0.131:6443”\n     [discovery] Created cluster-info discovery client, requesting info from “https://10.10.0.131:6443\"\n     [discovery] Requesting info from “https://10.10.0.131:6443\" again to validate TLS against the pinned public key\n     [discovery] Cluster info signature and contents are valid and TLS certificate validates against pinned roots, will use API Server “10.10.0.131:6443”\n     [discovery] Successfully established connection with API Server “10.10.0.131:6443”\n    This node has joined the cluster:\n     * Certificate signing request was sent to master and a response\n     was received.\n     * The Kubelet was informed of the new secure connection details.\n\nRun `kubectl get nodes` on the master to see this node join the cluster.\n\nIf you forgot the cluster token, you can generate a new one with the command:\n\n    kubeadm token generate\n\nRepeat all the steps above on all your nodes.\n\n## Install OpenEBS on ARM (Le Potato)\n\nSimilar to most of the arm based hobby boards, Le Potato doesn’t provide any additional redundancy. Even using a RAID protected external USB device wouldn’t give me protection against node failure unless it’s some form of a shared network storage. They are both way over my affordability requirement. All I need is a replicated block device, so my container can survive a node or USB device failures.\n\nOpenEBS provides a great solution for modern x64 architecture but currently doesn’t have a build for [arm64](https://en.wikipedia.org/wiki/ARM_architecture#64/32-bit_architecture) (armv8) architecture. Therefore, I’ve opened an issue [here](https://github.com/openebs/openebs/issues/1295) and started working on it myself. I did successfully build OpenEBS images for arm64 architecture from the repo base on the 0.5.3 release and uploaded custom images to my personal docker registry [here](https://hub.docker.com/u/muratkarslioglu/). So, it is work in progress and please use it at your own risk, until it’s merged.\n\n    sudo apt-get install -y curl open-iscsi\n    kubectl apply -f https://raw.githubusercontent.com/muratkars/openebs/lepotato-arm64/k8s/openebs-operator-arm64.yaml\n    kubectl apply -f https://raw.githubusercontent.com/muratkars/openebs/lepotato-arm64/k8s/openebs-storageclasses.yaml\n\nNow, get the list of storage classes using the below command:\n\n    $ kubectl get sc\n     NAME PROVISIONER AGE\n     openebs-cassandra openebs.io/provisioner-iscsi 1h\n     openebs-es-data-sc openebs.io/provisioner-iscsi 1h\n     openebs-jupyter openebs.io/provisioner-iscsi 1h\n     openebs-kafka openebs.io/provisioner-iscsi 1h\n     openebs-mongodb openebs.io/provisioner-iscsi 1h\n     openebs-percona openebs.io/provisioner-iscsi 1h\n     openebs-redis openebs.io/provisioner-iscsi 1h\n     openebs-standalone openebs.io/provisioner-iscsi 1h\n     openebs-standard openebs.io/provisioner-iscsi 4d\n     openebs-zk openebs.io/provisioner-iscsi 1h\n\n**Voila…!**\n\n`openebs-standard` storage class creates 3 replicas. That’s what I will use for my application.\n\nTo test the OpenEBS installation you can try my Jenkins example here:\n\n    kubectl apply -f https://raw.githubusercontent.com/muratkars/openebs/lepotato-arm64/k8s/demo/jenkins/jenkins-arm64.yaml\n\n## Next — Installing containerized OwnCloud on OpenEBS\n\nFinding right container images to run on arm64 architecture is challenging. On the next article, I will build an OwnCloud container image running on Postgres database and both containers will store their data on OpenEBS persistent volumes.\n\nMy final goal is to build a mobile OwnCloud cluster installed in my family van, where storage is replicated to another cluster in my home lab.\n\nStay tuned!\n\n---\n\n_Originally published at _[_Containerized Me_](http://containerized.me/arming-kubernetes-with-openebs-1/)_._\n","slug":"arming-kubernetes-with-openebs-1"},{"id":11,"title":"\"Recap of Google Next’18\"","author":"Murat Karslioglu","author_info":"No author information","date":"01-08-2018","tags":["Cloud-Services-Platform","Knative","Google-Next18","Istio","Openebs"],"content":"\n![](https://lh3.googleusercontent.com/iBQD9nOCN5cmrzn73zLeMoHDdhbTZWa3d4sSC1k1wkudXXL0L0912hrjUe2Bxr3MBTLOM_-LDC-ZrA-zNq8arcTJfD_V6e0pc_A9_oKcm6tAsBnIfqXdTfEbnmb8Qu_PoSyBZkVN)You know that you are at the right event when you see a familiar face like Mr. Hightower :)\nThis year I have attended a number of tech events and in terms of size, organization, and especially the content — Next ’18 is so far my favorite.\n\nNext ’18 was an excellent representation of Google as a company and their culture. Sessions were mostly in Moscone West, but the whole event was spread across Moscone West, the brand new South building, and six other buildings.\n![](https://lh4.googleusercontent.com/3ojmOPqqjEieE6GxfEjgFxRRv4sIzQpA_x21hFRpj3IRrmy6i7HL4k5FO2zztbwf9b5HJlrzO8BP3bWkOM34gZQdKS5lmLqR0FjmHJr96VIToFfc-SWdIKmlLcMJLz2y_tWPbERn)Next ’18 Event Map\nThe floor plan was fun and casual; catering was of “Google Quality” and the security was insane, with metal detectors, police, K9 search dogs, and cameras everywhere. And of course games, fun, and even “Chrome Enterprise Grab n Go” were there in case you needed a loaner laptop to work on — see some pictures at the end. :)\n\n### **What I learned at the Next ’18 conference**\n\nFirst of all, a big shout out to all involved in the [**Istio** project](https://istio.io/). It is not a surprise that we see great advocate marketing and support for the Istio 1.0 GA release on social media last week. Istio is a big part of the [**Google’s Cloud Services Platform**](https://cloud.google.com/solutions/cloud-services-platform/)(**CSP**) puzzle.\n![](https://lh4.googleusercontent.com/taoSgNELqkMCnfsqUd84nPfbIATkjucboLYdbzMUWKct5ZFiXb_PZFjoU5KFBc5LZNBz6mhuwHXEpMs49tREabCzrMDCuNTrKniQ4UYuk_i1pNxR08pUHOEjtZ3nxfUOZswcA_xe)GCSP Dashboard — After deploying my first app in less than 30 seconds.\nLater this year, Google is targeting to make all components of their CSP available (in some form). CSP will combine **Kubernetes**, **GKE**, **GKE On-Prem**and **Istio **with Google’s infrastructure, security, and operations to increase velocity, reliability and manage governance at scale.\n\nCloud Services Platform will be extensible through an open ecosystem. **Stackdriver Monitoring** and **Marketplace** are the extensions to platform services. [Marketplace](https://console.cloud.google.com/marketplace/browse?filter=solution-type:k8s) already has 27 Kubernetes apps including commonly used components of many environments such as Elasticsearch and Cassandra.\n![](https://lh3.googleusercontent.com/esTW1l0iBV-Wvleoosxha1W5KqmA5BQLZ-4jyfb3e0W2j_S5rzqtncJCFA8t6brQc_ZJdF2eVqaXAdhHASBlTq9izYO85SLSZRyE8mbwoB1EiFHTmQdwDHsnTdFm2EDb0i4yefVA)CSP Marketplace\nUsers will be able to deploy a unified architecture, that spans from their private cloud, using Google CSP to Google’s public cloud. Again, the two most important pieces to this puzzle are managed versions of the open source projects Kubernetes and Istio. To me, the rest of it still feels mostly to be DIY-like quality.\n\nKnative, Cloud Build, and CD are other significant solutions announced at Next’18.\n\n### **A new cloud availability zone, this time in your datacenter — which might be in your garage**\n\nAt first,** GKE on-prem** got me interested. But, after talking to a few Google Cloud Experts again, I felt it’s very early to be seriously considered. You can read others’ thoughts here on [Hacker News](https://news.ycombinator.com/item?id=17602555).\n![](https://lh5.googleusercontent.com/q_0yHazRpRZ9bLptYCw1_GQsmdM8TpbM7xXmZ8nL8nejR3uhVg79bvJokA_BrQ91VfzYYl8OLtQ1Evl5VNJqDwJM3EKwqKFsn_jr99N91hCEa1lkazjMZE3aphRbr21LEc0atqTr)Discussions on GKE on-prem\nGKE on-prem alpha will support **_vSphere 6.5_** only, no bare-metal for now!\n\nFailover from on-prem -> GKE is something Google team is working on. This means GKE on-prem instance will look like another availability zone (AZ) on a Google Cloud dashboard.\n\nOther than vSphere dependency, the idea of being able to have an availability zone, local in your data center is really compelling. It is also a very common use-case for [**OpenEBS**](https://openebs.io/) since there is no cloud vendor provided, a cloud-native way of spreading your cloud volumes, EBS, etc. across AZs — we see many community users running web services today using OpenEBS to enable that.\n\n### **Github and Google Partnership to provide a CI/CD platform**\n\n**Cloud Build** is Google’s fully managed CI/CD platform that lets you build and test applications in the cloud. Cloud Build is fully integrated with GitHub workflow, simplifies CI processes on top of your GitHub repositories.\n![](https://lh3.googleusercontent.com/Vid2Mpm0eaSATtriAt3eLoDdBvvRcv7WCJeNBKxe_VOhVcbdrmh_nJIn5aiQlnMfEOpywRMhHF7Gnv58Nyu_5MQHoWWfxMCmPYdfDlYlKkiQPldJvHxEk9Qa5BOQBuDQNW-YZ0dc)Me deploying myself on Serverless Cloud Maker ;)\nCloud Build features;\n\n**Multiple environment support** lets developers build, test, and deploy across multiple environments such as VMs, serverless, Kubernetes, or Firebase.\n\n**Native Docker support **means that deployment to Kubernetes or GKE can be automated by just importing your Docker files.\n\n**Generous free tier **— 20 free build-minutes per day and up to 10 concurrent builds may be good enough for many small projects.\n\n**Vulnerability identification** performs built-in package vulnerability scanning for Ubuntu, Debian, and Alpine container images.\n\n**Build locally or in the cloud **enables more edge usage or GKE on-prem.\n\n### **Serverless — here we are again**\n\n**Knative **is a new open-source project started by engineers from Google, Pivotal, IBM, and a few others. It’s a K8s-based platform to build, deploy, and manage serverless workloads.\n\n_“The biggest concern on Knative is the dependency on Istio.”_\n\nTraffic management is critical for serverless workloads. Knative is tied to Istio and can’t take advantage of the broad ecosystem. This means existing external DNS services and cert-managers cannot be used. I believe, Knative still needs some work and not ready for prime-time. If you don’t believe me, read the installation YAML file — I mean the 17K lines “human readable” configuration file ([release.yaml](https://github.com/knative/serving/releases/download/v0.1.0/release.yaml)).\n![](https://lh6.googleusercontent.com/0qn1GCe8B-15DIr5G7eqqbg3FfnOcm58iQ08ZUobrKJ82xIArtNjnSuFS2KOkkEhyGfyTH8pz5_NXZOk87EllIjN4rSVYlyxxmN6iDemZ0AgM_Yd-FMZzMR-nQdCHpFPTIL84hwS)\n\n### **My take on all of the above — Clash of the Cloud Vendors**\n\nIf you have been in IT long enough, you could easily see the pattern and predict why some technologies will become more important and why will the others be replaced.\n\n_“What is happening today in the industry is the battle to become the “Top-level API” vendor.”_\n\n20–25 years ago hardware was still the king of IT. Brand-name server, network, and storage appliance vendors were ruling in the datacenters. Being able to manage network routers or configure proprietary storage appliances were the most wanted skills. We were talking to hardware…\n\n20 years ago (in 1998), VMware was founded. VMware slowly but successfully commercialized hypervisors and virtualized the IT. They became the new API to talk to, everything else under that layer became a commodity. We were suddenly writing virtualized drivers, talking software-defined storage and networking — the term “software-defined” was born. Traditional hardware vendors lost the market and momentum!\n\n12 years ago, the AWS platform was launched. Cloud vendors became the new API that developers wanted to talk to, hypervisors became a commodity. CIO and enterprises that are sucked into the cloud started worrying about the cloud lock-in. Just like the vendor lock-in or hypervisor lock-in, we have experienced before. Technology might be new, but concerns were almost the same.\n\n4 years ago, Kubernetes was announced and v1.0 released in mid-2015. Finally, an open-source project that threatens all previous, proprietary, vendor managed “Top-level API” that we were using became a majorly adopted container orchestration technology. Although it came from Google, it took off after it got open-sourced and probably would be right to say that so far financially, Red Hat profited most from Kubernetes with their Red Hat OpenShift platform. And now we see somewhat of a battle over APIs to be used in operating applications on Kubernetes, with the RedHat / CoreOS operator framework and other projects including one supported by Google and others such as Rook.io emerging to challenge or extend the framework.\n\nGoogle Container Engine (**GKE**), Microsoft Azure Container Service (AKS**)**, Amazon Elastic Container Service (**EKS**), IBM Cloud Container Service (**CCS**), and Rackspace Kubernetes-as-a-Service (**KaaS**) are all competing in the hosted Kubernetes space (new vendors expected here).\n\nThere is enough space to grow in the self-hosted Kubernetes space. GKE on-prem is the validation from Google.\n\n**Hardware>Virtualization>Cloud>Containers>Serverless???**\n\nMany of us see **Serverless** as the next step, but it might be too granular to support larger adoption and current limitations validate the claims. It doesn’t scale well for intense workloads.\n\nOne size doesn’t fit all, there are still traditional use cases that even run on bare-metal and VMs. Same might be true for Serverless. It is not for every workload. Modernizing existing workloads will take time, and we will see who will become the leader of the next “Top-level API”.\n\nWhat do you think? Who is going to win the clash of the titans? What did you think about Next’18 and Google’s strategy?\n\nThanks for reading and for any feedback.\n\n### **Some Next’18 moments from my camera**\n\n![](https://lh4.googleusercontent.com/ARfwggxkEIm1I-QXUGinQGV0zVQLzaTaQ9WxUEC4nN-xuTUsK0I-Bi4JO9kwyIi6MQYxnu0hBQDxdbkVy5nsTd5oQMEl-JCXRvdWWVhcrbCK3EfM8EegXImT2_Kn0kXeZoHbfLmK)![](https://lh5.googleusercontent.com/bUCoD0IKci0QEETmHlcrUN-wOSLFSYsIuR4aG96D3QtZo23_gm10SfBqMzUtHVduFt-XzA4m9mI-sae4ktxJRIG9m9aBUt9VUtG0ytYyjFoh-Q2GbFNlQC7Ry0iBiTiaKUNuKsFd)![](https://lh3.googleusercontent.com/Vdr19dKixjLs64xGxB_thJ3D8_-cnMihbC-gH50S5FuFJ13y2UMb42zSQy9Rp2LT9olLP5TPSRb4WPoW71l71NMJoBeK70SiFtYgsDs1l2k2tmLTiqJTlo9ajj0F0xTp4JlkQuF2)![](https://lh4.googleusercontent.com/GGkcm_nFqb_gDKJuBJISMI3mueZx6xiBE6R8diM84xEOnYmcSDQVNPaRTbIFgBf-fh1Y_8JcioxxP8g8RzrxYEUJ4Xhw51RMRdXw3aS3fVpbH_mjc_kPUC0pXL3WxXZNlgR3baCb)![](https://lh4.googleusercontent.com/seBUEu7ltrIHW3VxY_V5rqekHkLXfLYhR0dZZbsyr8MC-vww-_rGvQA3rPz0kfbqudV-LNAi292BTwNrGIe_KG56Vqr-sHSv-mPlIy8nhnJDQPQKnUj7ohg3uql67RVvqTf-earr)![](https://lh6.googleusercontent.com/2BPdWJYXZizBdmFra0GYqedeArDGynas8VsxPkC0FWhyCjUm8A7TYLpPN06hPMmQ1UQ_yPoG8mH91eRjAyQE6sbw4Jo2wjPlsqDVTLEohowMOtSQaEuSWZO0lIntDOeMip75K20P)![](https://lh3.googleusercontent.com/esI-PdVDc9sEqPoOkwG4nQhcD_FYSxs8Z1eBiHW9UTBDNO9bbd145X9vwnQgijXHTiz6DUD_bgkz9ViC1C2ukDYtjLaHVAIFlEMPcHmQEWjpKeq3pvEy4HyWXeK65oe61LUMTZ1-)![](https://lh5.googleusercontent.com/KtS0m1tRBvjWehJSCSFItgtvDK5IiAEU20aa3GfSK6TmlyPVWjQpjnq_z5OAxsa1-L7PQuNRuiK2ZRX1It-1CrDlqzv1ubwrYaZA_gQQGxsb2rXJCAiQPjZ9GLiqXHZsCess6dYz)![](https://lh6.googleusercontent.com/Uee-fb3QJewe05s4AWM2bF6b7MuRI8XgU9r3KfX72RNwVYYecjt5UX15vw1jhk0LoqvgL1MN5yKT5t9Mei6QzI7bohUAKtoQthG02YCr1VXiM4HFB-RRmQB29uuANQNDiq1sGKGe)![](https://lh6.googleusercontent.com/OXx7ZGSWDI5z2UnqunkcWtB1MWY5ZtXs3EmruVAqfZo4JiLzhd00hmRkKZi_y2Icv6FV4CJRJW68HK1laKNXCKnGI5A9Z1l53R1BtOiM6dLzjDvecuWLgzPIgir3Q89qxkHt50yo)![](https://lh4.googleusercontent.com/LUlB3APRP1t0gEEzaXmPbUxZFKGD1nVHRtdNMoKp7iSTLAZAHXOF3W_VPaZs9-XsLdw54GC2TnjnxGyR_spqek8X5ZLFkWICZpP4oXEzATj4n_vfvLQtr0FNceiT3lKzGKg7oh1f)![](https://lh4.googleusercontent.com/AZP7UsS_i0gXvSBRuoDas6D48cBdU9JD3N39C53YEIdJwXARCyEg2sXRSuvOGUSa07o0xZ2UzQc8mLgZxj6EQm8uRLZ3JXVDzEwx6kTT3Vq-eia5OV865zc0q3bq3htEDZxUiIX1)![](https://lh4.googleusercontent.com/GkXUs0HYRwS66hSMex7NDDT6Ck0NaxO4VrIHW23GzjrQbRMWDDA4EGwIOwSsg3O8tL_iNuISRywMDuF1u61rZm4fzaBisfUkyo-aPIcCcTk3KwUPunnPwgrV6-oRca0td-eYHxss)![](https://lh3.googleusercontent.com/EPOoqoV_b11WJCV9cNJFgAtGfuRyqF3xZpKKoJ46J54wNsrE0kFFp82WFZn_gRoRTSLYPAkFHdFcizdOOBYwk_pL6pUZiy9ld24o-xBHIJZWcLmz_tMSFav77_9fbc2pPbwgnObR)![](https://lh5.googleusercontent.com/cbuvmjdXzUEgiSf6BL6jC3-TKAbwf1WASiNfypDXQcmeXLrr6OPhITsEjeEUo1dXtg3OW3YTPNez3XxjaRxeAV_Ox6dTq9XpbwNDqh2-iWiXqWhrgn2o1VIe45xKPGYsxxPluLkw)![](https://lh5.googleusercontent.com/wskI0Jy2g9icXoitcNDIp9VChhWlxu9fIDwepnqd0ds_Oq1m8Yt7ZHY8GZ_DvfS8IQcNfsJyBanCPIpp_GUznnzK3b3YBP7F2oV9gsi9k9WyKfwmWGCI4um2SKeNveXy2uaeD-sd)![](https://lh5.googleusercontent.com/zeDLw8eZvkjgSfWnUwOkIG_Ze3GmKAwrTH59o37K8XEMXDMcAOtUsOSzfEwP8qF7qgVHEbgCs6YbXyE9loDTZOX4q5JeRe2J4JMMufrD0H6wr-ADk9sMBzRRwgi3iRVjhTCLh0Uy)\n\n### **Check-out the popular hashtags :**\n\n[#next18](https://twitter.com/search?q=next18)[#googlenext18](https://twitter.com/search?q=googlenext18)[#knative](https://twitter.com/search?q=knative)[#kubernetes](https://twitter.com/search?q=kubernetes)[#istiomesh](https://twitter.com/search?q=istiomesh)\n\nAlso check out the keynotes:Keynotes from last week’s[ #GoogleNext18](https://twitter.com/hashtag/GoogleNext18?src=hash) here →[ http://g.co/nextonair](https://t.co/mVuwk0hw4i)\n","slug":"recap-of-google-next18"},{"id":12,"title":"Designating OpenEBS pods to run on specific K8S Nodes","author":"Ajesh Baby","author_info":"Product Manager at MayaData","date":"30-07-2018","tags":["Openebs","Kubernetes","Solutions","Scheduler","Scheduling"],"content":"\nOpenEBS does not have a separate scheduler used to manage scheduling pods. Instead, it uses the Kubernetes scheduler for managing the scheduling needs of an administrator. Kubernetes provides the following methods for controlling the scheduling pods on cluster nodes:\n\n- [nodeSelector](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector)\n- [Taints and Tolerations](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)\n\nFor more details and information about these features, you can refer to the Kubernetes documentation.\n\nIn this post, I would like to cover the different aspects of how to restrict/control the OpenEBS pods scheduling to a set of specific nodes in the Kubernetes cluster.\n\nOpenEBS deals with many types of Kubernetes pods throughout its life cycle. These can be broadly categorized into two types, control plane pods and data plane pods. Control plane pods are installed as part of installation of the following OpenEBS components:\n\n- OpeEBS API Server\n- OpenEBS Provisioner\n- OpenEBS Snapshot Controller\n\nData plane pods are installed as part of volume provisioning:\n\n- Target Pod\n- Replica Pods\n\nFor details on the exact steps of scheduling, see the configuration section [here](https://docs.openebs.io/docs/next/scheduler.html?__hstc=216392137.e7b2938c542eaf0f98426e5d8be4aa84.1579859056424.1579859056424.1579859056424.1&__hssc=216392137.1.1579859056424&__hsfp=3765904294).\n\nUse case: Let’s consider a scenario in which you have 20 nodes named Node1, Node2 ... Node20. You may want to designate Node1, Node2, Node3 as storage nodes so that all storage pods are scheduled only on these nodes.\n\nSolution: You can use Kubernetes scheduling methods to achieve this. Below are some of the possible options and their effect on scheduling pods to respective nodes.\n![](/content/images/2020/01/storage-pods.png)Storage Pods\nYou may select and use any of the above options based on your unique requirements.\n\nOption 2 does not necessarily guarantee storage pod scheduling on Node1, Node2 and Node3.\n\nOption 1, Option 3, and Option 4 will limit the scheduled OpenEBS pods to Node1, Node2 and Node3. Option 3 is my preferred choice, for the following reasons:\n\n- Other application pods will not be scheduled on my storage nodes, whereas Option 1 does present the possibility of other application pods being scheduled on Node1, Node2, and Node3.\n- While scaling the cluster for application deployments, I do not have to worry about changing the policy for storage. If I use option4, I must taint the new nodes with respective applications.\n- In this scenario, I am worried only about storage nodes, as these have local disks attached to them. I am not restricted to schedule an application pod deployment on any nodes other than storage nodes.\n","slug":"designating-openebs-pods-to-run-on-specific-k8s-nodes"},{"id":13,"title":"OpenEBS 0.6 serves IOs amidst Chaos and much more","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"20-07-2018","tags":["DevOps","Kubernetes","Openebs","Statefulcontainers","Storage"],"content":"\nWe are very excited to announce the availability of OpenEBS version 0.6. I would like to take a few minutes to talk about what has been keeping us busy in making it GA. We have been making a number of additions to both the design and code in the last few months. In this blog I’ll talk about:\n\n- Quality leveraging Chaos Engineering\n- Framework (CAS Templates) for supporting multiple storage engines\n\nI won’t talk about our new Storage Engine (cStor) — written in C — which is _almost_ ready. I’ll save that for a later blog.\n\nBefore going into specifics, I would like to express my sincerest gratitude to the OpenEBS community users and developers who are helping to make OpenEBS the most simple and easy to setup containerized attached storage (CAS) solution available for Kubernetes today — and the most popular open source one as well.\n\nSince the OpenEBS 0.5 release we have seen so many ways users have deployed OpenEBS many of which we had not envisioned when we started OpenEBS back in 2016. We are working hard to listen to the growing user community — and of course MayaOnline is helping us a bit as well as we learn something from MayaOnline users who are using this free SaaS monitoring and ChatOps integration of their stateful workloads. Along these lines, we have a survey that is running through the end of July that takes 2–3 minutes that has proven helpful; please do fill it out if you have not already and we will even send you some swag: [https://www.surveymonkey.com/r/BRDCCWY](https://www.surveymonkey.com/r/BRDCCWY)\n\nThe timing of OpenEBS 0.5 was perfect in that it coincided with a take-off in interest in stateful workloads on Kubernetes. Some deployment patterns I’ve encountered just in the last few weeks include:\n\n- GitLab for internal IT teams\n- Kube weekly just featured a step by step blog on this subject: [https://blog.openebs.io/git-freedom-on-kubernetes-3a491dd37cdf](https://blog.openebs.io/git-freedom-on-kubernetes-3a491dd37cdf)\n- Data Science training sessions\n- Here we are seeing hundreds of pods with stateful workloads spun up and destroyed repeatedly — really a great use case for container attached storage\n- Running Minio on OpenEBS which some users have called a happy marriage between OpenEBS block and Minio S3\n- We remain huge fans of Minio and are looking forward to more community led collaboration with our almost neighbors\n- OpenEBS being deployed as a basic part of DBs on kubernetes; in particular we are seeing a good amount of NuoDB on OpenShift for example\n- The elastic SQL technology of NuoDB seems to resonate with lots and lots of users; we’re pretty proud that using OpenEBS underneath is becoming a common pattern\n- And of course many Containers as a Service offerings now include OpenEBS as a default option with more to be announced shortly\n\nAnd all this adoption means heterogeneity and dynamism.\n\n## Challenge 1: Kubernetes is resilient amidst Chaos and so must be storage\n\nBecause OpenEBS is deployed on so many varieties of Kubernetes and our fundamental job is to keep the data safe no matter what — we have been investing heavily in our ability to create these varied environments and their behaviors and to then measure and validate the resilience of OpenEBS as these environments respond to outages and increased load and so forth. We are seeing OpenEBS deployed across lots of varieties including:\n\n- Native Kubernetes or using Rancher, OpenShift, IBM Cloud Private, GKE, Tectonic, StackPoint Cloud, and others\n- Operating Systems -Ubuntu, CentOS, CoreOS and others\n- Pod Networking of all types, with Flannel being a favorite\n- Various cloud services — AWS EC2 remains the preferred option, with GCE growing in adoption amongst OpenEBS users\n\nEach combination comes with nuances that are unique and sometimes annoying as well. For example, recently a user on a Cloud Provider saw their nodes shut down frequently and occasional high network latency or packet drops in inter pod networking. Anyone with experience working with Storage Systems knows how detrimental these situations can be for latency-sensitive Stateful Applications.\n\nWe consciously chose the well-understood and widely used iSCSI protocol as the underlying storage connectivity used by Applications to connect to OpenEBS Volumes. There are many benefits to this architecture, but I will not address those here.\n\nThere are some annoying pieces when running iSCSI at scale as well. For example, depending on the response from the iSCSI targets and your operating system, there are some quirky things that can happen with iSCSI. The most notorious of these happens when iSCSI backed volumes move into read-only if you are using ext4 under certain conditions. You must then go through the steps for manually recovering the volumes. To address this, we have put together a troubleshooting guide that you can access [here](https://docs.openebs.io/docs/next/readonlyvolumes.html?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294).\n\nHowever, we wanted to solve as many of these issues as possible with the right approach. We stepped up our use of chaos engineering in our OpenEBS development process. We also extended and open sourced our in-house tooling, and we are starting to see it used more and more by engineers deploying stateful workloads on Kubernetes — whether or not OpenEBS is the underlying storage.\n\n## Solution : Chaos Engineered OpenEBS, the birth of Litmus.\n\nIf you would like an introduction to the Litmus project, which we open sourced at KubeCon in Denmark, visit the following link: [https://openebs.io/litmus](https://openebs.io/litmus?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294) or [https://github.com/openebs/litmus](https://github.com/openebs/litmus)\n\nWe are also working on operators to add additional autonomic function into OpenEBS, leveraging improved metrics and advancements in CSI around node daemonsets and the mount-propagation feature. In the meantime, we use Litmus to increase automated real-world scenario testing to ensure improvements in every release. In this regard, a lot of effort has gone towards beefing up the tests that can simulate Chaos at Node, Network, Storage, RAM, and CPU. These typically contribute to Volume Pods switching nodes and, if not careful, interrupted IOs.\n\nOf course, this Chaos for Storage Application is something we believe should be applied to stateful workloads and underlying storage both during testing and as a part of a healthy chaos engineering practice. This is what led us to Open Source Litmus.\n\nOne outcome of our improved chaos engineering and testing is improvements to the resiliency of intra OpenEBS deployment communication. Specifically, we added enhancements to the responses sent by the iSCSI Target to the initiator; overall, this makes OpenEBS more resilient even when Pods are rescheduled unexpectedly and when the environment otherwise changes. You can learn more about these issues in the [release notes](https://github.com/openebs/openebs/releases/tag/v0.6).\n\nWe expect that the incidence of read-only issues will decrease greatly for the tested scenarios. We are constantly adding more scenarios, workloads and other tooling into Litmus to bolster the Jiva storage engine and other engines to come. Contributions to Jiva are of course always welcome!\n\n## Challenge 2: The evolving state of the State in Kubernetes!\n\nIf you regularly monitor storage developments, you will notice that Kubernetes is moving towards CSI and Snapshots are beginning to become a standard. There are enhancements to support Block Volumes and Topology aware Scheduling for Stateful Applications powered by Local PVs, which also benefits other PV types like OpenEBS.\n\nTo give an example, OpenEBS strongly prefers the case when the OpenEBS Controller Pod (and the application Pod) schedule on nodes where the OpenEBS Replica Pod resides. Currently, we achieve this via Pod/Node Affinity parameters. However, with Topology Aware scheduling, the constructs of pinning are efficiently done via the PV topology parameters.\n\nThat is just one example of new capabilities that we must now embrace. Features in Kubernetes now transition “quickly” from alpha to beta and the new paradigms/patterns that enter into Kubernetes must be adopted, or you will soon become outdated like the Third Party Resources (TPRs). However, we are not complaining about the pace of progress and continually contribute upstream to Kubernetes itself. We always seek to lend a hand to make Kubernetes an even better platform for storage and stateful workloads.\n\nNonetheless, the challenge remains. After all, the core of the Orchestration layer in OpenEBS is to deploy and operate the Container Attached Storage solution using Kubernetes native constructs. And the constructs just keep changing!\n\nLooking at the situation, we decided to step back and think about an architecture that would allow us to minimize the need to make code changes every time Kubernetes changes. For example, some users want to deploy their OpenEBS by specifying Pod Disruption Budges (PDBs) or setting specific Resource Limits for PVs in certain namespaces/users etc. We wondered: how can we embrace these new knobs, settings, and advances without endless code churn? This type of work — effectively upgrading the transmission of the underlying orchestration of OpenEBS — is not easy to do unless you really understand the architecture of OpenEBS. That’s not good — what’s the point of being open source if the code itself is too hard to work with and adjust? Fortunately, Kubernetes has CRDs, which provides a way forward.\n\n## Solution : Provide templates to Cluster Owners to define and manage the storage infrastructure.\n\nIn the OpenEBS 0.6 release, we have utilized the power of Kubernetes CRDs to provide a workable solution to introduce pluggable storage engines. OpenEBS now provides a complete workflow for developers and cluster administrators to choose the right storage software and hardware for their unique requirements. The control of the storage infrastructure stays with the cluster owner, and the ability to address a given need in storage lies with the developer. OpenEBS 0.6 brings the initial version of CAS Templates, which are YAMLs that can be scripted by cluster owners, fit into your GitOps, and are associated with Storage Classes.\n\nWe like the way OpenEBS CAS Templates are shaping up, and we can see many of the cluster owners’ needs being met over time, including enforcing of policies using tools like OPA. I will share more on this in upcoming blogs, but you can glance at them by reading this introductory documentation [here](https://docs.openebs.io/docs/next/storageengine.html?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294). We intend to build upon this improved architectural pattern to do even more than the pluggability of storage engines. As always, we would especially welcome your feedback and use cases.\n\n### And there is more…\n\nYou will notice when you look at the release notes or try OpenEBS 0.6 that there are many other enhancements, including:\n\n- Configuring of OpenEBS for running stateful workloads that span across Availability Zones\n- Enabling the management of Snapshots and Clone from kubectl\n- Enhancement to mayactl to display volume status\n- Improved Integration and Unit Testing coverage\n- Enhanced Contributor Guides\n\nAnd, most importantly, product documentation has been overhauled to provide accessible insights about OpenEBS as well as a process to provide feedback.\n\nAs mentioned above, our next release also enables users to try out _cStor — a storage engine_ that is more efficient in terms of performance and capacity management. It also reduces the number of containers required to run OpenEBS. If you are interested in taking a look, please get in touch as we have some alpha users of cStor now.\n\nWith its strong community of users, developers, and partners building us into their solutions, it feels like OpenEBS is nearly unstoppable. As always, we look forward to your feedback and suggestions on this release and the direction that you want to see OpenEBS move going foward. Please reach out to us on Slack or add comments below. [https://slack.openebs.io](https://slack.openebs.io/?__hstc=216392137.386b1bc3a48de21192b74b07a4e27366.1580120418429.1580120418429.1580120418429.1&__hssc=216392137.1.1580120418429&__hsfp=3765904294)/\n\nFinally, if you have not done so yet, claim your free access to [MayaOnline](https://mayaonline.io/). You will be surprised by how easy it can be to visualize and manage your storage needs.\n\n[Public domain](https://creativecommons.org/publicdomain/mark/1.0/).\n","slug":"openebs-06-serves-ios-amidst-chaos-and-much-more"},{"id":14,"title":"How do I run a litmus test to compare storage performance on Kubernetes","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"16-07-2018","tags":["Benchmarking","Kubernetes","Litmus","Openebs","Solutions","Chaos-Engineering"],"content":"\nThis article belongs to a #HowDoI series on Kubernetes and Litmus\n\nEver so often, developers and devops engineers building or managing stateful applications on Kubernetes are on the lookout for for suitable storage options which serves their application’s specific needs. The emphasis could be on high-availability, provisioning ease, performance etc.., **Litmus **(as detailed in this [article](https://blog.openebs.io/litmus-release-a-chaos-monkey-on-your-kubernetes-stateful-workloads-6345e01b637d)), is an attempt to arm them with the necessary info to make the right choice. One of the important storage tests is to simulate application workloads or multiply its effect using synthetic workload generators like fio. In this article, we list the steps to run a fio-based benchmark test using litmus\n![](https://cdn-images-1.medium.com/max/800/1*zRIZ9WjL7S0wq6Sp_IbzCw.png)Evaluating storage performance w/ Litmus\n\n## PRE-REQUISITES\n\n- At least a single-node Kubernetes cluster with the necessary disk resources, mounted on the node. (**_Note_**: _Certain storage solutions need minimum Kubernetes versions from which they are supported. For ex: Local PVs are beta from 1.10, OpenEBS needs 1.7.5+_)\n- Storage operator installed (typically, this includes control-plane elements like the static/dynamic provisioners, storage classes and other elements) with appropriate references to the node & disk resources (**\\*For example\\*\\***: This may involve storage pool creation OR updating disk and node details in the static provisioners etc.,\\*)\n\n## STEP-1: Setup Litmus essentials on the Kubernetes cluster\n\n- Obtain the Litmus Git repository via a Git Clone operation on the Kubernetes master/Control machine used to manage cluster & set up the Litmus namespace, service account & clusterrolebinding by applying _rbac.yaml_\n\n  karthik_s@cloudshell:~ (strong-eon-153112)$ git clone https://github.com/openebs/litmus.git\n\n  Cloning into 'litmus'...\n\n  remote: Counting objects: 2627, done.\n\n  remote: Compressing objects: 100% (16/16), done.\n\n  remote: Total 2627 (delta 2), reused 9 (delta 2), pack-reused 2609\n\n  Receiving objects: 100% (2627/2627), 10.50 MiB | 4.23 MiB/s, done.\n\n  Resolving deltas: 100% (740/740), done.\n\n  karthik_s@cloudshell:~ (strong-eon-153112)$ cd litmus/\n\n  karthik_s@cloudshell:~/litmus (strong-eon-153112)$ kubectl apply -f hack/rbac.yaml\n\n  namespace \"litmus\" created\n\n  serviceaccount \"litmus\" created\n\n  clusterrole \"litmus\" created\n\n  clusterrolebinding \"litmus\" created\n\n- Create a configmap resource out of the cluster’s config file, typically at _~/.kube/config_, _/etc/kubernetes/admin.conf_ or elsewhere depending on the type of cluster or setup method (**\\*Note\\*\\***: Copy the config file to admin.conf before creating the configmap out of it, as the litmus job expects this path\\*)\n\n  karthik_s@cloudshell:~ (strong-eon-153112)$ kubectl create configmap kubeconfig --from-file=admin.conf -n litmus\n\n  configmap \"kubeconfig\" created\n\n## STEP-2: Update the Litmus test job as per need\n\nThe litmus fio test job allows the developer to specify certain test parameters via ENV variables, such as the following:\n\n- The litmus fio test job allows the developer to specify the storage provider (PROVIDER_STORAGE_CLASS) and the node on which to schedule the application. (APP_NODE_SELECTOR)\n- The desired fio profile can also be specified. Currently, litmus supports simple [test-templates](https://github.com/ksatchit/litmus/tree/fio_test/tools/fio/templates), and is expected to grow to include multiple standard profiles. (FIO_TEST_PROFILE)\n- Certain simple test parameters such as the size of the test file (FIO_SAMPLE_SIZE) and duration of I/O (FIO_TESTRUN_PERIOD) can be specified as well, while the core I/O params continue to be housed in the templates.\n- The developer can choose to specify a comma-separated list of pods whose logs need to be collected for analysis of results, as well as the logs’ location on the host in the spec for the logger.\n\n  karthik_s@cloudshell:~ (strong-eon-153112)$ cd litmus/tests/fio/\n\n  karthik_s@cloudshell:~/litmus/tests/fio (strong-eon-153112)$ cat run_litmus_test.yaml\n\n  ***\n\n  apiVersion: batch/v1\n\n  kind: Job\n\n  metadata:\n\n  name: litmus\n\n  namespace: litmus\n\n  spec:\n\n  template:\n\n       metadata:\n\n         name: litmus\n\n       spec:\n\n         serviceAccountName: litmus\n\n         restartPolicy: Never\n\n         containers:\n\n         - name: ansibletest\n\n           image: openebs/ansible-runner\n\n           env:\n\n             - name: ANSIBLE_STDOUT_CALLBACK\n\n               value: log_plays\n\n\n             - name: PROVIDER_STORAGE_CLASS\n\n               value: openebs-standard\n\n\n\n             - name: APP_NODE_SELECTOR\n\n               value: kubeminion-01\n\n\n             - name: FIO_TEST_PROFILE\n\n               value: standard-ssd\n\n\n             - name: FIO_SAMPLE_SIZE\n\n               value: \"128m\"\n\n\n             - name: FIO_TESTRUN_PERIOD\n\n               value: \"60\"\n\n\n           command: [\"/bin/bash\"]\n\n           args: [\"-c\", \"ansible-playbook ./fio/test.yaml -i /etc/ansible/hosts -v; exit 0\"]\n\n           volumeMounts:\n\n             - name: logs\n\n               mountPath: /var/log/ansible\n\n           tty: true\n\n         - name: logger\n\n           image: openebs/logger\n\n           command: [\"/bin/bash\"]\n\n           args: [\"-c\", \"./logger.sh -d 10 -r fio,openebs; exit 0\"]\n\n           volumeMounts:\n\n             - name: kubeconfig\n\n               mountPath: /root/admin.conf\n\n               subPath: admin.conf\n\n             - name: logs\n\n               mountPath: /mnt\n\n           tty: true\n\n         volumes:\n\n           - name: kubeconfig\n\n             configMap:\n\n               name: kubeconfig\n\n           - name: logs\n\n             hostPath:\n\n               path: /mnt\n\n               type: Directory\n\n## STEP 3: Run the Litmus fio test job.\n\nThe job creates the Litmus test pod, which contains both the test runner as well as the (stern-based) logger sidecar. The test runner then launches an fio test job that uses a persistent volume (PV) based on the specified storage class.\n\n    karthik_s@cloudshell:~/litmus/tests/fio (strong-eon-153112)$ kubectl apply -f run_litmus_test.yaml\n\n    job \"litmus\" created\n\n## STEP 4: View the fio run results.\n\nThe results can be obtained from the log directory on the node in which the litmus pod is executed (By default, it is stored in _/mnt_). The fio & other specified pod logs are available in a tarfile (\\_Logstash*<timestamp>*.tar\\_\\_).\n\n    root@gke-oebs-staging-default-pool-7cc7e313-bf16:/mnt# ls\n\n    Logstash_07_07_2018_04_10_AM.tar  hosts  systemd_logs\n\nThe fio results are captured in JSON format with job-specific result sections. Below is a truncated snippet reproduced from the log for a sample basic rw run:\n\n    {\n      \"jobname\": \"basic-readwrite\",\n      \"groupid\": 0,\n      \"error\": 0,\n      \"eta\": 0,\n      \"elapsed\": 61,\n      \"read\": {\n        \"io_bytes\": 28399748,\n        \"bw\": 473321,\n        \"iops\": 118330.31,\n        \"runtime\": 60001,\n        \"total_ios\": 7099937,\n        \"short_ios\": 0,\n        \"drop_ios\": 0,\n        \"slat\": {\n          \"min\": 0,\n          \"max\": 0,\n          \"mean\": 0,\n          \"stddev\": 0\n        },\n        \"write\": {\n          \"io_bytes\": 28400004,\n          \"bw\": 473325,\n          \"iops\": 118331.38,\n          \"runtime\": 60001,\n          \"total_ios\": 7100001,\n          \"short_ios\": 0,\n          \"drop_ios\": 0,\n          \"slat\": {\n            \"min\": 0,\n            \"max\": 0,\n            \"mean\": 0,\n            \"stddev\": 0\n          }\n        }\n      }\n    }\n\n## CONCLUSION\n\nHow is this different from doing an fio package installation on the kubernetes nodes and running tests?\n\n- Running an fio kubernetes job will offer better control to simulating actual application loads when used with resource limits.\n- The litmus fio jobs with various profiles can be included as part of a larger suite using the executor framework, thereby obtaining results for different profiles.\n- Litmus (as it continues to mature) will provide jobs that perform Chaos tests against storage while running different types of workloads. Running a fio job lends itself to that model.\n- Finally, it is a more “Kubernetes” way of doing things!\n\nLet us know your experience with using fio-based performance tests with Litmus. Any feedback is greatly appreciated!\n","slug":"how-do-i-run-a-litmus-test-to-compare-storage-performance-on-kubernetes"},{"id":15,"title":"Kubernetes storage extensions to Weave Scope","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"28-6-2018","tags":["Open-Source","Weave-Scope","Node-Disk-Manager","Persistent-Volume","Kubernetes"],"content":"\nIt was in Austin KubeCon 2017 that I first got a deep look at Weave Scope, and could not stop falling in love with it. The visualisation Scope provides into Kubernetes resources is simply amazing. It greatly simplifies the tasks of an Administrator in dealing with the clutter of Kubernetes components and helps directly go to the component of interest and start observing and managing it.\n\nBeing tasked with the goal of simplifying storage management for Kubernetes, my immediate thought was, why can’t we use Scope for Kubernetes storage? Of course, storage in Kubernetes is a developing area and new features are always coming but the existing adoption of Kubernetes persistent storage volumes(PVs) concept was already pretty large and we thought it warranted extensions to Scope to include PVs.\n\nSo we got to and with the help of [Alexis](https://twitter.com/monadic) and the Weave team — we started coding!\n\nWe set out multiple milestones for this journey:\n\n- The first one — get the persistent volumes (PVs), persistent volume claims (PVCs) and Storage Classes (SCs) into Scope\n- The second one — add snapshot/clone support and start monitoring the volume metrics\n- The third one — bring in the disk or SSD or similar as a fundamental resource that is being managed by the Administrator just like they might want to sometimes take a look at CPU and Memory\n\n## Persistent Volumes (PVs)\n\nMost of the time, Persistent Volume Claims (PVCs) are the entry points to increasing the storage. The number of PVCs will be about the same as the number of pods, or slightly less in a reasonably-loaded Kubernetes cluster. The administrator will benefit from having visibility of which POD is using which PVCs and the associated storage classes and PVs. This is especially true if they are using the storage capacity of the Kubernetes clusters themselves. Adding this visibility is precisely is what we did to start.\n![](/content/images/2020/01/pvc-pv-sc-pod.png)PVC-PV-SC-POD Relationship on Scope\nYou can see this new visibility in Scope by using the newly-created filter “Show storage/Hide storage” under the PODs section. This filter puts the storage components in perspective with the remaining pods and associated networked-data connections. Users can **Hide storage** when not interested, or to reduce clutter.\n\nWe received an enthusiastic welcome to the Scope community from the Weaveworks team. We also found encouragement from [Alexis](https://twitter.com/monadic) and plenty of technical help from [Bryan](https://twitter.com/bboreham) at Weaveworks. The first pull request (PR) was really about adding PV, PVC and Storage Class support, and was merged into the Weave Scope master recently ([https://github.com/weaveworks/scope/pull/3132](https://github.com/weaveworks/scope/pull/3132) ).\n![PV-PVC-SC Integration into Scope](https://blog.mayadata.io/hubfs/0_iYXgl-m8oxyXVs1s.gif)PV-PVC-SC Integration into Scope\n\n## Future work:\n\n### Snapshots and Clones\n\nCI/CD pipelines are the most active areas in which DevOps are finding stateful applications on Kubernetes to be immediately applicable. Storing the state of a database at the end of each pipeline stage, and restoring them when required, is a commonly performed task. The state of the stateful application is stored by taking snapshots of its persistent volumes and is restored by creating clones of persistent volumes. We believe that offering visibility and administrative capabilities to manage snapshots and clones in Scope is a natural next step.\n\n### Disk Management and Monitoring\n\nHyper-converged Infrastructure (HCI) has yet to find its rhythm with Kubernetes, largely due to a lack of fully-developed tools for disk management and monitoring. Kubernetes now has a well-accepted method to provision and manage volumes and attach them to disk management. Therefore, the enabling of HCI for Kubernetes will be improved by new tools such as [Node Disk Manager (NDM)](https://github.com/openebs/node-disk-manager), to which, incidentally (humble brag), we are also contributing. With Disk being the fundamental component for storage and the main participant in the chaos engineering of storage infrastructure, it helps to have it visualised and monitored in a proper way. In large Kubernetes clusters (100+) nodes, the disks will be in the thousands. Scope’s resource utilisation panel is a powerful tool that brings in the visibility of CPU and Memory utilisation at the Host, Container and Process level. This is a natural extension to add Disk Capacity, Disk performance (IOPS and throughput) to this resource utilisation tool. Our view is shown in the figure below, that Disk performance can be added.\n\n![Current View of the Resource Utilisation Tool on Scope](https://blog.mayadata.io/hubfs/0_9SozVWeQ2F69fDQO.gif)\nCurrent View of the Resource Utilisation Tool on Scope\n\nAnother important aspect of disk management is simply browsing from the application volume all the way to the disk where the data is stored. It is not possible to locate the actual disk of a persistent volume if the underlying storage is a cloud-disk such as EBS or GPD, but if it is a Kubernetes local PV or OpenEBS volume, the volume data vs. physical disks relationship can be identified. This will be useful while managing the hyper-converged infrastructure on Kubernetes.\n\n![(Future work) PODs/Disks and Nodes Relationship at Scope](https://blog.mayadata.io/hubfs/0_WJA8ii6NlaBoS94H.gif)\n(Future work) PODs/Disks and Nodes Relationship at Scope\n\nThe above screens are a dirty implementation on a dev branch that is still in process. However, it provides a good, quick glimpse of how a POD’s volume is linked to the associated disks.\n\n_Weaveworks team recently started community meetings led by [Fons](https://twitter.com/2opremio), and it appears to be a great beginning of broader community involvement into the development of Scope. You can access the public meeting notes at_\n\n_[https://docs.google.com/document/d/103_60TuEkfkhz_h2krrPJH8QOx-vRnPpbcCZqrddE1s/edit?usp=sharing](https://docs.google.com/document/d/103_60TuEkfkhz_h2krrPJH8QOx-vRnPpbcCZqrddE1s/edit?usp=sharing)_\n\n## Summary:\n\nWeave Scope is a very useful tool for Kubernetes administrators for visualising and basic administration. With the addition of extensions being added, and a wider community being formed, Scope’s adoption will certainly increase and benefit the Kubernetes eco-system. We are looking forward to being an active contributor to this excellent visualisation tool.\n\nPlease provide any feedback here or in the next Scope community meeting. We will be there!\n\nThanks to [Akash Srivastava](https://medium.com/@srivastavaakash?source=post_page) and [Satyam Zode](https://medium.com/@satyamz?source=post_page).\n","slug":"kubernetes-storage-extensions-to-weave-scope"},{"id":16,"title":"OpenEBS announces the availability of version 1.0","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"24-06-2018","tags":["Cncf","Kubernetes","Openebs","Storage"],"content":"\nCongratulations and thanks to each one of you from the OpenEBS community for reaching this significant milestone!\n\nIn this blog, I will touch upon what I have learned from users about Open Source CAS solutions like OpenEBS at KubeCon EU 19, followed by a quick note on the major changes in 1.0 and what is in the immediate roadmap.\n\nBeing an active member of the OpenEBS Slack channel and from the usage statistics, I was cognizant of the vibrant user community. For instance, a recent usage report generated by MayaData since 0.8 was released, OpenEBS is running on — 340 different flavors of Operating Systems, 90 different flavors of Kubernetes and across 75 different countries.\n\n![](https://cdn-images-1.medium.com/max/800/0*QKRCQN6eguXuHH6u)\n\nKubeCon EU 19, was by far the most interesting for me — to interact with some of the above users who are already running OpenEBS in production or in the process of evaluation. For those of you, curious about the kind of views expressed from users and the partner community about OpenEBS and Kubernetes Storage at large, here are some interesting ones:\n\n**Feedback from Users running OpenEBS in production. **The choice to adopt OpenEBS was made after evaluating and comparing other available solutions as can be seen from several stories shared by the users:\n![](/content/images/2020/01/slack-snnipets.png)User feedback about adoption of OpenEBS\nThis growing adoption is attributed to the following:\n\n- The major one being the architectural superiority of using Kubernetes to build highly portable distributed systems — and **not locking** all the applications into a single point of failure — by making them write into storage system run by some other group or provider. OpenEBS helps to build a storage solution where each application gets its own storage controllers. This is a perfect validation of the Container Attached Storage Category, which is explained in more detail at a [CNCF Blog](https://www.cncf.io/blog/2019/05/16/a-year-later-updating-container-attached-storage/).\n- Containerized distributed applications are much smarter than their legacy server-based counterparts and these new containerized applications don’t have the same dependency on the storage system as before. What applications need are **ala-carte** of Storage Solutions that OpenEBS offers as Storage Engines. Depending on the application needs, cluster administrators can decide what components of OpenEBS are really deployed. For example — does the cluster need to only have Local PVs or a full-fledged storage solution like cStor.\n- Of course the fact the OpenEBS itself is completely developed in user space and just runs on any platform easily. **No kernel taints required.** Yes, currently with 1.0 — there is a performance hit, but there are enough use cases where the current performance is good enough.\n\nWords just can’t express the joy of hearing directly from users on how OpenEBS has helped them. It is just amazing to see the diversity of users as well; from universities to financial corporations, startups to enterprises, fresher to seasoned SREs.\n\nPersonally, the most humbling moment for me at the KubeCon EU 2019, was when an end-user approached me just to thank for the efforts we have put into OpenEBS. He works at a University as a SysAdmin and he mentioned that using OpenEBS — he is able to spin up a self-contained Kubernetes Cluster with host storage that can be used by the stateful applications. This has helped in the number of support calls he receives from the University IT department when rolling out Stateful Applications that needed some hand-holding to provide the PVs.\n\nA similar sentiment is being expressed by large enterprises where the Infra team is supposed to roll out services to 100s of there application teams, in a more agile and uniform way than before. Some of the enterprises run Big Data pipelines at mammoth scale and have found OpenEBS to contains the right set of abstractions that can be extended and used.\n\n**Feedback from the growing community and partner ecosystem** that comprises of individual contributors, home users, enterprise solution architects, technology enthusiasts to hardware vendors included:\n\n- Solution Architects, DevOps, SREs >> I have put together a few scripts to make backups and restores with the Velero plugin for cStor volumes a little easier, since there are some parameters to remember and some additional steps required for both backups and restores other than using the basic Velero commands. I created a tool for [velero openebs](https://github.com/vitobotta/velero-openebs-backup) — with a few notes in a comment, in case anyone is interested\n- Storage Solution Engineers >> Hey, I know OpenEBS was not meant for this — but I think I made some changes can now serve Volumes from Kubernetes Cluster to Virtual Machines. A custom SDS, if you will, that is developed using OpenEBS.\n- Storage Vendors >> We are a storage devices company and OpenEBS can be used to run in an optimized way and help us shift storage boxes.\n- Kubernetes Managed Service Providers >> It will be cool to have OpenEBS available via the Operator Hub/Marketplace.\n\nBy the way, it is hard to gauge how much of the above discussions were really made possible by OpenEBS becoming part of the CNCF family. However, a major shift that I have observed since becoming a CNCF project, is that both end users and partners are more forthcoming to share their stories and integrate OpenEBS into their portfolio. _For anyone considering donating their projects to CNCF, I highly recommend it**—**there is a steep learning curve that helps with Governance of the project, by just being part of the efforts to propose the project into CNCF._\n\nClearly, these days the discussions at KubeCon EU are not around What or Why OpenEBS? but around When a specific feature is going to be made available. While the top requests with regards to missing features were around CSI support, automation of the operations like — disk provisioning and capacity expansion and performance improvements — they were really not blocking users from running OpenEBS in production. There are lots of users out there, that have found the current performance offered by the OpenEBS Data Engines was good enough for their use cases, and they have gone ahead and implemented playbooks and tools for performing maintenance and monitoring operations.\n\nPost KubeCon, having known and also met in person some of these early adopters that are running OpenEBS in production with a set of home-grown solutions, we felt a sense of responsibility to release 1.0 at the earliest and promise to provide long term support on the current feature set. As we progress with implementing additional functionality around operators, CSI, supporting the latest from Kubernetes Storage, and so forth we are also making a commitment that the current version will be supported.\n\nHence, for 1.0 — we changed our gears a bit to focus on helping address the feedback received on the existing feature sets for all the three data engines now supported by OpenEBS and deployed in production- Jiva, cStor Data Engines and Local PV.\n\nSome significant changes in 1.0 are as follows:\n\n**Enhanced Lifecycle Management of Block Devices**. The component of OpenEBS — NDM — Node Disk Manager or Node (Storage) Device Manager as we call it now, has been enhanced to support Block Device Claim (BDC). A new NDM Operator has been introduced in 1.0, that helps to request and reserve a Block Device before using that for either creating Local PV or cStor Pool. NDM is also being used independently of OpenEBS Storage Engines, and the ability to claim a Block Device — similar to PVC — enables the sharing of the block devices without stepping on each other.\n\nBlock Device(BD) is a new CR — which is a preferred way to represent a storage device than a Disk CR ( which was used in earlier releases.) Disk CR are also present — to allow for backward compatibility. The cStor Data engines and Local PVs that typically use block devices have been enhanced to use BDC/BD in place of Disk.\n\nWhen a BDC is deleted, the BD is released. And before it can be claimed by another BDC, the NDM takes care of deleting the data that has been written from the previous consumer. The cleaner utility used is derived from the Kubernetes Local PV cleaner jobs.\n\n**Enhance the OpenEBS Local PV to be used with Block Devices.** In the previous release, we introduced Local PVs that can be used with a hostpath, in this release, we have added support to create a Local PV directly on a Block Device (discovered by NDM). The Block Device can either be a raw block device (Example: GPD) — in which case it will be formatted (Example: Local SSDs on GKE) with the requested filesystem type or already mounted block device.\n\nAlso included in this release are:\n\n- Bug fixes reported around the cStor and Jiva data engines that surface after running OpenEBS on nodes that experience frequent reboots.\n- Additional debugging tools for cStor and Jiva engines, jivactl being the significant one that will help with clearing up of older snapshots. This tool has to be used to clear older snapshots to avoid hitting a cap limit of 255 snapshots in older releases.\n- Added few more Prometheus monitoring metrics\n- Added several e2e tests and included more applications into the OpenEBS CI pipeline maintained by [MayaData](https://mayadata.io/) at [openebs.ci](https://openebs.ci/)\n\nFor detailed changes summary, please check the [OpenEBS 1.0 Changelog](https://github.com/openebs/openebs/wiki/Change-Summary----v1.0).\n\nPlease refer to the[ OpenEBS Documentation](https://docs.openebs.io/?__hstc=216392137.ed92f0691adfb1cbf08ea329504224a3.1580116629364.1580116629364.1580116629364.1&__hssc=216392137.1.1580116629364&__hsfp=3765904294) to get started.\n\nOpenEBS 1.0 — ships with multiple Data Engines to choose from depending on your application needs:\n\n- OpenEBS Jiva PVs — can be used if your kubernetes nodes don’t have the capability to add raw block devices, but have extra capacity available on the host filesystem. This is the first and the longest running in production with lots of Kubernetes tunables available like — to customize the location where data is saved, the specific nodes on which data needs to be replicated — within or across availability zones, setup the volumes for thin provisioning, and so forth.\n- OpenEBS cStor PVs — is the preferred option when your nodes have raw block devices. cStor Data Engine continues to be a preferred solution for use cases that require instant snapshot and clone of volumes.\n- OpenEBS Local PVs — best suited for applications that can do their own replication and require high performance. OpenEBS Local PVs can work with either hostpath or with block devices that are already attached to the nodes.\n\nThere are a lot of options available to customize from the type of block devices that can be used for OpenEBS volumes to customizing the resources allocated to the Storage Pods.\n\nOpenEBS has turned a new leaf in its journey by releasing version 1.0. Thank you for all the support and love that you have shown along this journey. We are forever more committed to learn from you and help you realize the Data Agility that Cloud Native promises to offer.\n\nOur immediate focus is on getting OpenEBS ready for CSI and enhancing the OpenEBS Operators — for managing the Day 2 operations like dealing with Kubernetes upgrades, ASG, expansion of cStor Pool capacity or migrating them to new nodes and so forth. Development on these items is being tracked in the Kubernetes style at [Product Planning Sheet](https://docs.google.com/spreadsheets/d/1bbphUqbxShBhgr1VHaEQUzIGMaJJacPNKc1ckNXU1QE/edit).\n\nThanks to CNCF, we have the following mailing lists to connect apart from the [Slack](https://openebs.org/community).\n\n- For OpenEBS project updates — subscribe to [https://lists.cncf.io/g/cncf-openebs-announcements](https://lists.cncf.io/g/cncf-openebs-announcements)\n- For interacting with other openebs users, you can either join the [Slack](https://openebs.org/community), raise issues on [Github](https://github.com/openebs/openebs/issues) or send an email to [https://lists.cncf.io/g/cncf-openebs-users](https://lists.cncf.io/g/cncf-openebs-users)\n\nAs always, I am eager to learn from you. Please hit me up on [twitter (@kiranmova)](https://twitter.com/kiranmova), [slack](https://openebs.org/community) or on here in the comments.\n\nThanks to [Murat Karslioglu](https://medium.com/@muratkarslioglu?source=post_page). [Public domain](https://creativecommons.org/publicdomain/mark/1.0/).\n","slug":"openebs-announces-the-availability-of-version-10"},{"id":17,"title":"Git freedom on Kubernetes","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"05-06-2018","tags":["DevOps","Git","Gitlab","Kubernetes","Openebs"],"content":"\n#### Steps to easily run GitLab\n\nAfter Microsoft announced the acquisition of GitHub, many developers raised concerns on social media about Microsoft’s history of unsuccessfully running the acquired businesses like Skype, Nokia’s handset business, Navision and other 150 companies (you probably haven’t noticed) they have swallowed up over the years.\n\nOther than keeping the developer’s life-support plugged, one of the biggest concern is that MS would use its power on GitHub repositories to analyze trends among software development in order to launch competing products. Fears that GitHub privacy may be in jeopardy have already led many developers to jump off the ship or consider alternatives. GitLab’s publicly available [status graphs](https://t.co/svpWpI0Rb2) show spikes of 70x increase in imported repositories (average 100 vs 7.5K), a validation of increased user apprehension.\n\nHere is one of the fastest way to get your private repository with Gitlab up and running on your Kubernetes environment — Let’s “**Make DevOps lifecycle private again**” ©\n\nCurrently, the easiest and recommended way to install GitLab on Kubernetes is using the [Gitlab-Omnibus](https://docs.gitlab.com/ee/install/kubernetes/gitlab_omnibus.html) Helm charts.\n\nGitlab-Omnibus deploys every feature a small deployment would require including the [Container Registry](https://docs.gitlab.com/ee/user/project/coThis year I have attended a number of tech events and in terms of size, organization, and especially the content — Next ’18 is so far my favorite.ntainer_registry.html#gitlab-container-registry), [load balancer (NGINX)](https://github.com/kubernetes/ingress/tree/master/controllers/nginx), [Mattermost](https://docs.gitlab.com/omnibus/gitlab-mattermost/), and [Runner](https://docs.gitlab.com/runner/).\n\n#### **Prerequisites**\n\nMinimum requirements for a multi-node cluster:\n\n**Hardware**\n\n- **Boot node:** 1x 1+ core(s) >= 2.4 GHz CPU, 4GB RAM, >=100 GB disk space\n- **Master node:** 1 or 3x 2+ cores >= 2.4 GHz CPU, 4+GB RAM, >=151 GB disk space\n- **Worker node:** 3x 2+ cores >= 2.4 GHz CPU, 4+GB RAM, >=100 GB disk space\n\nSince I’m not planning to run anything heavy, I’ll be using 3 nodes, and will install Master, Proxy, and Workers an all 3.\n\n**Software**\n\n- [Ubuntu 16.04 LTS](https://www.ubuntu.com/download/server) (RHEL 7.x is also supported)\n- Docker 1.12 to 17.03\n- Kubernetes 1.7+ Cluster (You can use [IBM Cloud Private 2.1.0.2](http://containerized.me/how-to-install-openebs-on-ibm-cloud-private/) or [Red Hat OpenShift Origin](http://containerized.me/how-to-install-openebs-on-openshift/))\n- [kubectl](https://github.com/kubernetes/kubectl)\n- Helm client\n- A [GitLab Omnibus](https://docs.gitlab.com/omnibus/) Pod, including Mattermost, Container Registry, and Prometheus\n- An auto-scaling [GitLab Runner](https://docs.gitlab.com/runner/) using the Kubernetes executor\n- [Redis](https://github.com/kubernetes/charts/tree/master/stable/redis)\n- [PostgreSQL](https://github.com/kubernetes/charts/tree/master/stable/postgresql)\n- [NGINX Ingress](https://github.com/kubernetes/charts/tree/master/stable/nginx-ingress)\n- [OpenEBS](https://github.com/openebs/openebs) persistent volumes for Data, Registry, Postgres, and Redis\n\nThe Kubernetes instructions described below using Helm are generic and should work on all other platforms.\n\n**Installing GitLab and OpenEBS using the Helm Chart**\n\nGitLab depends on stateful applications like Redis and PostgeSQL, and requires persistent volumes for its data and the registry. Here, I will simplify the storage provisioning using OpenEBS.\n\nFirst, install OpenEBS using the chart.\n\n    helm install — name ‘openebs-gitlab-test’ stable/openebs\n\nOptional: If you would like to customize your OpenEBS installation you can also use a copy of the [value.yaml](https://raw.githubusercontent.com/kubernetes/charts/master/stable/openebs/values.yaml) file from the OpenEBS chart and modify parameters listed [here](https://github.com/kubernetes/charts/tree/master/stable/openebs).\n\n    helm install — name ‘openebs-gitlab-test’ -f values.yaml stable/openebs\n\nNext, add the predefined storage classes.\n\n    kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-storageclasses.yaml\n\nThere are many ways to enable OpenEBS for use by GitLab. The fastest is by making one of the OpenEBS storage classes a default StorageClass:\n\nList available OpenEBS storage classes in your cluster.\n\n    murat@icpnode1:~$ kubectl get sc\n    NAME PROVISIONER AGE\n    openebs-cassandra openebs.io/provisioner-iscsi 18d\n    openebs-es-data-sc openebs.io/provisioner-iscsi 18d\n    openebs-jupyter openebs.io/provisioner-iscsi 18d\n    openebs-kafka openebs.io/provisioner-iscsi 18d\n    openebs-mongodb openebs.io/provisioner-iscsi 18d\n    openebs-percona openebs.io/provisioner-iscsi 18d\n    openebs-redis openebs.io/provisioner-iscsi 18d\n    openebs-standalone openebs.io/provisioner-iscsi 18d\n    openebs-standard openebs.io/provisioner-iscsi 18d\n    openebs-zk openebs.io/provisioner-iscsi 18d\n\nEither create your StorageClass or pick one of the predefined classes. _openebs-standard_ creates 3 replicas and is an ideal candidate here to be used for most of the stateful workloads. Let’s mark this StorageClass as default.\n\n    kubectl patch storageclass openebs-standard -p ‘{“metadata”: {“annotations”:{“storageclass.kubernetes.io/is-default-class”:”true”}}}’\n\nNo verify that your chosen StorageClass is indeed the **default**.\n\n    murat@icpnode1:~$ kubectl get sc\n    NAME PROVISIONER AGE\n    openebs-cassandra openebs.io/provisioner-iscsi 18d\n    openebs-es-data-sc openebs.io/provisioner-iscsi 18d\n    openebs-jupyter openebs.io/provisioner-iscsi 18d\n    openebs-kafka openebs.io/provisioner-iscsi 18d\n    openebs-mongodb openebs.io/provisioner-iscsi 18d\n    openebs-percona openebs.io/provisioner-iscsi 18d\n    openebs-redis openebs.io/provisioner-iscsi 18d\n    openebs-standalone openebs.io/provisioner-iscsi 18d\n    openebs-standard (default) openebs.io/provisioner-iscsi 18d\n    openebs-zk openebs.io/provisioner-iscsi 18d\n\nNext, we can install the GitLab-ce chart. It is recommended to save your configuration options in a values.yaml file for future use.\n\n    wget https://raw.githubusercontent.com/kubernetes/charts/master/stable/gitlab-ce/values.yaml\n\nEdit the _values.yaml_ file and at minimum, add the **externalUrl** field. Otherwise, you’ll end up with a non-functioning release.\n\nHere is how my _values.yaml_ file looks like after these changes:\n\n    image: gitlab/gitlab-ce:9.4.1-ce.0\n    externalUrl: http://containerized.me/\n    serviceType: LoadBalancer\n    ingress:\n    annotations:\n    enabled: false\n    tls:\n    url: gitlab.cluster.local\n    sshPort: 22\n    httpPort: 80\n    httpsPort: 443\n    livenessPort: http\n    readinessPort: http\n    resources:\n    requests:\n    memory: 1Gi\n    cpu: 500m\n    limits:\n    memory: 2Gi\n    cpu: 1\n    persistence:\n    gitlabEtc:\n    enabled: true\n    size: 1Gi\n    storageClass: openebs-standard\n    accessMode: ReadWriteOnce\n    gitlabData:\n    enabled: true\n    size: 10Gi\n    storageClass: openebs-standard\n    accessMode: ReadWriteOnce\n    postgresql:\n    imageTag: “9.6”\n    cpu: 1000m\n    memory: 1Gi\n    postgresUser: gitlab\n    postgresPassword: gitlab\n    postgresDatabase: gitlab\n    persistence:\n    size: 10Gi\n    storageClass: openebs-standard\n    accessMode: ReadWriteOnce\n    redis:\n    redisPassword: “gitlab”\n    resources:\n    requests:\n    memory: 1Gi\n    persistence:\n    size: 10Gi\n    storageClass: openebs-standard\n    accessMode: ReadWriteOnce\n\nNow, install the chart.\n\n    helm install — name gitlab-test -f values.yaml stable/gitlab-ce\n\nList the pods and confirm that all pods are ready and running.\n\n    $ kubectl get pods\n    NAME READY STATUS RESTARTS AGE\n    gitlab-test-gitlab-ce-dd69cdf4b-69vmb 1/1 Running 0 11m\n    gitlab-test-postgresql-75bf9b667d-lwj2b 1/1 Running 0 11m\n    gitlab-test-redis-998998b59-hzztj 1/1 Running 0 11m\n    openebs-gitlab-test-apiserver-68fc4488fd-jf8gz 1/1 Running 0 1h\n    openebs-gitlab-test-provisioner-7dfdf646d8–9wpmg 1/1 Running 0 1h\n    pvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-ctrl-74d4b59c9f-bjtg2 2/2 Running 0 11m\n    pvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-rep-64f56667d-6ds26 1/1 Running 0 11m\n    pvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-rep-64f56667d-99mbh 1/1 Running 0 11m\n    pvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800-rep-64f56667d-d8d4z 1/1 Running 0 11m\n    pvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-ctrl-bd7cff65f-ph8dr 2/2 Running 0 11m\n    pvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-rep-595dd9c997–2lm4x 1/1 Running 0 11m\n    pvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-rep-595dd9c997-jldjs 1/1 Running 0 11m\n    pvc-cb1064ee-6904–11e8–9f57–06a0a9acf800-rep-595dd9c997-kzlrc 1/1 Running 0 11m\n    pvc-cb111261–6904–11e8–9f57–06a0a9acf800-ctrl-668f5988c5-hv8vb 2/2 Running 0 11m\n    pvc-cb111261–6904–11e8–9f57–06a0a9acf800-rep-74974f6644-hsn49 1/1 Running 0 11m\n    pvc-cb111261–6904–11e8–9f57–06a0a9acf800-rep-74974f6644-lj64g 1/1 Running 0 11m\n    pvc-cb111261–6904–11e8–9f57–06a0a9acf800-rep-74974f6644-z6kfd 1/1 Running 0 11m\n    pvc-cb11a791–6904–11e8–9f57–06a0a9acf800-ctrl-585cf7c97d-58pnq 2/2 Running 0 11m\n    pvc-cb11a791–6904–11e8–9f57–06a0a9acf800-rep-79d658d94c-5bzn6 1/1 Running 0 11m\n    pvc-cb11a791–6904–11e8–9f57–06a0a9acf800-rep-79d658d94c-9dz5f 1/1 Running 0 11m\n    pvc-cb11a791–6904–11e8–9f57–06a0a9acf800-rep-79d658d94c-snkfb 1/1 Running 0 11m\n\nGet the list of persistent volumes.\n\n    $ kubectl get pv\n    NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\n    pvc-cb0fc1b2–6904–11e8–9f57–06a0a9acf800 10Gi RWO Delete Bound default/gitlab-test-postgresql openebs-standard 17m\n    pvc-cb1064ee-6904–11e8–9f57–06a0a9acf800 10Gi RWO Delete Bound default/gitlab-test-redis openebs-standard 17m\n    pvc-cb111261–6904–11e8–9f57–06a0a9acf800 10Gi RWO Delete Bound default/gitlab-test-gitlab-ce-data openebs-standard 17m\n    pvc-cb11a791–6904–11e8–9f57–06a0a9acf800 1Gi RWO Delete Bound default/gitlab-test-gitlab-ce-etc openebs-standard 17m\n\nYou can see above that four persistent volumes were created (**postgresql, redis, gitlab-ce-etc, gitlab-ce-data**), and each volume is protected by 3 replicas.\n\nNow go to the external endpoint address you have defined and start using GitLab after you set your new password.\n![](https://lh4.googleusercontent.com/9UnAe3ZuKt_weq1IbxOrgA_JQMpXE2ZCd80PgDxIodeUdFslr-wCt2DUjbWyoERYWa6RKht8JYvihV-_dQS0EYArc4dJhkPPtN0cGPNfYcDsiHgtjS7unCLOW9MTDre79AjZ660xm6IN94OPew)\nNow click on **Create a project**, then import your existing project from GitHub and start using GitLab.\n![](https://lh4.googleusercontent.com/CDe7SDXnBmCL5IGVTIOYATjzjZN2iMPsZaVBmuY3-l6qXFX8xReeU6M234eX0ELY1Pips6JfR1FJb4rzfL_d53KLDon0MrzBKqQvuBslQDboCw1yPehiKrSf771PMy79ckmPdLGWnhmijDFkVg)![](https://lh6.googleusercontent.com/AFqy2l5MohpC1kCk5k2yFoZA90qJGabfUymqmMmI0kFqcpgqXnrapoYCs1dMfrFDqKj-37ncNvoCe7Kf8UfCQq6VRvmFMK742abC58ju6TiRSUk2yeq1OtMBZWPMd3pqyQWawBDgUcSpSZ8Djg)\n\n---\n\nHopefully this helps anyone who is motivated to reexamine their approach to Git to quickly and easily start running GitLab on Kubernetes. Thank you for reading, and please provide any feedback below or via twitter — [**@**muratkarslioglu](https://twitter.com/muratkarslioglu)_Originally published at _[_Containerized Me_](http://containerized.me/git-freedom-on-kubernetes/)_._\n","slug":"git-freedom-on-kubernetes"},{"id":18,"title":"Berlin K8s meetup retrospect","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"31-05-2018","tags":["Openebs","Kubernetes","DevOps"],"content":"\nLast week, I was invited to give a talk about OpenEBS during the Kubernetes meetup in Berlin. The event was hosted by the friendly folks at Profitbricks, who once again I want to thank for the lovely venue and experience. Matt Baldwin, from our friends at StackPoint Cloud, was once again an organizer — thank you Matt for your ongoing support of the community (and of OpenEBS as well).\n\nAs we went over some of the nitty-gritty details on how we are building OpenEBS, I received a few questions that I thought deserved an extended response. I will address one of those here.\n\nA common question was: “If I’m running on an _<insert cloud vendor>_ system, what is the benefit of OpenEBS?”\n\n**_So, let’s dive into one of the biggest questions— what if you are running on AWS and you are using EBS volumes, why use OpenEBS on top?_**\n\nFirst of all, we already made the implicit assumption that if you were to run an application managed by Kubernetes, you are using EBS volumes. But, this assumption does not have to be true. In fact, if you want fast and performant storage, AWS suggests that you use optimized storage instances, meaning _not using EBS_ volumes at all.\n\nThe EBS volumes are not the fastest thing you can get from AWS, but they do provide replication across zones and snapshots. This brings me to the second part, a snapshot, in AWS, is stored in S3. That bill (depending on dataset size) can quickly and easily pile up with the number of snaps. With OpenEBS, we store the snapshot locally on the volume itself, and we don’t require you to “copy” this into S3 or a similar location. Also, consider the amount of time it takes for a snapshot to be created in AWS; it can take hours and the snapshot restores require you to attach a new EBS volume. Moreover, if you do these types of things, you have to “fiddle” with the OS to get it attached, something that OpenEBS handles for you, making snapshots instantly and allowing you to rollback immediately.\n\nThere is also the matter of granularity; with OpenEBS, you can control everything per application or even per workload. You can fine-tune the replication factors (or not have it all) and you can use just one EBS volume for all your apps since OpenEBS handles the slicing and dicing for you.\n\nSo, this was about using EBS volumes, I hope the advantages are apparent and easy to understand. This brings data agility to your applications, not just in AWS, but also across clouds: public, private or hybrid. The developer does not have to make any changes to his or her YAML, and can write once and run everywhere, precisely what containers are supposed to do. Do not let others take that freedom away from you =)\n\nBack to the non-EBS volumes, what AWS refers to as “instance store.” More information from Amazon:\n![](/content/images/2020/01/instance-stores.png)\nAs the docs point out, when you use this, you get high speed with zero features. With OpenEBS, you get high speed and all of the features if you delegate control of the “instance store” to OpenEBS. An interesting note, the instance store comes with the price of the machine instance itself, so there are no extra charges on your bill.\n\nIn a future blog I’ll cover some other common questions that arose — and I’m also going to continue talking about the shift of IO and so forth to the user space, and what it may mean for Container Attached Storage and running IO intensive workloads in general.\n\nFeel free to ask any questions below, or maybe I’ll see you on the [OpenEBS slack community](https://slack.openebs.io/?__hstc=216392137.c2ca19ae0ec72f00a9ae3bf6f8a512a3.1579861713935.1579861713935.1579861713935.1&__hssc=216392137.1.1579861713935&__hsfp=3765904294) where we are discussing many related subjects.\n","slug":"berlin-k8s-meetup-retrospect"},{"id":19,"title":"Container Attached Storage (CAS) — Taking off nicely","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder & COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"28-05-2018","tags":["Cas","Kubernetes","Stateful-Applications","Openebs","Mayaonline"],"content":"\nI had the fortune of [presenting](https://www.slideshare.net/OpenEBS/openebs-cas-sdc-india-2018) to a group of brilliant folks at SNIA India SDC event last week. This event being in Bangalore, I could sense the heat emanating from technology savvy brains mostly from the storage companies like DELL-EMC, NetApp, RedHat storage, HP storage etc and the questions at the end of the presentation were a proof of it. Lots of great questions on the lines of “Nice architecture, I never knew storage can be run completely in user space”, “CAS — great topic, I understand the value and benefits, but are not you adding too many containers to the equation?”. In the interest of answering those questions in detail, I thought let me take the most commonly asked ones and answer them in this short article.\n\n## Just a quick recap on CAS:\n\n[Container Attached Storage (CAS)](https://docs.openebs.io/docs/next/conceptscas.html) is a new storage architecture to run the entire storage software in containers and hence in user space. This architecture has many benefits, primary one being “a dedicated storage controller per application” and bring in the possibility of hardening the storage controller for a given application workload. Read more on the benefits at the [CNCF blog](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/). A typical CAS architecture example is shown below.\n![](https://cdn-images-1.medium.com/max/800/1*4dJDmPbxxrP-fZK7NZZmYg.png)CAS architecture with controller and replica pods for each application\nNow back to the CAS FAQ, here are a couple:\n\n### Q1: Well, how can you run entire storage in user space? I thought it can never be run in user level because of performance reasons.\n\nFor more technical answer, read our [CTO’s blog](https://blog.openebs.io/the-mule-and-the-flash-going-for-a-run-b104acbc74a2) on this precise topic 🙂\n\nShort answer is, we think storage should take advantage of container technology, so in CAS, we run storage as a microservice. The performance will be taken care by using technologies like SPDK, VPP and also taking advantage of the abundant availability of compute cores on the node.\n\nReality is that, linux kernel, as it is today, cannot deliver all the IOPS from the underlying NVMe flash disks. Do we think kernel can deliver 12 Million IOPS from the 24 NVMe disks ? Of course not, not today !!\n\nIn summary, higher performance can only be delivered using CAS architecture, SPDK, VPP and using more CPU cores.\n![](https://cdn-images-1.medium.com/max/800/1*aKjepAaB5sIZF-hOq_dxIg.png)CAS with SPDK leads to higher performance\n\n### Q2: In CAS, you are adding more containers to the cluster because of storage. Isn’t that increasing the compute needs of the Kubernetes cluster ?\n\nCAS enables native hyper convergence capability on Kubernetes. You don’t need an external storage array to manage the storage/data needs of applications on K8S, thats a lot of saving of CPU and hardware. With CAS, the overall TCO reduces as the additional storage (local disks), CPU and software (CAS) are provisioned on the same K8S cluster nodes and avoids the need of expensive external storage arrays.\n\nAs for the the question of dealing with large number of containers is concerned, there are nice tools like Weave Scope which you can use either on the local K8S or in a free service like MayaOnline. Check out [MayaOnline](https://www.mayaonline.io) where the storage extensions to Scope are put to use.\n![](https://cdn-images-1.medium.com/max/800/1*RQYjI0MdsXf1kj8AGqLJZA.png)Application relationship with storage (PVC, PV, SC, and CAS)\n\n## Conclusion:\n\nWe continue to say — With CAS, storage fades away as a concern !! Join our [slack community](https://slack.openebs.io) to find more !!\n","slug":"container-attached-storage-cas-taking-off-nicely"},{"id":20,"title":"\"My First Contribution to OpenEBS #OSS\"","author":"Vipul Gupta","author_info":"Enter a short bio? No, thank you. If you like to find me or my content, then I would be at http://mixstersite.wordpress.com/","date":"28-05-2018","tags":["Openebs","Go","Golang","Summer-Hackfest","Open-Source"],"content":"\nWriting documentation for any project is tough, be it big or small, propriety or open-source. Rewriting and improving it is even tougher. Let no one tell you any different. Take it from someone who scoured through 6000+ lines of documentation written in Markdown spread across 20 or so files and been able to fix about 900 odd lines of them for a major open-source project. That’s how my story goes if you want to know about my first contribution to OpenEBS.\n\nHonestly, I have little experience in Go, I have never been inclined to use it much. As I am already comfortable, writing code in Python for about a year now. But that doesn’t stop me from learning new languages and technologies. Hence my utmost dedication to cure myself of the “Too Much too Learn” Syndrome. I went to the \\***\\*Women Who Go meetup\\*\\*** in New Delhi, India for a [Go 101 workshop](https://twitter.com/vipulgupta2048/status/977893034808434689?s=09). And that’s how I got to know about the open-source project, OpenEBS, and their exciting Summer HackFest.\n\n[OpenEBS](https://openebs.io/) is an open source storage platform that provides persistent and containerized block storage for DevOps and container environments. OpenEBS is also tightly integrated with Kubernetes and is a part of Kubernetes-Incubator project. And works with all popular workloads such as PostgreSQL, Redis, Jenkins etc.\n\nNow, OpenEBS is still under active development from the team. Hence comes in, [Summer HackFest](https://openebs.io/hackfest). \\***\\*Summer HackFest\\*\\*** is a unique opportunity for new contributors and people working with Go to develop and fix issues for OpenEBS and their projects such as [Maya](https://mayaonline.io/), [Litmus](https://openebs.io/litmus). By contributing to the Hackfest, you get community access, useful knowledge on working with new technologies, learn new skills and along the way win cool goodies, swag. Also, the chance to take home the grand prize, a laptop. HackFest starts out in April 2018. Being open-source, all contribution was needed to be submitted to [GitHub](https://github.com/openebs/openebs). I did and oh man, I had a good time writing code for OpenEBS. Sounds good. Want to contribute?\n\n---\n\n## Let’s get you started\n\nRefer to this [quick guide](https://github.com/search?utf8=%E2%9C%93&q=org%3Aopenebs+is%3Aissue+label%3Asummerhack+label%3Akind%2Funit-test&type=) to get started. You would also need to be familiar with the basics of Go, hence you can refer to the widely recommended tutorial [https://tour.golang.org/](https://tour.golang.org/), for the same. After that, make sure to join the OpenEBS Slack channel to resolve all doubts and questions that you might have. The link can be found here in the [contributing document](https://github.com/openebs/openebs/blob/master/CONTRIBUTING.md) on their repository. Read the document (I re-wrote it) And you are committed.\n\nGo to their website that I linked above, and figure out which section of issues you would like to contribute too. Once done. Head over there, and do your thing. Push the changes, make that PR and rest is history.\n\n## Well, sure thing but how was your experience?\n\n![](/content/images/2020/01/hackfest-contributors.png)Contributors to OpenEBS Hackfest\nMy experience has been great so far while contributing to OpenEBS (**I am still actively contributing to it**). Everything was a breeze. They have very flexible rules and easy guidelines, no hard checks with the CI. The reviewers are very helpful, and would assist you in every possible manner ( Shoutout to Kiran Mova !!) I have been working on solving issues in the documentation of OpenEBS and vagrant files that are being used in the project.\n\nEarlier, I also attended a webinar OpenEBS conducted on Introduction to contributing and solving issues of Maya and scope, which was very informative and helpful. Hence goes on to show their dedication to helping their contributors even further then most people would go. The codebase could be quite intimidating at first, but with time and the helpful answers provided by the very vibrant and active community will keep you going. I can tell you for a fact, that the journey is the reward here.\n\nI asked so many questions, and never got a blowback. I really appreciated all the support shown to me by the community. The environment is beginner-friendly and very welcoming, great for all new contributors. It couldn’t get any better with the incentives they add to it for contributing.\n\nI honestly had a lot of fun while contributing. One of the most notable [pull requests](https://github.com/openebs/openebs/pull/1511) of mine to Summer Hackfest was about rewriting and improving the documentation, which received a whopping 392 comments. They were sweet enough to put my name on the website with the fellow contributors and made me the star contributor of the week. Woohoo !! They also awarded me with a book as a token of their appreciation. Thanks, OpenEBS !!\n\nAnd that’s it for this time, I guess. For all my PR’s to Summer HackFest, [click here](https://github.com/search?utf8=%E2%9C%93&q=org%3Aopenebs+is%3Apr++label%3Asummerhack++author%3Avipulgupta2048+is%3Amerged&type=Issues). I will update the blog post with a picture of the goodies once I receive them (**So excited**). I highly recommend heading over to [https://openebs.io/hackfest](https://openebs.io/hackfest), to take part in this golden opportunity to contribute to such a brilliant project and being a part of their community.\n\n---\n\nVipul Gupta ([vipulgupta2048](http://www.letmegooglethat.com/?q=vipulgupta2048)) posts occasional on his blog, [Mixster](http://www.mixstersite.wordpress.com/). Check him out there for more updates like these.\n","slug":"my-first-contribution-to-openebs-oss"},{"id":21,"title":"Using Kubernetes Custom Resources for Microservices IPC","author":"Ganesh Kumar","author_info":"Gopher, Open Source Contributor, Thinker, Health enthusiast","date":"11-05-2018","tags":["Kubernetes","Golang","Openebs","Microservices"],"content":"\nThis blog talks about why I used [Custom Resources](https://kubernetes.io/docs/concepts/api-extension/custom-resources) as a way for communication between different microservices (aka Kubernetes Pods).\n\nOpenEBS is a fully containerized storage solution running within Kubernetes. Infact [OpenEBS](https://docs.openebs.io/) extends the Kubernetes cluster functionality to manage storage and stateful workloads.\n\nOpenEBS has an operator (or orchestration component) called [Maya](https://github.com/openebs/maya) (magic) that relays Volume management operations to several storage engines. OpenEBS already supports [Jiva](https://github.com/openebs/jiva) based storage engine. The purpose is to plugin a more independent [cStor](https://github.com/openebs/cstor)based storage engine (making use of zfs on userspace).\n\nI essentially have a user interacting with OpenEBS Maya using PV, PVC, StorageClasses etc. and OpenEBS Maya interacts with cStor Pods. I will be focusing on the design considerations for interactions between OpenEBS Maya and cStor Pods.\n![](/content/images/2020/01/architecture.png)\n**1 — Shows user creating StoragePoolClaim (SPC) CR, with details like the number and type of pools to be created. Let us consider, SPC specifies a cStor pool should be created.**\n**2 — Maya has a custom controller that watches for the SPC CR and it will go ahead and create the cStor Pods with a cstor-pool container and a side-car cstor-pool-mgmt that has a CLI interface for creating pools and volumes. Side-car container (following the Kubernetes Ambassador Pattern), helps in translating the Pool and Volume operations triggered by Maya into the corresponding CLI commands.**\n**3 — Depending on the user’s request for creating a pool or a volume, Maya will create CStorPool and CStorVolumeReplica CRs respectively. Note that, I could have had the cstor-pool-mgmt container expose an API service that Maya could have invoked. Instead, I decided to use CRs and I will explain why in the following sections.**\n**4 — cstor-pool-mgmt sidecar application watches for CRs of CStorPool and CStorVolumeReplica and performs pool — volume operations.**\n\n\\***\\*One of the core design constraint while deciding on inter-pod communication between Maya and CStor Pod is that: \\*\\*\\*\\***When the user requests for a Volume, the cluster state may not be fully ready to satisfy all the criteria — for example, User requests for 3 replicas but there are only 2 nodes running. The request should be cached and a third replica has to be provisioned whenever a new node gets added to the cluster.\\*\\*\n\nDevelopers normally go with an approach to make a REST/gRPC call to the receiver and store in a database, running in separate pod/statefulset. But OpenEBS thinks beyond that.\n\nNow consider, that I had used the traditional approach of using a REST/gRPC method of interactions between Maya and CStor Pods, then Maya would have to implement/consider cases like:\n\n- Where to store the state of current request, as the request can’t be serviced immediately depending on the cluster state. This is required to handle the case where the node running Maya can itself go down.\n- When working in a scaled environment, when there are multiple Maya pods, who gets to service the requests and when one of the pod goes down, should the other take it over or not?\n- How to handle the case where, Maya sends the request to the CStor container and then it goes boom (after all this is Kubernetes Cluster and they are supposed to handle all kinds of Chaos), who handles the results of the operation at CStor. In other words, how to implement a 2-phase commit?\n\n**However, if you look at my design constraint, doesn’t it sound similar to how a Kubernetes deployment with 3 replicas work?** The user defines a desired state (in this case Maya) and the controllers make it happen eventually. So, why not just, be a roman when in rome.\n\n### Thats exactly what OpenEBS does!\n\nOpenEBS goes with `watch`-er approach. i.e., watch [\\***\\*k8s custom resource definition\\*\\***](https://kubernetes.io/docs/concepts/api-extension/custom-resources). If a pool (virtual disk) must be created on top of the actual disk, Maya creates a custom resource (named CStorPool), and a pod running cstor-pool-mgmt watcher gets an event for corresponding resource request and starts performing pool related operations. Cool, isn’t it?\n\n### Where does the custom resource get stored?\n\nkubernetes etcd. You pronounced it right, that’s `yetsed`, :-)\n\n### How is custom resource efficient?\n\n- Storing critical details in a separate pod-database, leads to pod level consistency. Storing in etcd leads to \\***\\*cluster level consistency\\*\\***.\n- Even if the \\***\\*receiver is not running\\*\\***, when the request is generated, the receiver-watcher gets an event, as and when it starts running.\n- Users can access the resources via \\***\\*k8s cli\\*\\*** — `kubectl get <crd-name>`\n- Update the status of request on the same custom resource.\n\n### What is the problem with custom resource?\n\n- It is not suitable for transactional communication. (Say if an OTP request needs to be done within 20 seconds, it is not applicable to go with, “as and when up” approach).\n  Solution: Before making any transactional call, verify status of receiver and make a REST/gRPC API call. No other go, :-(\n- It is slightly complex to implement watcher.\n  Solution: My next blog will address an easy way to implement CRD watcher, how to solve issues with watcher design and different ways to implement watching controller. Practise, you become perfect; Follow us, you become fantastic :-)\n\nSupport and follow us [\\***\\*@gkGaneshR\\*\\***](https://twitter.com/gkGaneshR) and [\\***\\*@openebs\\*\\***](https://twitter.com/openebs) to get instant updates.\n\nThanks [Kiran](https://twitter.com/kiranmova) for your valuable support. We at OpenEBS are always looking for help and feedback from Community. Please join us on [Slack](https://slack.openebs.io/) or comment on the [design doc](https://docs.google.com/document/d/1Q5W3uHktHa-vOm8oGp-3kpAQ3V1tvyk5AYmxxtf57Rg/edit?usp=sharing) and related [Pull Request](https://github.com/openebs/maya/pull/284).\n\n\\***\\*Summary\\*\\***\n\n- K8s CRD becomes a good alternative to REST/gRPC API for “push to perform” operations.\n- Few more implementation details will be covered in upcoming blogs — Follow us for updates.\n","slug":"using-kubernetes-custom-resources-for-microservices-ipc"},{"id":22,"title":"Announcing MayaOnline — A SaaS platform for freeing data management from its traditional…","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"01-05-2018","tags":["Gitops","Kubernetes","Mayaonline","Openebs","Stateful-Workloads"],"content":"\nAt this Kubecon, we, at MayaData, are thrilled to make couple of [announcements](https://www.prnewswire.com/news-releases/mayadata-releases-litmus---open-source-chaos-engineering-for-kubernetes--free-tier-of-mayaonline-681458381.html). One of them is the launch of beta version of [MayaOnline](https://mayaonline.io). MayaOnline provides **free** visibility, ChatOps and cross-cloud control for users running OpenEBS or just local disks on Kubernetes clusters.\n\nMayaOnline provides application developers, Kubernetes administrators and CIOs different variants of visibility into stateful applications data and helps these users to better manage data operations.\n\nIt has become an almost untold expectation that the modern era tools being built for easing / helping DevOps are built with easy integration into GitOps; change controlling configurations much in the way that code is managed has been identified as a key determinant of success. MayaOnline takes the GitOps philosophy into its design;configurations come from single source of truth — Git repositories.\n\nTalking about simple integrations — we also have made APIs first class citizens in the design of MayaOnline. Almost anything you can do via the GUI you can do via APIs.\n\nKubernetes’ stateful applications journey is still evolving. We observe two primary usage patterns.\n\n1. Perhaps the most common pattern is running stateful workloads with the help of open source storage that is easy to use and operate; if the open source storage delivering capabilities to microservices and containers is itself built from microservices and containers — all the better.. OpenEBS is a leading example of this pattern, with an architecture described as [CAS](https://www.cncf.io/blog/2018/04/19/container-attached-storage-a-primer/) or container attached storage. In OpenEBS, data volumes are containerized and each workload has its own storage controller enabling teams to be fully in control of their storage without any central single point of failure (or latency)\n2. A second common pattern that we see is perhaps best characterized by NoSql workloads such as Cassandra, that manage the data operations themselves (replication, snapshotting and rebuilding) and therefore for which just raw storage underneath is good enough. This type of stateful workloads are starting to use Kubernetes Local PVs. However, the raw storage needs to be planned, monitoring and managed for Local PVs too otherwise your Cassandra and application engineers spend all their time trying to figure out why the ring is rebalancing again and again.\n\nM**_ayaOnline is intended to be an all in one storage resource planning, monitoring and management solution for Kubernetes deployments across clouds; we do support the above patterns, allowing you to manage OpenEBS and Local PVs as the underlying storage choices._**\n\nMayaOnline is released as a beta version today and comes live with the following features. In this post, I discuss MayaOnline’s current capabilities and delve a bit into the vision as well.\n\n## Sifting through your PVCs and PVs:\n\nMicroservices architectures typically split applications into multiple kubernetes PODs. It is not uncommon to have a production Kubernetes cluster with hundreds of PODs, in some cases even thousands. Each POD can have multiple volumes claims (PVCs), derived from a combination of storage classes (SCs) and resulting in volumes (PVs). Thanks in large part to our newly released Weave Scope integration, MayaOnline provides an efficient way to view, debug and for some scenarios manage these PVC and PVs and their relationships.\n\nOne simple use case is sifting through the snapshots of a volume and creating a clone out of one.\n![](https://cdn-images-1.medium.com/max/800/1*uEEzklDvtzepvdjGUIQdJQ.gif)Browse storage configuration of a cluster\n\n## Managing hyper-convergence:\n\nThe same problem of sifting through hundreds of objects and their logical and physical relationships can arise while managing underlying storage media, including disks, cloud volumes, SSDs and more. MayaOnline helps here as well, simplifying disk monitoring and management, the pooling of disks, expansion of capacity . OpenEBS NDM is a key piece go get the hyper-convergence management right, you can refer to [this blog](https://blog.openebs.io/achieving-native-hyper-convergence-in-kubernetes-cb93e0bcf5d3) for more thoughts on contributing NDM to Kubernetes itself.\n![](https://cdn-images-1.medium.com/max/800/1*7w2jYA2KghNxT7c96snCxw.gif)Browse disks relationship to a volume\n\n## Visibility:\n\nPrometheus is a popular project applying a time series approach to monitoring. We use Prometheus in MayaOnline in a variety of ways. Thanks to Prometheus Developers, Operators and CIOs have readily customized dashboards for volume data and for storage resources data within and across clusters. MayaOnline makes it easy to aggregate Prometheus metrics from various clusters spread across multiple clusters and on-prem data centers. External API support, customization of Prometheus dashboards, and the creation of new dashboards are other favorite features of MayaOnline.\n![](https://cdn-images-1.medium.com/max/800/1*ZeFadSNW8zEQ9DWaotiOhA.gif)Comprehensive metrics of a volume, cluster and organization\n\n## ChatOps — Dedicated chatbot for automated operations:\n\nGetting useful alerts on time and be able to act on them is an integral part of data management operations. With MayaOnline, one can view and manage the alerts centrally by logging onto MayaOnline — or can just have them pop up in your chat thanks to our dedicated chatbot, which we call MuleBot. MuleBot is a [Slack application](http://slack.com/apps/A7XH78AAH-mulebot) that works hard to deliver alerts to the Slack channels you want while participating in your GitOps workflow by interacting with your teams end users, allowing them to storage infrastructure right from the slack channel.\n![](https://cdn-images-1.medium.com/max/800/0*U47i8j0o34sBq3AW.)MuleBot Slack Application\n\n## Looking into the future of MayaOnline:\n\n### Seamless cross cloud data movement:\n\nThough Kubernetes solves the problem of cloud lock-in with regard to application provisioning and management — by being a common orchestration framework and set of operations APIs across environments -, we still have the problem of lock-in caused by data gravity. MayaOnline’s cMotion feature — which we are working on actively and have demoed in the past — will help with seamless and policy based workload movements. cMotion APIs at MayaOnline will be used to automate workload movement across clouds or Kubernetes clusters right from the user’s DevOps platforms.\n\n### Learning workloads\n\nOne of the reasons we made MayaOnline freely available is to learn from users how they use OpenEBS and, more broadly, how they are managing stateful workloads on Kubernetes.\n\nIn the not too distant future we will use what we learn from MayaOnline to nudge users towards better approaches. For example, we are investigating how to suggest better storage policies based on our experience from many users. For example, certain workloads may benefit from larger block sizes and a replication approach optimized for videos — OpenEBS allows this kind of extreme customization thanks to its CAS architecture; with MayaOnline we intend to coach users towards better approaches.\n\n### It is free. Import your Kubernetes cluster today !\n\nMayaOnline follows a [freemium ](https://en.wikipedia.org/wiki/Freemium)model. Using the free tier, one can manage certain number of Kubernetes clusters for free, forever.\n\nSign-up with your github credentials and import your Kubernetes cluster, we are eagerly looking for your feedback !!\n","slug":"announcing-mayaonline-a-saas-platform-for-freeing-data-management-from-its-traditional"},{"id":23,"title":"\"Litmus - Release a chaos monkey on your Kubernetes Stateful Workloads!\"","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"01-05-2018","tags":["Chaos","Kubernetes","Litmus","Software-Testing","E2e","Chaos-Engineering"],"content":"\n**In this blog we quickly talk about what led us to build Litmus and to open source it.**\n\nIf you are a Kubernetes Enthusiast and working on stateful workloads, you may be asking yourself:\n\n“With all the options I have to run Kubernetes — the permutations are endless — how can I be sure that my particular mix of options works well end to end at keeping my data safe and accessible?”\n\nYou are not alone, as can be seen by the ever increasing conversations on Kubernetes sig-storage slack channel and other forums like Reddit or Twitter. To just pick a few conversations:\n![](https://cdn-images-1.medium.com/max/800/1*6VJXdgFpuwD-fUkEKPo0GA.png)[Is it really recommended to run stateful workloads like MySQL on Kubernetes?](https://www.reddit.com/r/kubernetes/comments/88fxdg/is_it_really_not_recommended_to_run_stateful/)![](https://cdn-images-1.medium.com/max/800/1*5s60fO7nzhZfC3SFNiY0gA.png)[What are the storage solutions offered in Kubernetes today? Which one will suit my workload](https://twitter.com/rothgar/status/978694465975083009)\nAnd say, you somehow have made the journey to explore different solutions out there, mostly referring to product documentation and blogs, how can you be sure that the solution will continue to work in your enterprise environment ?\n\nAs enterprises move to DevOps and microservices, more and more of the infrastructure from policy engines through storage and everything in between such as DNS, tracing, logging and more are selected and operated by all in one teams. With this control and autonomy comes greater agility — and all too often, _stress_.\n\nMeanwhile, infrastructure vendors and projects are also (we know first hand) challenged to keep their end-to-end (e2e) and chaos engineering frameworks updated with the ever-increasing permutations of deployment scenarios. Kubernetes itself is changing, new providers emerge every day, workloads are changing, and all of it is increasingly simple to adopt and deploy. As a storage solution provider we simply cannot have the resulting explosion of “corner cases” go untested.\n\nThe solution providers can go one step ahead to open source their project, but it still doesn’t help the users to ensure that the selected kubernetes stack works in their highly distributed and agile environments and they are not called to fight fires at 3 AM**.**\n![](https://cdn-images-1.medium.com/max/800/0*qX8CliW_E3gKMURn.)Fire-fighting production issues !!\n“What’s a person to do? Test, test, release the chaos monkeys, and test again!”\n\nThankfully, Kubernetes and containerization and Go and some software engineering we’re happy to share make it much easier to provide end to end validation in real world conditions !\n\n#### So — What is Litmus?\n\n**_Litmus is a community for e-2-e testing and chaos engineering for Kubernetes, focusing on stateful workloads._**\n\nThe primary objective of Litmus is to ensure a consistent and reliable behavior of Kubernetes for various persistent workloads and to catch hard-to-test bugs and unacceptable behaviours before users do. Litmus can detect many more real-world issues than relatively simple issues identified by unit and integration tests.\n\nLitmus can also be used to determine if a given Kubernetes deployment is suitable for stateful workloads. While Litmus tests and metrics were developed initially to test the resilience of container attached storage from OpenEBS and others — we realized that the use cases are broader and overall system resilience can be characterized, which is a major reason we are open sourcing our efforts and putting the time into starting the Litmus community.\n\nLitmus tests range from initial setup and configuration validation to deploying and running persistent workloads under various conditions and failures.\n\n_What sets Litmus apart is not just its intent of being an end to end testing framework that can be embedded into any CI/CD pipeline, but the ease with which different teams from product developers to customers can contribute to the tests. Litmus allows for defining scenarios using native language specifications (English !!) OR a set of easy-to-define/understand YAML templates which are internally converted into test scripts, with a simple Kubernetes manifest as the end-product._\n\nHere is a simple test, defined in plain English:\n![](https://cdn-images-1.medium.com/max/800/0*ar6cYX2rEJ7Nh_G2.)\n\n## How to get involved with Litmus?\n\nFirst, it might be useful to understand the basic pieces of Litmus. Litmus has the following major components:\n![](https://cdn-images-1.medium.com/max/800/1*CdBbpkSilx3aJnZA3tiAjQ.png)Litmus: High level architecture\n\n- **Deployments** that help in setting up different types of Kubernetes Clusters like on-premise, cloud, OpenShift, etc. The default is that the deployments provision and configure OpenEBS storage, however, these deployments are easily extended to support other storage and we are happy to help any user or storage vendor to build additional deployments.\n- **Facilitators** for test execution that aid: defining and running test suites, capturing logs and generating reports about the test runs, fault/error injection tools that help to perform chaos tests, examples that demonstrate how to integrate these test pipelines with Slack notifications\n- **Test modules **that are triggered from within a Kubernetes cluster. Think of these as containerized tests. For instance, the **_mysql-client_** can be launched as a pod to validate MySQL resiliency while the underlying nodes and the connected storage are subjected to chaos engineering.\n- **Tests** that themselves are written in easy to understand formats, either in plain English (thanks [Godog](https://github.com/DATA-DOG/godog)!) or in Ansible Playbooks. These tests primarily interact with the Kubernetes cluster via **_kubectl _**making them highly portable.\n\nLitmus can be used to test a given workload in a variety of Kubernetes environments, for example, a developer minikube or a GKE cluster with a specific storage solution or as a part of a full-fledged CI setup.\n\nLitmus is early and needs all the help you can provide to have it cover the ever-growing Kubernetes landscape. Checkout the [Litmus Project](https://github.com/openebs/litmus) on Github for more details or if you are at KubeCon EU, please join us for the talk this Friday on [End to End testing with Kubectl](https://kccnceu18.sched.com/event/DqwD/using-kubectl-to-run-your-end-to-end-tests-amit-kumar-das-uday-kiran-mayadata-intermediate-skill-level) to learn more about how we have built Litmus and a quic\n\n#### Conclusion:\n\nPlease welcome Litmus into the world! We’re pretty sure it addresses a set of needs being felt by everyone from developers and operators to service providers and cloud native open source projects such as OpenEBS. With Litmus we use microservices and containers and Kubernetes to test, validate and characterize environments end to end. Your feedback is welcome and needed. Thanks for reading!\n","slug":"litmus-release-a-chaos-monkey-on-your-kubernetes-stateful-workloads"},{"id":24,"title":"How do I create an OpenEBS storage pool on Google Persistent Disk","author":"Karthik Satchitanand","author_info":"Karthik has been into the Design and Development of tools for infrastructure as code, software testing performance & benchmarking & chaos engineering.","date":"13-04-2018","tags":["Docker","Openebs","Solutions","Google-Cloud-Platform","Kubernetes"],"content":"\nThis article belongs to #HowDoI series on Kubernetes and OpenEBS.\n\nThe OpenEBS volume replicas, which are the actual backend storage units of the OpenEBS iSCSI target currently store the data in a hostPath on the Kubernetes nodes. By default, a folder with the volume (PV) name is created on the root filesystem, in a parent directory (/var/openebs) & bind mounted into the container during the replica pod instantiation. This parent directory (also created if not already available), which is basically a persistent path to hold the individual volumes is referred to as a **_Storage Pool_**.\n\nNote: The notion of the storage pool described above is specific to the current default storage engine ,i.e., Jiva. Future releases may see availability of additional storage-engines which can consume block devices instead of hostdir to create storage pools\n\nFor various reasons, it may be desirable to create this storage pool on an external disk (GPD, EBS, SAN) mounted into specific locations on the Kubernetes nodes. This is facilitated by the **\\*OpenEBS storage pool policy\\*\\***, \\*which defines the storage pool as a **_Kubernetes Custom Resource_** with the persistent path as an attribute.\n\nThis blog will focus on the steps to be followed to create the OpenEBS PV on Google Persistent Disks (GPD).\n\n## PRE-REQUISITES\n\n- 3-Node GKE cluster with the OpenEBS Operator installed (Refer: [https://docs.openebs.io/docs/cloudsolutions.html](https://docs.openebs.io/docs/cloudsolutions.html))\n- 3-Google Persistent Disks, one attached to each node of the cluster.This can be done using the **\\*gcloud compute disks create\\*\\*** & \\***_gcloud compute instances attach-disk_**commands (Refer for console steps: [https://cloud.google.com/compute/docs/disks/add-persistent-disk#create_disk](https://cloud.google.com/compute/docs/disks/add-persistent-disk#create_disk))\n\n### STEP-1: Format the GPDs & Mount into desired path\n\nOn each node, perform the following actions :\n\n- Switch to root user _sudo su –_\n- Identify GPD attached _fdisk -l_\n\n  root@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# fdisk -l\n  Disk /dev/sda: 100 GiB, 107374182400 bytes, 209715200 sectors\n  Units: sectors of 1 \\* 512 = 512 bytes\n  Sector size (logical/physical): 512 bytes / 4096 bytes\n  I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n  Disklabel type: dos\n  Disk identifier: 0x635eaac1\n\n  Device Boot Start End Sectors Size Id Type\n  /dev/sda1 \\* 2048 209715166 209713119 100G 83 Linux\n\n  Disk /dev/sdb: 10 GiB, 10737418240 bytes, 20971520 sectors\n  Units: sectors of 1 \\* 512 = 512 bytes\n  Sector size (logical/physical): 512 bytes / 4096 bytes\n  I/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\n- Format the disk with, say ext4 fs (_mkfs.ext4 /dev/sd<>)_\n\n  root@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# mkfs.ext4 /dev/sdb\n  mke2fs 1.42.13 (17-May-2015)\n  /dev/sdb contains a ext4 file system\n  last mounted on /openebs on Fri Apr 13 05:03:42 2018\n  Proceed anyway? (y,n) y\n  Discarding device blocks: done  \n   Creating filesystem with 2621440 4k blocks and 655360 inodes\n  Filesystem UUID: 87d36681-d5f3-4169-b7fc-1f2f95bd527e\n  Superblock backups stored on blocks:\n  32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632\n\n  Allocating group tables: done  \n   Writing inode tables: done  \n   Creating journal (32768 blocks): done\n  Writing superblocks and filesystem accounting information: done\n\n- Mount the disk into desired mount point (_mount -o sync /dev/sd<> /mnt/openebs_)\n\n  root@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# mount -o sync /dev/sdb /mnt/openebs/\n  root@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# mount | grep openebs\n  /dev/sdb on /mnt/openebs type ext4 (rw,relatime,sync,data=ordered)\n\n### STEP-2 : Create a storage pool custom resource\n\n- Construct a storage pool resource specification as shown below & apply it (Note that the custom resource definition for the storage pool is already applied as part of the operator install)\n\n  apiVersion: openebs.io/v1alpha1\n  kind: StoragePool\n  metadata:\n  name: sp-mntdir\n  type: hostdir\n  spec:\n  path: \"/mnt/openebs\"\n\n### STEP-3 : Refer the storage pool in a custom storage class\n\n    ---\n    apiVersion: storage.k8s.io/v1\n    kind: StorageClass\n    metadata:\n       name: openebs-custom\n    provisioner: openebs.io/provisioner-iscsi\n    parameters:\n      openebs.io/storage-pool: \"sp-mntdir\"\n      openebs.io/jiva-replica-count: \"3\"\n      openebs.io/volume-monitor: \"true\"\n      openebs.io/capacity: 5G\n\n**STEP-4 : Use the custom storage class in an application’s PVC spec**\n\n    ---\n    kind: PersistentVolumeClaim\n    apiVersion: v1\n    metadata:\n      name: demo-vol1-claim\n    spec:\n      storageClassName: openebs-custom\n      accessModes:\n        - ReadWriteOnce\n      resources:\n        requests:\n          storage: 5G\n\n**STEP-5 : Confirm volume is created on the storage pool**\n\n- Once the OpenEBS PV is created (_kubectl get pv, kubectl get pods_), list the contents of the custom persistent path mentioned in the storage pool custom resource. It should contain a folder with the PV name consisting of the sparse files (disk image files)\n\n  karthik_s@strong-eon-153112:~$ kubectl get pv\n  NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\n  pvc-556e7ab7-3ed9-11e8-8e6a-42010a800216 5G RWO Delete Bound default/demo-vol1-claim openebs-custom 59m\n\n  root@gke-oebs-staging-default-pool-7cc7e313-0xs4:~# ls /mnt/openebs/\n  lost+found pvc-556e7ab7-3ed9-11e8-8e6a-42010a800216\n\n### GOTCHAS !!\n\n_Issue_: GPDs are detached in the event of a) Cluster resize (downscale/upscale) , b) upgrades & c) VM halts\n\n- No options to add “additional disks” during cluster creation\n- Instance templates are “immutable”, disks have to be added to instances separately\n\n_Workaround _: Perform a manual re-attach in above situations (Enlarged root disks are an option, but generally not recommended)\n","slug":"how-do-i-create-an-openebs-storage-pool-on-google-persistent-disk"},{"id":25,"title":"Using chaoskube with OpenEBS.","author":"Sudarshan Darga","author_info":"Senior Software Engineer at MayaData","date":"12-04-2018","tags":["Openebs","Chaos-Engineering","Kubernetes","Solutions"],"content":"\n\\***\\*Chaos Engineering\\*\\*** is the discipline of proving the reliability of any system by causing “chaos”. The work ‘Chaos’ means the state of confusion or failure caused due to unexpected reason.\n\n### Failures can be caused due to:\n\n- Power outages.\n- Software bugs.\n- Human Error.\n\n### Since failure is unavoidable.\n\n- Why not deliberately introduce failure to ensure the system can deal with the failure?\n- Chaoskube is one such tool, which can be used to introduce pod failures on Kubernetes Cluster.\n\n### Overview of Chaoskube:\n\n- Chaoskube is an open source Chaos Testing tool.\n- Written in GO language.\n- Can induce pod/controller failures on K8s Cluster.\n- Can kill pods by specifying the labels, namespaces.\n- Simple and easy to run.\n\n## Setup Chaoskube infrastructure on 3 node Kubernetes Cluster:\n\n    ubuntu@kubemaster-01:~$ kubectl get nodes\n    NAME            STATUS    ROLES     AGE       VERSION\n    kubemaster-01   Ready     master    2d        v1.8.8\n    kubeminion-01   Ready     <none>    2d        v1.8.8\n    kubeminion-02   Ready     <none>    2d        v1.8.8\n    kubeminion-03   Ready     <none>    2d        v1.8.8\n    ubuntu@kubemaster-01:~$ kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/e2e/ansible/playbooks/resiliency/test-ctrl-failure/chaoskube.yaml\n    deployment \"chaoskube\" created\n    serviceaccount \"chaoskube\" created\n    ubuntu@kubemaster-01:~$ kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/e2e/ansible/playbooks/resiliency/test-ctrl-failure/rbac.yaml\n    clusterrole \"chaoskube\" created\n    clusterrolebinding \"chaoskube\" created\n    ubuntu@kubemaster-01:~$ kubectl get pods\n    NAME                                   READY     STATUS    RESTARTS   AGE\n    chaoskube-55fc8f5f6d-tb6hj             1/1       Running   0          32s\n    maya-apiserver-69f9db69-b9qxk          1/1       Running   0          2d\n    openebs-provisioner-77cb47986c-w6wbz   1/1       Running   1          2d\n\n## Deploy Percona application on OpenEBS volume with Liveness probe:\n\n    ubuntu@kubemaster-01:~$ kubectl apply -f https://raw.githubusercontent.com/openebs/elves/master/e2e/percona-liveness/percona.yaml\n    deployment \"percona\" created\n    persistentvolumeclaim \"demo-vol1-claim\" created\n    service \"percona-mysql\" created\n    ubuntu@kubemaster-01:~$ kubectl create configmap sqltest https://raw.githubusercontent.com/openebs/elves/master/e2e/percona-liveness/sql-test.sh\n    configmap \"sqltest\" created\n    ubuntu@kubemaster-01:~$ kubectl get pods\n    NAME                                                             READY     STATUS    RESTARTS   AGE\n    chaoskube-55fc8f5f6d-tb6hj                                       1/1       Running   0          6m\n    maya-apiserver-69f9db69-b9qxk                                    1/1       Running   0          2d\n    openebs-provisioner-77cb47986c-w6wbz                             1/1       Running   1          2d\n    percona-85b8997987-dg6jm                                         1/1       Running   0          1m\n    pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-ctrl-6fcb879bdb-vd8t5   2/2       Running   0          1m\n    pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-64rv5    1/1       Running   0          1m\n    pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-b5v25    1/1       Running   0          1m\n    pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-gs69w    1/1       Running   0          1m\n\n## Induce controller failure using Chaoskube:\n\n- Induce failure on pod with label ‘openebs/controller=jiva-controller’ for duration of 60 seconds with interval of 20 seconds, which means it will induce controller pod failure for every 20 seconds for 3 times.\n\n  kubectl exec chaoskube-55fc8f5f6d-tb6hj -- timeout -t 60 chaoskube --labels 'openebs/controller=jiva-controller' --no-dry-run --interval=20s --debug\n\n- Output should look something like this:\n\n  time=\"2018-04-13T09:50:36Z\" level=info msg=\"terminating pod\" name=pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-ctrl-6fcb879bdb-vd8t5 namespace=default\n  time=\"2018-04-13T09:50:36Z\" level=debug msg=sleeping duration=20s\n\n- Lets observe the failure induces by watching `kubectl get pods` for every 2 seconds.\n\n  Every 2.0s: kubectl get pods Fri Apr 13 09:55:35 2018\n  NAME READY STATUS RESTARTS AGE\n  chaoskube-55fc8f5f6d-tb6hj 1/1 Running 0 16m\n  maya-apiserver-69f9db69-b9qxk 1/1 Running 0 2d\n  openebs-provisioner-77cb47986c-w6wbz 1/1 Running 1 2d\n  percona-85b8997987-dg6jm 1/1 Running 7 12m\n  pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-ctrl-6fcb879bdb-nh5fk 2/2 Running 0 15s\n  pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-64rv5 1/1 Running 0 12m\n  pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-b5v25 1/1 Running 0 12m\n  pvc-0f07b9ae-3eff-11e8-8f7e-02b983f0a4db-rep-5df559c66c-gs69w 1/1 Running 0 12m\n\n- Observe that percona application pod with liveness probe is still running after inducing openebs controller pod failure using chaoskube. Hence, the system is reliable after causing ‘Chaos’.\n\n### Reference Links:\n\n- [https://github.com/linki/chaoskube](https://github.com/linki/chaoskube)\n- [https://docs.openebs.io/](https://docs.openebs.io/)\n","slug":"using-chaoskube-with-openebs"},{"id":26,"title":"How do I pin the OpenEBS Replica Pod(s) to the Kubernetes Nodes where they were scheduled?","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"26-03-2018","tags":["Howdoi","Kubernetes","Openebs","Storage","Solutions","Tutorials"],"content":"\nThis article belongs to #HowDoI series on Kubernetes and OpenEBS.\n\nA OpenEBS Volume comprises of a Controller pod and one or more Replica pod(s). Controller pod (also known as a Target pod) is the one to which the application can make an iSCSI connection. The Replica pods are the ones that access the underlying disk resources for storing the data.\n\n> **\\*Use Case #1:\\*\\*** In my Kubernetes cluster, \\*[**_OpenEBS volume pods are scheduled on appropriate nodes_**](https://blog.openebs.io/how-do-i-configure-openebs-to-use-storage-on-specific-kubernetes-nodes-361e3e842a78)_. This is all fine till the cluster experiences a disruption due to network partition. Kubernetes tries to evict & re-schedule these volume pods into newer nodes that does not have the underlying data. This results in volume getting into offline state. I want the OpenEBS volume pods to stick to the nodes they were originally placed._\n\n> ***S*olution**: Patch the Replica deployment with **nodeAffinity** property\n\nAs per Kubernetes docs, nodeAffinity allows you to constrain which nodes your pod is eligible to be scheduled on. It is based on labels on the node.\n\nThere are currently two types of node affinity:\n– `***requiredDuringSchedulingIgnoredDuringExecution***` &\n– `***preferredDuringSchedulingIgnoredDuringExecution***`\n\nThese node affinity types can be thought of “_hard_” vs. “_soft_” affinity respectively.\n\n- *Hard *affinity states that pod will be scheduled only if the conditions are met.\n- _Soft_ affinity implies Kubernetes will make a best effort but the affinity may not be guaranteed.\n\nWe shall make use of `*hard affinity`\\* as this fits perfectly to the needs of Replica deployment.\n\nSteps required to patch the Replica deployment are summarised below:\n\n> **\\*Step 1\\*\\***:-\\* Replica pod(s) gets scheduled by Kubernetes default scheduler (via OpenEBS provisioner — a dynamic Kubernetes storage provisioner)\n> **\\*Step 2\\*\\***:- Wait till r\\*eplica pod(s) get into `Running` state\n> **\\*Step 3\\*\\***:-\\* Operator determines the node(s) on which the replica pod(s) are scheduled\n> **\\*Step 4\\*\\***:-\\* Replica deployment is patched with nodeAffinity\n\n    ```bash\n    # REPLACE <namespace-where-openebs-pods-are-deployed> WITH ACTUAL NAMESPACE\n    # REPLACE <name-of-persistentvolume> WITH ACTUAL PV NAME\n    # TAKE A NOTE OF THE NODE NAME(S) TO BE USED IN THE PATCH.YAML\n\n    kubectl get po -n <namespace-where-openebs-pods-are-deployed> \\\n      -o=custom-columns=NAME:metadata.name,NODE:spec.nodeName,STATUS:status.phase \\\n      | grep -E 'NAME|<name-of-persistentvolume>-rep'\n    ```\n\n    ```bash\n    $ cat replica_patch.yaml\n    ```\n\n    ```yaml\n    spec:\n      template:\n        spec:\n          affinity:\n            nodeAffinity:\n              requiredDuringSchedulingIgnoredDuringExecution:\n                nodeSelectorTerms:\n                - matchExpressions:\n                  - key: kubernetes.io/hostname\n                    operator: In\n                    values:\n                    - nodename_where_replica_pod_1_got_scheduled\n                    - nodename_where_replica_pod_2_got_scheduled\n                    - nodename_where_replica_pod_3_got_scheduled\n    ```\n\n    ```bash\n    # REPLACE <name-of-persistentvolume> WITH ACTUAL PV NAME\n\n    kubectl patch deployment <name-of-persistentvolume>-rep \\\n      -p \"$(cat replica_patch.yaml)\"\n    ```\n\n    ```bash\n    # VERIFY IF PODs ARE BACK TO `Running` AFTER PATCH\n    # REPLACE <namespace-where-openebs-pods-are-deployed> WITH ACTUAL NAMESPACE\n    # REPLACE <name-of-persistentvolume> WITH ACTUAL PV NAME\n\n    kubectl get po -n <namespace-where-openebs-pods-are-deployed> \\\n      | grep -E 'NAME|<name-of-persistentvolume>-rep'\n    ```\n\nSample Replica Deployment Patch\nLearn more about nodeAffinity from Kubernetes docs at [https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity).\n\nIf you want to understand more on kubectl patch operation, then go through [https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/](https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/).\n","slug":"how-do-i-pin-the-openebs-replica-pods-to-the-kubernetes-nodes-where-they-were-scheduled"},{"id":27,"title":"How do I configure OpenEBS to use storage on specific Kubernetes nodes?","author":"Amit Kumar Das","author_info":"Engineer the DAO","date":"18-03-2018","tags":["Howdoi","Openebs","Solutions","Kubernetes","Tutorials"],"content":"\nThis article belongs to **#HowDoI** series on [**Kubernetes**](https://kubernetes.io/) and [**OpenEBS**](https://openebs.io/).\n\n> Note: The approach mentioned in this article applies for OpenEBS version 6.0 or below. One can refer to this [link](https://github.com/openebs/community/pull/20) for OpenEBS version 0.8.0 and above.\n\nA OpenEBS Volume comprises of a Target pod and Replica pod(s). There can be one or more Replica pods. The Replica pods are the ones that access the underlying disk resources for storing the data.\n\n> **Use Case #1: **In my Kubernetes Cluster, I have certain nodes that have disks attached. I call these as Storage Nodes. I want the OpenEBS Volume Replica Pods to be scheduled on these Storage Nodes.\n\n> **_Solution:_** Use Kubernetes “taints & tolerations” feature.\n\nAs per Kubernetes docs, taints allow a node to repel a set of pods. Taints and tolerations work together to ensure that pods are not scheduled onto inappropriate nodes.\n\n- You can apply `*NoSchedule*` & `*NoExecute*` taints to the node(s).\n- `*NoSchedule*` marks that the node should not schedule any pods that do not tolerate the taint.\n- `*NoExecute*` marks that the node should evict existing/running pods that do not tolerate this taint.\n- Tolerations are applied to pods, and allow the pods to get scheduled onto nodes with matching taints.\n- You need to set an ENV variable in maya API server Deployment specifications, which in turn ensures setting of above tolerations on the replica pods.\n- The ENV variable referred to here is `*DEFAULT_REPLICA_NODE_TAINT_TOLERATION*`\n\nFollowing are the instructions to do the same:\n\n    # Step 1  —  Taint the node(s)\n    ```bash\n    # kubeminion-01 is the name of a Kubernetes node\n    # The taint effects used here are `NoSchedule` and `NoExecute`\n    kubectl taint nodes kubeminion-01 storage=ssd:NoSchedule storage=ssd:NoExecute\n    ```\n\n    # Step 2  —  Maya API server should be deployed with below specs\n    # This ensures the replica pods are set with appropriate tolerations\n    ```yaml\n    apiVersion: apps/v1beta1\n    kind: Deployment\n    metadata:\n     name: maya-apiserver\n    spec:\n     replicas: 1\n     template:\n      metadata:\n       labels:\n        name: maya-apiserver\n     spec:\n       serviceAccountName: openebs-maya-operator\n       containers:\n       —  name: maya-apiserver\n         imagePullPolicy: Always\n         image: openebs/m-apiserver:0.5.3\n         ports:\n         —  containerPort: 5656\n         env:\n         —  name: DEFAULT_REPLICA_NODE_TAINT_TOLERATION\n           value: storage=ssd:NoSchedule,storage=ssd:NoExecute\n    ```\n\n> **Use Case #2:** In my Kubernetes Cluster, I have certain nodes that have disks attached. I call these as Storage Nodes. I want the OpenEBS Volume Replica Pods to be scheduled on these Storage Nodes. In addition, I want a better utilisation of these nodes by being able to schedule my application Pods on these nodes as well.\n\n> **Solution:** Use Kubernetes taints & tolerations feature. You may also want to try with `nodeAffinity` to achieve this. However, this solution focuses on use of tolerations.\n\n- You need to make use of `*PreferNoSchedule*` as the taint effect.\n- This can be thought of as a _soft version_ of `*NoSchedule*`.\n- In other words the system tries to avoid placing a pod that does not tolerate the taint on the node, but it is not mandatory.\n\nFollowing are the instructions to do the same:\n\n    # Step 1  —  Taint the node(s)\n    ```bash\n    # kubeminion-01 is the name of a Kubernetes node\n    # The taint effect used here is `PreferNoSchedule` i.e. a soft version of `NoSchedule` \n    # the system tries to avoid placing a pod that does not tolerate the taint on the node,\n    # but it is not mandatory.\n    kubectl taint nodes kubeminion-01 storage=ssd:PreferNoSchedule\n    ```\n\n    # Step 2  —  Maya API server should be deployed with below specs\n    # This ensures the replica pods are set with appropriate tolerations\n    ```yaml\n    apiVersion: apps/v1beta1\n    kind: Deployment\n    metadata:\n     name: maya-apiserver\n     namespace: default\n    spec:\n     replicas: 1\n     template:\n      metadata:\n       labels:\n        name: maya-apiserver\n      spec:\n       serviceAccountName: openebs-maya-operator\n       containers:\n       —  name: maya-apiserver\n         imagePullPolicy: Always\n         image: openebs/m-apiserver:0.5.3\n         ports:\n         —  containerPort: 5656\n         env:\n         — name: DEFAULT_REPLICA_NODE_TAINT_TOLERATION\n           value: storage=ssd:PreferNoSchedule\n     ```\n\nIf you want to learn more on taints & tolerations, then go through [https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/](https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/)\n\nI shall strive to put more such articles in future. Do let me know if you want any specific topics that I should explain.\n\n_Thanks to Kiran Mova._\n","slug":"how-do-i-configure-openebs-to-use-storage-on-specific-kubernetes-nodes"},{"id":28,"title":"Achieving native hyper convergence in Kubernetes","author":"Uma Mukkara","author_info":"Contributor at openebs.io, Co-founder& COO@MayaData. Uma led product development in the early days of MayaData (CloudByte).","date":"13-03-2018","tags":["Hyper-Convergence","Kubernetes","Nutanix","Openebs","Persistent-Storage"],"content":"\nHyper convergence has a lot of benefits — which is one reason it has become popular in the traditional infrastructure-centric world of virtual machines with proprietary vendors like Nutanix reaching prominence over the last several years.\n\nKubernetes is nearly ready as a layer enabling hyper convergence, as the compute orchestration is extremely flexible and networking has moved to a largely containerized approach that leverages local resources in attached physical and virtual hosts.\n\nWhen it comes to storage, however, there are a few pieces that are missing. Once added to Kubernetes, these pieces will unlock a number of benefits to users of Kubernetes including better resource utilization, reduction of noisy neighbor phenomena, simpler management, isolation at the node level thereby reducing the potential blast radius of failures, and, perhaps most importantly, further ownership and management of relevant infrastructure per workload and per DevOps team.\n\nStorage management capabilities in Kubernetes have improved in the last couple of years. For example, there is now clarity around how to connect a stateful application to persistent storage. The constructs of persistent volume claim (PVC), persistent volume (PV), and storage class (SC) along with dynamic provisioners from vendors have clarified how to connect a pod to a storage volume. With these Kubernetes constructs, a large ecosystem of legacy storage found its way to be connected to application pods. Many vendors and open source projects are so excited about this connectivity to cloud native environments that they have taken to calling their traditional storage “[cloud native](https://blog.openebs.io/cloud-native-storage-vs-marketers-doing-cloud-washing-c936089c2b58)”.\n\nIn order to explain why new tools and constructs are needed to improve the management of storage media, let’s start by reviewing pod connectivity. Shown below is a pod connected to external storage through a dynamic provisioner interface.\n![](https://cdn-images-1.medium.com/max/800/1*zm4UFgEvTWesM2JoxQF9Cg.jpeg)_Need for new tools and constructs in Kubernetes for managing disks_\nIn addition, we show the Local PV construct connected to local disks whether spinning or solid state.\n\nCurrently the Local PV can manage just a single disk. In a typical hyper-converged solution, more disks would be involved for a given pod. In addition to this single disk limitation, the following are limitations or gaps in the local PV feature.\n\n- Add disks / detach disks to a pod currently requires the pod to be restarted\n- Control and access to the storage is itself is limited. There will be a number of benefits of enabling access at times to the level of NUMA and to allowing CPU cores to be attached to the storage pod; keep in mind that these days using all the cores itself can be a challenge and driving up utilization is one of the central attributes of hyper converged systems\n- Today there is no standard ability to share the underlying disk. This is particularly important as extremely fast, and relatively expensive, NVMe SSD devices are now readily available and if shared they could be used as a cache for multiple Persistent Volumes\n- Lack of any fault management capabilities. Kubernetes needs to be able to receive and manage storage faults such as failures of the underlying disk, changes to the latency of disk IO\n\nWith these limitations in mind, we summarize needed enhancements as:\n\n- Capability to pool the disks, and provide an interface to manage the pooling\n- Capability to monitor disks, identify faults, forward them to the appropriate receivers\n\nIn the drawing above, these requirements are loosely shown as “constructs and tools to manage local disks”. These disk related constructs and tools are largely meant to be managed by Kubernetes cluster administrators and DevOps administrators in a Kubernetes like way.\n\nIt may be easier to think about this using human personas. Let’s say a DevOps developer is interested in connecting a working storage volume to their workload. Meanwhile a DevOps admin wants to rely as much as possible on Kubernetes to deliver storage services.\n\nToday, DevOps admins are forced to turning to different storage solutions to create storage classes as opposed to having a generic way of writing solutions around creating storage classes in a k8s native way. The DevOps admin would love to have a native k8s way to create storage classes so that they can standardize on an approach irrespective of the underlying storage systems or even storage cloud services.\n![](https://cdn-images-1.medium.com/max/800/1*17YT5-GR_JUXEq6qW2SD1A.jpeg)_Using and constructing a storage class in Kubernetes_\n\n## Some thoughts on what these new disk related constructs and tools could be\n\nJust like storage connectivity issue is solved with a dynamic volume provisioner, we could introduce pool provisioners into Kubernetes.\n![](https://cdn-images-1.medium.com/max/800/0*eM2LjKDvhbl62mjG.)Proposed disk related constructs and interfaces\nAs shown above, DevOps administrators will have the required tools to design the storage policy decisions. A toolset called is created node-disk-manager to provision, monitor and manage disks on the node. The disks are then grouped into pools by an interface called pool provisioner. The pool provisioner gives a generic set of APIs to consume the kubernetes disk objects and create a storage technology specific pools such as OpenEBS cStorPool, OpenZFS zpool, GlusterPool etc.The advantage of representing the pools in native Kubernetes constructs is that Kubernetes native tools can be extended to manage these new constructs.\n\nWith these constructs, the end-to-end volume provisioning work flow could be depicted like below.\n![](https://cdn-images-1.medium.com/max/800/1*9bAs7wOPNNGLxELpgP-4FA.jpeg)_New proposed workflow for managing local disks and achieving true hyper convergence in Kubernetes_\n\n## Conclusion:\n\nKubernetes native constructs and tools to manage and monitor local disks will help move towards achieving true hyper-convergence. We have observed many users in the OpenEBS community are using OpenEBS dynamic provisioner seamlessly, and requesting tools to manage the disks and storage pools. We are thinking of adding such tools to Kubernetes itself so that they are available to the larger community. A draft design proposal is available at We are looking forward to proposing and discussing these thoughts with K8S SIG leadership.\n\nWe are cooking up some draft proposals in the OpenEBS project before we take the to K8S SIG. Your feedback is appreciated and needed.\n\n### Disk Manager design:\n\n[https://docs.google.com/presentation/d/11GLg21x7G-nMTNw8aNIOhhjW\\_-eK19zSI9Xm-0jYHKs/edit?usp=sharing](https://docs.google.com/presentation/d/11GLg21x7G-nMTNw8aNIOhhjW_-eK19zSI9Xm-0jYHKs/edit?usp=sharing)\n\n[https://github.com/kmova/node-bot/blob/3cb83976a5392003d02275f8a94d1860257915f0/design/node-storage-management.md](https://github.com/kmova/node-bot/blob/3cb83976a5392003d02275f8a94d1860257915f0/design/node-storage-management.md)\n\n### Pool Provisioner design:\n\n[https://github.com/kmova/openebs/blob/35fb65540b17ad3da3df270ccc425c4ec417ca12/contribute/design/proposal-cstor-orchestration.md](https://github.com/kmova/openebs/blob/35fb65540b17ad3da3df270ccc425c4ec417ca12/contribute/design/proposal-cstor-orchestration.md)\n","slug":"achieving-native-hyper-convergence-in-kubernetes"},{"id":29,"title":"The Mule and (the) Flash — going for a run?","author":"Jeffry Molanus","author_info":"Jeffry is the CTO at MayaData. At MayaData, his primary focus is to make sure the product is flexible and scalable. When he is not working with code, he practices martial arts.","date":"26-02-2018","tags":["Kubernetes","Cloud-Storage","Container"],"content":"\nIn this blog, I discuss why we are building an innovative approach to user IO for the purpose of containerized storage, in particular vhost. If you just want the code, take a look at [https://github.com/openebs/vhost-user](https://github.com/openebs/vhost-user).\n\nFirst off, as mentioned in previous blog articles, OpenEBS is not yet another distributed file system. Let’s reiterate the reasoning behind this:\n\n- As microservices typically require only a small (relatively) amount of storage, there is no need to build a scale-out storage system\n- As Direct-attached Storage (DAS), in particular, NVMe, is the fastest storage you can get, you want the workload and the controller to be local with respect to each other; this is true even with SSD cloud storage offerings like AWS EBS instances\n- As single NVMe devices can reach 450K IOPS per device or[ more](https://www.prnewswire.com/news-releases/supermicro-delivers-groundbreaking-18-million-iops-of-storage-performance-in-new-2u-ultra-server-300508258.html) there is no longer any need to “scale out” to achieve high IOPS or low latency, in fact, scale-out adds latency as per the above argument\n\nFinally, distributed applications are complex by nature. When you are building microservices, you are in fact, developing a distributed application. It seems unwise to put one distributed application on top of the other (storage) and sleep well at night. All that work you’ve done limiting single points of failure in your application layer can be undone through the use of complex distributed storage.\n\nAnother fundamental aspect of OpenEBS is that it runs in user space. This too has, we like to believe, a significant advantage as it does not require you to [build a kernel module](https://github.com/portworx/px-fuse) and taint your kernel (in case of closed source) with out-of-tree code. But it does not stop there; if you want to move your data from cloud to cloud (c2c), you do not have to worry about kernel version mismatches or anything like that. User space is the new kernel — when it comes to IO.\n\nBut what about performance? Linus Torvals himself said some years ago that file systems in user space are nothing but[ toys](https://www.phoronix.com/scan.php?page=news_item&px=OTYwMA). But, as it turns out, with these low latency SSDs and high-speed networking (100GbE) the kernel, in fact, has become the bottleneck!\n\n**“fuse works fine if the thing being exported is some random low-use interface to a fundamentally slow device.”**\n\nSo it seems that we have reached an impasse? The kernel appears to be the bottleneck, and user space implementations are just “toys.” Or have we? When you look into why IO in user space is slow, it’s mostly due to the inability to do DMA, the required context switches and the copying in and out of data. What if we could avoid this? Also, you as you may know, hardware is already causing a change in the way we do things — 3D XPoint™ next to NVMe. This can be seen by technologies applied in SPDK and others like FD.IO. As OpenEBS is storage in containers, we have started to work on what we call the IOC, or the IO Container using these technologies**.**\n\n**\\*\\*\\***The IOC runs in user space and can do IO to the underlying hardware, bypassing the kernel altogether. It owns a set of resources (CPU, NICs, memory, and storage) and applies polling for IO instead of being interrupt driven.**\\*\\*\\***\n\nWith 18-core desktop computers being available today, it’s hardly an issue to use a core or two dedicated for IO — in the user space.\n\nBecause the IOC exposes block devices, we need a way to connect these devices to the other containers. Luckily — the VM space solved that problem for us: v[host](http://www.spdk.io/doc/vhost.html). By reusing these approaches, we create high a speed connection between the IOC and the containerized storage controller without making a change to the applications.\n![](/content/images/2020/01/IOC-model-with-vhost-user-interface-and-vpp.png)_IOC model with vhost user interface and VPP_\nThe above picture tries to depict the situation on a single node. As the application sends its IO through a block protocol (the target), OpenEBS — through the shared vhost subsystem — sends the IO to the replica which applies storage logic to it. With storage logic, we mean things that allow OpenEBS to do Copy-on-write (COW), snapshots, clones, compression or whatever is required. Also, OpenEBS is starting to further leverage this architecture to alter data management parameters including replication and snapshot patterns and even lower level parameters as well as block size in those containers depending on the workload.\n\nThen finally, the IO is submitted again to the IOC where an adaptive polling algorithm waits for its completion. Note, that the target — replicates **n** copies to the other node(s) which is depicted with R(n).So instead of doing IO through the kernel, your application passes the IO to the IOC which takes care of completing the IO as fast as possible all from user space.\n\nWith this approach, we get the best of both worlds and are in fact capable of surpassing the performance you would get when doing the same in the kernel — hands down — while also providing per workload granularity of control.\n![](/content/images/2020/01/user-space-outperforming-the-kernel.png)User space outperforming the kernel\nAs you can see from the repository, the design is fairly straightforward and is intended to support both legacy workloads as well as those built for faster underlying storage. We welcome input and contributions from anyone.\n\nWhile the vHost work stands alone it is central to a new storage engine forthcoming in OpenEBS 0.6, code named ‘cStore’.\n\nWe would really like your input so please[ open an issue](https://github.com/openebs/vhost-user/issues) or join us on Slack to discuss at[ openebs-community.slack.com](http://openebs-community.slack.com/) or just contact me directly. I can be reached at Twitter at[ @jeffrymolanus](https://twitter.com/jeffrymolanus)\n","slug":"the-mule-and-the-flash-going-for-a-run"},{"id":30,"title":"OpenEBS plus Red Hat OpenShift and StackPointCloud and IBM Cloud Private and….","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"05-02-2018","tags":["DevOps","Docker","Kubernetes","Updates","Openebs"],"content":"\nThis week we [announced](https://www.prnewswire.com/news-releases/openebs-certified-with-red-hat-openshift-stackpointcloud-and-ibm-cloud-672729373.html) that our partnership with Red Hat is flourishing. We achieved their Primed level of certification for their OpenShift offerings and are seeing more and more users rely upon OpenShift and Kubernetes as a means to provide persistence to their workloads.\n\nThe alternative pattern, of course, is to connect to an external storage system. Solutions like Rook and others such as the CSI efforts of RexRay and many others enable the use of external storage.\n\nActually — so does OpenEBS :)\n\nOpenEBS can and often does use external storage underneath. With OpenEBS, however, every workload has its own storage controller(s) that themselves are easily orchestrated by Kubernetes and data is local by default. There are three main benefits to the OpenEBS containerized architecture that external only storage cannot address due to architectural limitations:\n\n- \\***\\*The granularity of control\\*\\*** — with OpenEBS the storage controller interprets ever more individualized and extensive storage policies and makes them so for each workload. Because OpenEBS is a full system (or is becoming one :)), it offers far more control than centralized storage that itself has to address the sometimes competing needs of countless — hundreds — of workloads. Developer teams can take on storage knowing they are much less constrained than they are working with least common denominator external storage.\n- \\***\\*No SPOF\\*\\*** — in an age in which chaos engineering is becoming more and more popular, the notion of a sacrosanct dependency that cannot itself be disrupted or the entire system crashes potentially into a non-recoverable state is anachronistic. Put more directly — shared scale-out storage is an anti-pattern for many. Blast Radius.\n- \\***\\*Performance\\*\\*** — as storage heads, we too often likely focus on performance. However, OpenEBS does work with databases, and in some cases the speed at which you run those workloads directly translates into user experience and hence money. So the tax a scale out storage system puts on performance versus the insane and rapidly accelerating speed of direct attached is essential. Ironically, scale-out first arose in part to work around how slow local disk was; times have changed. If you are interested in performance, you’ll want to grab our cStore by the way which, as the name suggests, is written in C and does much else as well to build upon our inherently faster Container Attached Approach. Stay tuned…\n\nSo why Red Hat and why StackPointCloud?\n\nIn both cases, we see organizations that are doing an incredible job helping their target users adopt Kubernetes based orchestration. With Red Hat, we tend to see especially larger enterprises taking the approach. With StackPointCloud, there is a real mix of departmental level users at large organizations as well as countless start-ups. In both cases, our support of Helm charts for OpenEBS makes it trivial to spin OpenEBS up.\n\nWhile OpenEBS itself as not achieve 1.0 status, we are working hand in hand w/ partners to make sure users are succeeding in their use of OpenEBS for stateful workloads. There must now be at least hundreds of production proof of concept deployments ongoing. We will be making [MayaOnline](http://www.mayaonline.io/) freely available to help these and other users in the near future via no cost monitoring and control and ChatOps integrations.\n\nPlease get in touch via [Slack](https://join.slack.com/t/openebs-community/shared_invite/enQtMjQzMTg4NTcyNTY2LTJiMzVjYjA5ZDk3YmI4NjAxY2QyYmI3MTA1MmUxMTAzNTU0NTM5NTViOTIxMjA1NWQ4NzVmMTBiNjk0NDU1YzQ) or otherwise if you would like to spend a little time with us to discuss your use cases and, of course, if you are running OpenEBS and testing it out.\n","slug":"openebs-plus-red-hat-openshift-and-stackpointcloud-and-ibm-cloud-private-and"},{"id":31,"title":"How to install OpenEBS on OpenShift?","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"22-01-2018","tags":["Kubernetes","Mongodb","Openshift","Percona","Solutions","Openebs"],"content":"\n## What is OpenShift Origin?\n\n**OpenShift Origin** is the upstream community project used in all deployment models provided by Red Hat OpenShift such as **OpenShift Online**, **OpenShift Dedicated**, and **OpenShift Container Platform**. **Red Hat OpenShift** is an enterprise container application platform that is based on a core of **Docker **container packaging, **Kubernetes **container cluster management and the **OpenShift Origin** project itself.\n\nFirst, having more than one option sounds confusing, but they clearly differentiate from each other. Here is the summary of all available deployment models to start with OpenShift.\n\n- [**OpenShift Origin**](https://www.openshift.org/) is a distribution of Kubernetes optimized for continuous application development and multi-tenant deployment. Origin is open source and all source code for the Origin project is available under the Apache License v2.0 on GitHub. Website and documentation for the Origin project are under [www.openshift.org](https://www.openshift.org/). It is completely free, you can deploy Origin on baremetal, in a VM or on a cloud. This is the option I will focus on this article.\n- [**OpenShift Online**](https://manage.openshift.com/) is Red Hat’s public cloud application development and hosting service. Starter plan is free to use and includes 1 project, 1GiB memory, 1GiB terminating memory and 1GiB storage. Pro Plan costs $50/month and includes 10 projects, 2GiB memory, 2GiB terminating memory and 2GiB storage. Details are available [here](https://www.openshift.com/pricing/index.html).\n- [**OpenShift Dedicated**](https://www.openshift.com/dedicated/index.html) is Red Hat’s managed private cluster offering, built around a core of application containers powered by Docker, with orchestration and management provided by Kubernetes, on a foundation of Red Hat Enterprise Linux. It’s available on the Amazon Web Services (AWS) and Google Cloud Platform (GCP) marketplaces. A complete OpenShift 3 cluster, configured for high availability (HA) with a minimum of 5 masters, infrastructure nodes and 4 application nodes managed by Red Hat costs $48k. Details are available [here](https://www.openshift.com/dedicated/index.html#pricing).\n- [**OpenShift Container Platform**](https://www.openshift.com/container-platform/index.html) (formerly OpenShift Enterprise) is Red Hat’s on-premise private PaaS product.\n\nIn this blog post, I will focus on configuring **OpenEBS** as a **persistent storage** option on the open-source self-managed **OpenShift Origin** and deploy a stateful workload both from CLI and custom catalog template using OpenEBS storage classes.\n\n## Prerequisites\n\n### Hardware\n\n- Minimum two nodes. Recommended four or more (Baremetal, VMs or cloud instances)\n\n### Software components used\n\n- [CentOS 7.x](https://www.centos.org/download/)\n- [OpenShift Origin 3.7+](https://github.com/openshift/origin)\n- [OpenShift-Ansible](https://github.com/openshift/openshift-ansible) (master branch used for installation)\n- [OpenEBS 0.5.1](https://openebs.io/)\n\n**Note: **Make sure the following package dependencies are installed: python, wget, git, net-tools, bind-utils, iptables-services, bridge-utils, bash-completion, kexec-tools, sos, psacct, docker-1.12.6, ansible, pyOpenSS, httpd-tool\n\n### Install OpenShift Origin\n\nFollow instructions from [OpenShift Origin Latest Documentation](https://docs.openshift.org/latest/welcome/index.html) to deploy a multi-node Origin cluster. If you are deploying it for the first time it may be a bit complicated. I plan to post my notes, steps on getting minimum requirements satisfied and have a successful deployment after this post.\n\n### Verify OpenShift Origin deployment\n\nExecute the following commands to verify successful installation.\n\n    # oc get nodes\n\nNumber of nodes you see maybe different in your case, but status should looks similar to below showing nodes ready.\n\n    # oc get nodes\n     NAME STATUS AGE VERSION\n     oonode1 Ready 2d v1.7.6+a08f5eeb62\n     oonode2 Ready 2d v1.7.6+a08f5eeb62\n     oonode3 Ready 2d v1.7.6+a08f5eeb62\n     oonode4 Ready 2d v1.7.6+a08f5eeb62\n\n### Configure access permissions\n\nCreate a new admin user with cluster-admin role/permissions and assing password using the following commands:\n\n    # oc adm policy add-cluster-role-to-user cluster-admin admin — as=system:admin\n    # htpasswd /etc/origin/master/htpasswd admin\n\nLogin as the `admin` user and you will be using default project.\n\n    # oc login -u admin\n\nOutput:\n\n    # oc login -u admin\n     Authentication required for https://oonode1:8443 (openshift)\n     Username: admin\n     Password:\n     Login successful.\n    You have access to the following projects and can switch between them with ‘oc project <projectname>’:\n    * default\n     kube-public\n     kube-service-catalog\n     kube-system\n     logging\n     management-infra\n     openshift\n     openshift-ansible-service-broker\n     openshift-infra\n     openshift-node\n     openshift-template-service-broker\n     openshift-web-console\n    Using project “default”.\n\nProvide access to the host volumes which is needed by the OpenEBS volume replicas by updating the default security context (scc). If you miss this step your replicas will fail to deploy.\n\n    # oc edit scc restricted\n\nNow set `allowHostDirVolumePlugin: true` and save changes. The file should look like below:\n\n    # Please edit the object below. Lines beginning with a ‘#’ will be ignored,\n     # and an empty file will abort the edit. If an error occurs while saving this file will be\n     # reopened with the relevant failures.\n     #\n     allowHostDirVolumePlugin: true\n     allowHostIPC: false\n     allowHostNetwork: false\n     allowHostPID: false\n     allowHostPorts: false\n     allowPrivilegedContainer: false\n     allowedCapabilities: []\n     allowedFlexVolumes: []\n     apiVersion: v1\n     defaultAddCapabilities: []\n     fsGroup:\n     type: MustRunAs\n     groups:\n     — system:authenticated\n     kind: SecurityContextConstraints\n     metadata:\n     annotations:\n     kubernetes.io/description: restricted denies access to all host features and requires\n     pods to be run with a UID, and SELinux context that are allocated to the namespace. This\n     is the most restrictive SCC and it is used by default for authenticated users.\n     creationTimestamp: 2018–01–20T19:39:18Z\n     name: restricted\n     resourceVersion: “68274”\n     selfLink: /api/v1/securitycontextconstraints/restricted\n     uid: 9abddec5-fe19–11e7–8d06–005056873c08\n     priority: null\n     readOnlyRootFilesystem: false\n     requiredDropCapabilities:\n     — KILL\n     — MKNOD\n     — SETUID\n     — SETGID\n     runAsUser:\n     type: MustRunAsRange\n     seLinuxContext:\n     type: MustRunAs\n     supplementalGroups:\n     type: RunAsAny\n     users: []\n     volumes:\n     — configMap\n     — downwardAPI\n     — emptyDir\n     — hostPath\n     — persistentVolumeClaim\n     — projected\n     — secret\n\nSave changes.\n\n### Install OpenEBS on Origin\n\nThere are few easy ways to install OpenEBS. You can either apply the operator and storageclasses direct from the URL or clone the repo and execute from the local copy. I prefer to clone a local copy, but i’ll also give you the other option if you prefer.\n\nClone the latest OpenEBS files and sample application specs using the below command on your OpenShift master node:\n\n    # git clone https://github.com/openebs/openebs.git\n     # cd openebs/k8s\n\nApply the file two yaml files below:\n\n    # oc apply -f openebs-operator.yaml\n    # oc apply -f openebs-storageclasses.yaml\n\nAlternative way — If you choose not to copy from the repo you can apply the yaml file direct from the URL below:\n\n    oc apply -f https://openebs.github.io/charts/openebs-operator.yaml\n\n### Verify OpenEBS deployment\n\nVerify that the OpenEBS provisioner and API server are created successfully and running.\n\n    # oc get deployments\n     NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE\n     maya-apiserver 1 1 1 1 2d\n     openebs-provisioner 1 1 1 1 2d\n\nCheck pods to confirm maya-apiserver and openebs-provisioner.\n\n    # oc get pods\n     NAME READY STATUS RESTARTS AGE\n     docker-registry-1-b5r7t 1/1 Running 0 2d\n     maya-apiserver-3053842955-xbx8w 1/1 Running 0 2d\n     openebs-provisioner-2499455298–46brm 1/1 Running 0 2d\n     registry-console-1-mrpc9 1/1 Running 0 2d\n     router-1-bf775 1/1 Running 3 2d\n\nCheck services to confirm maya-apiserver exists.\n\n    # oc get service\n     NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE\n     docker-registry 172.30.113.229 <none> 5000/TCP 2d\n     kubernetes 172.30.0.1 <none> 443/TCP,53/UDP,53/TCP 2d\n     maya-apiserver-service 172.30.17.113 <none> 5656/TCP 2d\n     registry-console 172.30.148.98 <none> 9000/TCP 2d\n     router 172.30.229.239 <none> 80/TCP,443/TCP,1936/TCP 2d\n\nCheck service accounts for openebs-maya-operator:\n\n    # oc get sa\n     NAME SECRETS AGE\n     builder 2 2d\n     default 3 2d\n     deployer 2 2d\n     openebs-maya-operator 2 2d\n     registry 3 2d\n     router 2 2d\n    # oc get clusterrole openebs-maya-operator\n     \\NAME\n     openebs-maya-operator\n    # oc get clusterrolebindings openebs-maya-operator\n     NAME ROLE USERS GROUPS SERVICE ACCOUNTS SUBJECTS\n     openebs-maya-operator /openebs-maya-operator default/openebs-maya-operator, default/default\n\nAnd finally verify OpenEBS default storage classes.\n\n    # oc get sc\n     NAME TYPE\n     openebs-cassandra openebs.io/provisioner-iscsi\n     openebs-es-data-sc openebs.io/provisioner-iscsi\n     openebs-jupyter openebs.io/provisioner-iscsi\n     openebs-kafka openebs.io/provisioner-iscsi\n     openebs-mongodb openebs.io/provisioner-iscsi\n     openebs-percona openebs.io/provisioner-iscsi\n     openebs-redis openebs.io/provisioner-iscsi\n     openebs-standalone openebs.io/provisioner-iscsi\n     openebs-standard openebs.io/provisioner-iscsi\n     openebs-zk openebs.io/provisioner-iscsi\n\nAfter few easy steps we are now ready to deploy workloads on persistent storage provided by OpenEBS. I’ll cover both CLI and Catalog installation through the OpenShift Web Console.\n\n### Install Percona on OpenEBS using OC CLI\n\nUse OpenEBS as persistent storage for a Percona DB deployment by selecting the `openebs-percona` storage class in the persistent volume claim. I will use the sample file available in the openebs repo which I cloned locally in the previous steps.\n\nView the Percona deployment yaml:\n\n    # cd openebs/k8s/demo/percona\n    # cat demo-percona-mysql-pvc.yaml\n     — -\n     apiVersion: v1\n     kind: Pod\n     metadata:\n     name: percona\n     labels:\n     name: percona\n     spec:\n     containers:\n     — resources:\n     limits:\n     cpu: 0.5\n     name: percona\n     image: percona\n     args:\n     — “ — ignore-db-dir”\n     — “lost+found”\n     env:\n     — name: MYSQL_ROOT_PASSWORD\n     value: k8sDem0\n     ports:\n     — containerPort: 3306\n     name: percona\n     volumeMounts:\n     — mountPath: /var/lib/mysql\n     name: demo-vol1\n     volumes:\n     — name: demo-vol1\n     persistentVolumeClaim:\n     claimName: demo-vol1-claim\n     — -\n     kind: PersistentVolumeClaim\n     apiVersion: v1\n     metadata:\n     name: demo-vol1-claim\n     spec:\n     storageClassName: openebs-percona\n     accessModes:\n     — ReadWriteOnce\n     resources:\n     requests:\n     storage: 5G\n\nAs you can see in the yaml file above, `storageClassName` is set to `openebs-percona` which has 2 replicas.\n\nNow, apply the file:\n\n    # oc apply -f demo-percona-mysql-pvc.yaml\n\nFinally, verify that Percona is deployed and OpenEBS controller and replica are running:\n\n    # oc get pods\n     NAME READY STATUS RESTARTS AGE\n     docker-registry-1-b5r7t 1/1 Running 0 2d\n     maya-apiserver-3053842955-xbx8w 1/1 Running 0 2d\n     openebs-provisioner-2499455298–46brm 1/1 Running 0 2d\n     percona-1378140207–5q2gb 1/1 Running 0 15mh\n     pvc-c7a24dc8-ffc7–11e7-a7cd-005056873c08-ctrl-1719480235-xf4t5 2/2 Running 0 15m\n     pvc-c7a24dc8-ffc7–11e7-a7cd-005056873c08-rep-1550141838-ldm59 1/1 Running 0 15m\n\n### Install MongoDB on OpenEBS using the OpenShift Web Console\n\nLogin to the OpenShift Web Console using the admin credentials we have created earlier.\n![](https://cdn-images-1.medium.com/max/800/0*-IbP4t-ZgYZx4qh6.png)\nClick on **Add to Project** button and select **Import YAML / JSON**.\n![](https://cdn-images-1.medium.com/max/800/0*FEwbuF146LMi7Zsx.png)\nCopy the content of [https://raw.githubusercontent.com/openebs/openebs/master/k8s/openshift/examples/v3.7/db-templates/openebs-mongodb-persistent-template.json](https://raw.githubusercontent.com/openebs/openebs/master/k8s/openshift/examples/v3.7/db-templates/openebs-mongodb-persistent-template.json) file and paste into **Import YAML / JSON** window.\n![](https://cdn-images-1.medium.com/max/800/0*d6b0iSD6JG83ad-N.png)\nClick on **Create** button, select **Save template** and click **Continue**.\n![](https://cdn-images-1.medium.com/max/800/0*14UvCpI6Gf-Q5Pd2.png)\nOn the **Template Configuration** window make sure Storage Class is `openebs-standard` and click on **Create**.\n![](https://cdn-images-1.medium.com/max/800/0*l_agQ7YUPJnqvKkq.png)![](https://cdn-images-1.medium.com/max/800/0*K8665fQzu2nIGNZh.png)![](https://cdn-images-1.medium.com/max/800/0*E6Vp2d7hqBWtJpzm.png)\nYou have successfully deployed MongoDB on a persistent storage provided by OpenEBS.\n\n---\n\n_Originally published at _[_Containerized Me_](http://containerized.me/how-to-install-openebs-on-openshift/)_._\n","slug":"how-to-install-openebs-on-openshift"},{"id":32,"title":"Using OpenEBS as a Kubernetes persistent volume","author":"Jimmy Song","author_info":"Developer Advocate at Ant Financial, CNCF Ambassador, co-founder of ServiceMesher community, blog https://jimmysong.io","date":"10-01-2018","tags":["Kubernetes","Openebs","Docker","Cloud-Native"],"content":"\n[OpenEBS](https://www.openebs.io/) is a containerized block storage written in Go for cloud native and other environments which make the data workloads more reliable in Kubernetes.\n\nOpenEBS is open sourced by [MayaData](http://www.mayadata.io/) who is a professional containerized storage company formerly known as CloudByte. Their vision is to make data workloads easy to use in Kubernetes across clouds or on premise.\n\nWe know that [EBS](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://amazonaws-china.com/cn/ebs/&usg=ALkJrhhv8rYmHkvvZS_bPmr_Ca1Wj24SnA) (Elastic Block Storage) is available in AWS, persistent block storage for Amazon EC2 to meet the functional and performance requirements of the most demanding applications, and OpenEBS is its open source implementation.\n\n## Introduction\n\nWith OpenEBS, you can treat containers that have persistent data as you would any other common container. OpenEBS itself is also deployed through containers that support Kubernetes, Swarm, Mesos, Rancher orchestration scheduling, and storage services can be assigned to each pod, application, cluster, or container level, including:\n\n- Data persistence across nodes\n- Synchronize data across available zones and cloud vendors\n- Use commercial hardware and container engines to provide highly scalable block storage\n- Integration with the container orchestration engine, the developer’s application can automatically configure OpenEBS\n- Based on CloudByte’s container-based experience in BSD, we provide users with OpenEBS QoS assurance\n\n## Architecture\n\nThe OpenEBS storage controller itself runs in a container. OpenEBS Volume consists of one or more containers that run microservices. This storage controller function is based on a microservices architecture — the data for each volume is provided by its own set of containers, not by a single monolithic storage controller that provides control for multiple volumes at the same time To provide. This is the essential difference between OpenEBS and traditional storage devices.\n\nThe OpenEBS architecture can be divided into Data Plane (Data Plane) and Control Plane (Control Plane) in two parts:\n\n- Data Plane: Provides data storage for applications\n- Control Plane: Managing OpenEBS Volume Containers, which typically uses the functionality of container layout software\n\n## Data plane\n\nThe following figure shows the architecture of OpenEBS deployed on Kubernetes cluster. Among them, the yellow or orange part is the OpenEBS persistent storage volume, created by Kubernetes’ PVs, implemented using iSCSI, and stored on host nodes or in the cloud (such as EBS, GPD, etc.) depending on where your cluster is deployed. The OpenEBS volume is completely independent of the user’s application life cycle to manage, which is Kuberentes PV in the basic idea.\n![](/content/images/2020/01/openebs-data-plane.png)OpenEBS Cluster - Data Pane\nOpenEBS volumes provide persistent storage for containers with resiliency to system failures and faster access to storage, snapshots and backups. In addition, it provides mechanisms for monitoring usage and enforcing QoS policies.\n\nThe disk that stores the data is called the storage backend and can be a host directory, an attached block device, or a remote disk. Each OpenEBS volume contains an iSCSI target container (represented as openebs-vol1 in the previous figure) and one or more replica containers (openebs-vol1-R1 and openebs-vol1-R2).\n\nThe application pod accesses the storage through the iSCSI target container, which copies the data to all of its replicas. In the event of a node failure, the iSCSI target container starts from one of the remaining online nodes and provides data by connecting to the available replica containers.\n\n\\***\\*Source\\*\\***\n\nThe implementation of this section consists of two containers:\n\n- [openebs/jiva](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/jiva&usg=ALkJrhhhCfHb4LkQReHbpayqLJwjwdctgw) : storage control functions, including copy logic\n- [openebs/gotgt](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/gotgt&usg=ALkJrhgoXb10SL2TVf8_urB_TIfEVSDBxg) : iSCSI target features used by openebs/jiva\n\n## Control plane\n\nThe OpenEBS control plane is also known as maya. The purpose is to create a hyper-converged OpenEBS that is mounted on a container scheduling engine such as Kubernetes, Swarm, Nomad, etc. to extend the storage capabilities provided by a particular container orchestration system.\n![](/content/images/2020/01/openebs-control-plane.png)OpenEBS Cluster - Control Plane\nOpenEBS’s control plane is also based on microservices, and its services can be divided into the following sections:\n\nContainer layout plug-in, used to enhance the function of the strong container layout framework:\n\n- \\***\\*Kubernetes Dynamic Configuration\\*\\*** : [openebs-provisioner](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/external-storage/tree/master/openebs&usg=ALkJrhjuOf_IBvwR0NC-g734l_p4Ia14hg)\n- \\***\\*Kubernetes-dashboard\\*\\*** : [openebs-dashboard](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/dashboard&usg=ALkJrhigRmJSDzmVT_NRMupygPwAM5EX9g)\n- \\***\\*Extended schema\\*\\*** : Kubernetes-based CRDs (custom resource defination) that store OpenEBS-related configuration data\n\nCluster services provide OpenEBS-specific storage intelligence such as:\n\n- \\***\\*maya-apiserver\\*\\*** : Contains APIs for performing volume operations that translate requests into container-specific system-specific operations\n- \\***\\*maya-mulebot\\*\\*** : Use the information collected to suggest optimized layout and event handling tips\n- \\***\\*maya-connect\\*\\*** : Allows monitoring data to be uploaded to `maya-cloud` for further storage access mode analysis\n\nNode Services, which provide OpenEBS-specific storage intelligence that runs with kubelet, such as:\n\n- \\***\\*maya-agent\\*\\*** : Includes storage management features\n\nBy using prometheus, heapster, grafana and jaegar for these services, you can add monitoring and tracking capabilities.\n\n\\***\\*Source\\*\\***\n\n- [openebs / maya](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/maya&usg=ALkJrhgksSLVDOSt9WRSnCdGdaf4nezkyQ) : All of the specific binary code (non-plugins) is stored in this repository, such as `maya-apiserver` , `maya-agent` , `maya-mulebot` , `maya-connect` , `mayactl` and more.\n- [openebs-dashboard](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/dashboard&usg=ALkJrhigRmJSDzmVT_NRMupygPwAM5EX9g) : A branch of the kubernetes-dashboard project that extends storage capabilities.\n- [openebs-provisioner](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=https://github.com/openebs/external-storage/tree/master/openebs&usg=ALkJrhjuOf_IBvwR0NC-g734l_p4Ia14hg) : The OpenEBS K8s Provisioner from the Kubernetes incubator project.\n\n## Install OpenEBS on Kubernetes\n\nBelow we will use the way to install OpenEBS operator, you need to make sure you have already installed iSCSI on your node before installation.\n\n## Prerequisites\n\nOpenEBS relies on iSCSI for storage management, so you need to make sure that you have OpenEBS installed on your cluster.\n\n\\***\\*Note\\*\\*** : If you are using kubeadm, container-mounted kublet, it comes with iSCSI and does not need to be manually installed. For a kubelet installed directly on the bare metal in binary form, you need to install iSCSI yourself.\n\nThe iSCSI (Internet Small Computer System Interface) is a TCP / IP-based protocol used to establish and manage interconnections between IP storage devices, hosts and clients, and to create storage area networks (SANs ). The SAN makes it possible for the SCSI protocol to be used in high-speed data transmission networks, with block-level data transfer between multiple data storage networks. The SCSI architecture is based on C/S mode and is typically used in environments where devices are close to each other and these devices are connected by a SCSI bus.\n\nOpenEBS needs to use iSCSI as a storage protocol, and CentOS default does not have iSCSI installed, so we need to manually install.\n\nThere are two types of roles in iSCSI:\n\n- \\***\\*target\\*\\*** : used to provide storage (server)\n- \\***\\*initiator\\*\\*** : use the stored client (client)\n\nThe following figure in Kubernetes uses iSCSI architecture (Source: [http://rootfs.github.io/iSCSI-Kubernetes/)](https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.co.in&sl=zh-CN&sp=nmt4&tl=en&u=http://rootfs.github.io/iSCSI-Kubernetes/%25EF%25BC%2589&usg=ALkJrhgk4iuBd1pHB1zGq6XKLwffkSGZew)\n![](/content/images/2020/01/iscsi-kubernetes.png)iSCSI-Kubernetes\nInstalling the iSCSI service is very simple, you do not need additional configuration, just start the service after installation.\n\nExecute the following command on each node node:\n\n    yum -y install iscsi-initiator-utils systemctl enable iscsid systemctl start iscsid\n\n## Quick start\n\nRun the OpenEBS service using Operator:\n\n    wget https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-operator.yaml kubectl apply -f openebs-operator.yaml\n\nUse the default or custom storageclass:\n\n    wget https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-storageclasses.yaml kubectl apply -f openebs-storageclasses.yaml\n\nMirror used are:\n\n- openebs/m-apiserver: 0.5.1-RC1\n- openebs/openebs-k8s-provisioner: 0.5.1-RC2\n- openebs/jiva: 0.5.1-RC1\n- openebs/m-exporter: 0.5.0\n\n## Test\n\nLet’s use the Example from the official OpenEBS documentation to install the Jenkins test:\n\n    wget https://raw.githubusercontent.com/openebs/openebs/master/k8s/demo/jenkins/jenkins.yml kubectl apply -f jenkins.yml\n\nCheck PV and PVC\n\n    $ kubectl get pv\n    NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\n    pvc-8e203e86-f1e5-11e7-aa47-f4e9d49f8ed0 5G RWO Delete Bound default/jenkins-claim openebs-standard 1h\n    $ kubectl get pvc kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\n    jenkins-claim Bound pvc-8e203e86-f1e5-11e7-aa47-f4e9d49f8ed0 5G RWO openebs-standard 1h\n\nView Jenkins pod:\n\n    Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 29m (x2 over 29m) default-scheduler PersistentVolumeClaim is not bound: \"jenkins-claim\" (repeated 3 times) Normal Scheduled 29m default-scheduler Successfully assigned jenkins-668dfbd847-vhg4c to 172.20.0.115 Normal SuccessfulMountVolume 29m kubelet, 172.20.0.115 MountVolume.SetUp succeeded for volume \"default-token-3l9f0\" Warning FailedMount 27m kubelet, 172.20.0.115 Unable to mount volumes for pod \"jenkins-668dfbd847-vhg4c_default(8e2ad467-f1e5-11e7-aa47-f4e9d49f8ed0)\": timeout expired waiting for volumes to attach/mount for pod \"default\"/\"jenkins-668dfbd847-vhg4c\". list of unattached/unmounted volumes=[jenkins-home] Warning FailedSync 27m kubelet, 172.20.0.115 Error syncing pod Normal SuccessfulMountVolume 26m kubelet, 172.20.0.115 MountVolume.SetUp succeeded for volume \"pvc-8e203e86-f1e5-11e7-aa47-f4e9d49f8ed0\" Normal Pulling 26m kubelet, 172.20.0.115 pulling image \"sz-pg-oam-docker-hub-001.tendcloud.com/library/jenkins:lts\" Normal Pulled 26m kubelet, 172.20.0.115 Successfully pulled image \"sz-pg-oam-docker-hub-001.tendcloud.com/library/jenkins:lts\" Normal Created 26m kubelet, 172.20.0.115 Created container Normal Started 26m kubelet, 172.20.0.115 Started container\n\nStart up successful. The Jenkins configuration uses \\***\\*NodePort\\*\\*** mode access and now accesses the NodePort of Jenkins service for any node in the cluster.\n\n## Reference\n\n- [OpenEBS Documentation](http://openebs.readthedocs.io/)\n- [CentOS 7.x 下配置 iSCSI 网络存储](http://blog.csdn.net/wh211212/article/details/52981305)\n- [Configure iSCSI Initiator](https://www.server-world.info/en/note?os=CentOS_7&p=iscsi&f=2)\n- [https://www.openebs.io/](https://www.openebs.io/)\n- [https://github.com/openebs/openebs](https://github.com/openebs/openebs)\n- [Data Scientists adopting tools and solutions that allow them to focus more on Data Science and less on the infrastructure around them](https://blog.openebs.io/data-scientists-adopting-tools-and-solutions-that-allow-them-to-focus-more-on-data-science-and-less-db9654063bd5)\n- [RHEL7: Configure a system as either an iSCSI target or initiator that persistently mounts an iSCSI target.](https://www.certdepot.net/rhel7-configure-iscsi-target-initiator-persistently/)\n\nOriginal page: [https://jimmysong.io/posts/using-openebs-as-kubernetes-persistent-volume/](https://jimmysong.io/posts/using-openebs-as-kubernetes-persistent-volume/)\n\nTranslated from Chinese to English by Google Translate\n","slug":"using-openebs-as-a-kubernetes-persistent-volume"},{"id":33,"title":"\"In 2018 - IT dreams deferred finally achieved?\"","author":"Evan Powell","author_info":"Founding CEO of a few companies including StackStorm (BRCD) and Nexenta — and CEO & Chairman of OpenEBS/MayaData. ML and DevOps and Python, oh my!","date":"09-01-2018","tags":["Containerization","Docker","Kubernetes","Openebs","Storage"],"content":"\n# **_…..Dreams deferred_**\n\nMany of us in the infrastructure business have been forced by experience to lower our expectations of what is possible. While we’ve all dreamed for decades of a world in which software just works — and delivers value where and how it is needed — we’ve been disappointed again and again.\n\nWe have seen open systems that, over time, became increasingly proprietary with Unix diverging into proprietary camps.\n\nWe’ve seen SQL go from a fascinating research project to a broadly deployed standard to, with the help of stored procedures and truly nefarious licensing, a source of lock-in dominated by one company and one eccentric multi-billionaire.\n\nWe’ve seen a vision of Java as a cross infrastructure abstraction layer bloom and wither.\n\nAnd of course, we’ve seen virtual machines offer the promise of cross infrastructure mobility only to fall prey to the rest of the stack and proprietary business models and incorrect levels of abstraction.\n\nOver time the result has been infrastructure by silos, with each silo — security, storage, networking and compute — dominated by proprietary solution providers that over time sought to provide the entire stack to drive up their sales, even if doing so meant increasing the friction for users seeking to combine best of breed solutions.\n\n# **_On the other hand…._**\n\nAll along technological progress has continued. Allowing for new possibilities.\n\nWe’ve even seen — finally — broadband make its way into the United States so that more and more we can cost effectively access the cloud (yes, the loss of net neutrality seems to put this at risk for at least consumers and new entrants).\n\nAnd intra data center networking has gotten insanely fast — which is crucial if we are to run workloads in a flexible manner.\n\nAnd arguably the best example of innovation at scale in modern business — Amazon — focusing on the right persona — the developer — and raising the bar massively for all of us in infrastructure.\n\nAnd perhaps most importantly, the Open Source community, which as Richard Stallman and others have pointed out predates the commercial software world and which some have called the world’s first social network, grew to become an undeniable force.\n\nAnd pulling all the positive forces together — DevOps and microservices. DevOps as a cultural movement and approach to building and running software at scale PLUS an emerging understanding of how to run systems via microservices as explained by the [12 factor approach](https://www.12factor.net/) and elsewhere led to countless examples of “software eating the world.”\n\n# **But …. What about lock-in?**\n\nSo as the above suggests, one theme in the story of innovation in IT over the years has been breakthrough technologies, and business models, enabling fundamentally better software delivered more easily to users. And as one approach came to predominate, proprietary approaches over time led to more “rent seeking”, where leading vendors extracted more value from their users and slowed their innovation. And this stagnation leads to pent up demand for better approaches — triggering the next cycle.\n\nWell — what about this time?\n\nKubernetes has emerged in part because it promises a world more free from lock-in to AWS and other clouds. Could it be that we have collectively learned enough from all the boom and bust cycles to know what is good for us?\n\nCould be — the signs are incredibly promising as all the cloud vendors and RedHat and Cloud Foundry and Docker and Mesos have all embraced Kubernetes as the standard control plane. This means that you are no longer locked-in by the control plane logic and should be able to move your applications from cloud to cloud and from on premise to off. Crucially — Kubernetes itself is open source and all the major vendors have pledged to not fork it; so it shouldn’t be _too_ bad to move from one vendor supporting Kubernetes to another.\n\n**…. but what about data? **Without data mobility all you can move is the stateless components of your applications — provided you address having those components able to access your store of state.\n\n# **And your data remains largely locked-in**\n\n**Locked into** proprietary vendors.\n\n**Locked into** underlying systems that are sources of risk and that themselves are resolutely monolithic.\n\nI harken back to a speech Randy Bias gave at one of the OpenStorage summits I helped host back in 2010 about “blast radius.” The basic idea is that microservices dramatically reduce the blast radius of any single outage; conversely putting all your state in a shared storage system is, by comparison, an anti-pattern. When your shared storage dies or slows down unexpectedly perhaps due to a rebalancing, so does your entire environment. So much for being built for failure!\n\nS3 for non performant data and EBS for performant data have become defacto standards. They are easy, they “just work”, and — crucially — they put the responsibility for the configuration, care and feeding of state in the hands of the teams that also control the microservices.\n\nThe only problem is that it is _hard_ to move your data from these AWS services to other solutions without a lot of work that frankly software development teams don’t have the time or inclination to invest. I see the lock-in that results as the TBs pile up treated much as technical debt is treated — it is annoying and yet it is much less important than getting valuable capabilities in the hands of end users.\n\nAnd putting all your data in a scale-out software solution running on these clouds only makes the issue worse. Now you have the blast radius issue and you have your data stored in a solution that cannot be stretched across clouds. Two sources of lock-in and at least twice the effort!\n\nIt might be worth remembering that networking, security and compute are all becoming both infrastructure services delivered as services **to** today’s microservice environments and \\***\\*are themselves also microservice based services\\*\\***. Take a look at Project Calico for instance. Or at Kubernetes itself.\n\nN**obody says — hey, Kubernetes is just a black box that sits to the side and so it needn’t be a bunch of microservices. But not storage. Storage somehow gets a pass. It gets to live with aged architectures and typically aged business models.**\n\n## Which raises the question: What if storage was itself delivered as microservices and orchestrated by Kubernetes?\n\nFor the purpose of this exercise, **assume** it were possible to make storage a set of capabilities delivered as microservices with the controller running on containers.\n\nYou’d probably agree that such an approach would have some benefits including:\n\n**Familiarity:**\n\n- If storage is delivered as microservices within Kubernetes then if you know how to run Kubernetes then you know how to run the storage.\n- Perhaps more importantly, you are familiar with the failure domain. You lose a storage controller — well, you just lost a stateless container that itself simply provides services and pointers towards the underlying data. Your data is always safe in multiple locations and your storage system itself is resilient (at least the way OpenEBS is architected with the use of atomic transactions).\n\n**Granularity:**\n\n- As mentioned above, the defacto standard approach to delivering storage is to use AWS itself with each team organized around one or more microservices having their own approach to EBS for performant storage and S3 for blobs of data.\n- Using a shared storage system runs counter to this approach and cuts these teams out of the loop. They are back to lobbying central IT as one of hundreds or even thousands of workloads with particular desires as to how storage should be configured. And, yes, those configurations matter. And, actually, they are impossible to get right. We’ve talked about that in the past including at Meet-ups: [https://www.slideshare.net/MattBaldwin3/containerized-storage-for-containers-why-what-and-how-openebs-works](https://www.slideshare.net/MattBaldwin3/containerized-storage-for-containers-why-what-and-how-openebs-works)\n\n![](/content/images/2020/01/0_IqrlTxSpFwh5l-qu_.png) \\***\\*Performant:\\*\\***\n\n- This being a storage blog, it is worth reiterating the point that shared storage is inherently less performant these days than direct attached or DAS. That is a fairly new reality. It used to be that DAS was really slow disk and the way to get IOPS was to stripe across a bunch of faster disks. That was a primary driver for shared storage. Imagine that — at one time CEPH would have been faster than the underlying hardware! How times have changed.\n- Our CTO, Jeffry Molanus does a good job walking through how the landscape of performance has changed why this and other changes now favor what we call “container attached storage”:\n- [https://blog.openebs.io/not-yet-another-distributed-storage-system-57ee9220c409](https://blog.openebs.io/not-yet-another-distributed-storage-system-57ee9220c409)\n\n**Natively cross cloud — with the help of metadata and routing services:**\n\n- What is perhaps least well appreciated about the potential of treating storage as a service delivered via microservices is that, correctly engineered, this means that data itself can be served as a service in the background across underlying clouds.\n- The first prerequisite is that the controller itself runs in a container or set of containers.\n- The second prerequisite is that the controller performs its magic in the user space so that the container does not need to be a special build and so that the system can perform.\n- Third, there needs to be the management of metadata to see where the data is versus the workloads. Kubernetes can help here as it expands however in addition a solution such as MayaOnline.io — as it matures — is needed. This service acts as an air traffic controller, helping the data to get to where it is needed. Such a service can also become more intelligent over time, for example suggesting improvements to Kubernetes storage policies based on success in running similar workloads.\n\n# **TL;DR:**\n\nSo, in short, this time perhaps it really **is** different.\n\nThis time we “won’t get fooled again” (gratuitous old guy music reference :)).\n\nThis time we **will** address the sources of lock-in not just at the controller plane via Kubernetes but also at the data layer. And in so doing we will avoid ending the the cycle of innovation prematurely. Perhaps it goes without saying — only an open source solution like OpenEBS that is widely accepted and easy to fork if needed can help free us from the risk of cloud lock-in without adding yet another source of lock-in.\n\nAnd we can address lock-in while respecting and extending the patterns we know are working including: every team controlling their infrastructure themselves, the elimination of single points of failure (aka “storage blast radius”), and allowing Kubernetes to control more and more of the environment, leaving the developers to focus on capabilities that add value to their end users.\n\nIn short, at MayaData we believe we and others are building the foundation for a much longer cycle of software-centric innovation thanks to proactively eliminating sources of lock-in.\n\nPlease help this reality come true by providing us feedback on [OpenEBS](http://www.openebs.io/) and [MayaData](http://www.mayadata.io/) or see us on the Kubernetes storage SIG where we are trying to be helpful as well.\n","slug":"in-2018-it-dreams-deferred-finally-achieved"},{"id":34,"title":"Austin KubeCon — Persistent Storage Round-up and Looking beyond!","author":"Kiran Mova","author_info":"Contributor and Maintainer OpenEBS projects. Chief Architect MayaData. Kiran leads overall architecture & is responsible for architecting, solution design & customer adoption of OpenEBS.","date":"08-01-2018","tags":["Kubecon","Kubernetes","Persistence","Storage-Containers","Updates"],"content":"\nTL;DR\n\nThis rather has become a long post as I drafted it and incorporated feedback from community members. So, in short:\n\n- 2017 saw Kubernetes being crowned as the de-facto container orchestration engine. And from the storage perspective, containerized storage makes its presence felt.\n- 2018 — The reign of Kubernetes continues. Containerized Storage gains momentum with renewed focus on manageability of persistence workloads\n\n—\n\nKubernetes Clusters are up and running at the [push of a button](https://twitter.com/muratkarslioglu/status/941399154714066944) or even better by [talking to your favorite bot](https://www.youtube.com/watch?v=07jq-5VbBVQ).\n![](https://cdn-images-1.medium.com/max/800/1*oz5esyJvsb5zBIaoyDKUeQ.png)source: Containerized Storage for Containers — session at Kubernetes Meetup [https://t.co/tdQaOue5w8](https://t.co/tdQaOue5w8)\nBut just about a year ago when we started envisioning OpenEBS — Containerized Storage for Containers — to be orchestrated by Kubernetes, setting up a cluster took a good three days. Phenomenal progress by the Kubernetes Community in 2017 — from Kubernetes — the Hard-Way to making it Child’s play!\n\nIf you were at KubeCon, you would have definitely been caught up in or at least glimpsed the Euphoria around Kubernetes. Kubernetes, almost feels like Noah’s Ark right now — you are either in or wait to perish. A little exaggerated, I know, but only a little.\n\n_Every Technology and Cloud Service Provider are now providing or planning to provide a container service using Kubernetes and almost every infrastructure provider is looking at putting themselves on the map of Kubernetes._\n![](https://cdn-images-1.medium.com/max/800/1*YJIF6xBEPL1WpVgOK4VV0Q.png)[https://raw.githubusercontent.com/cncf/landscape/master/landscape/CloudNativeLandscape_latest.png](https://raw.githubusercontent.com/cncf/landscape/master/landscape/CloudNativeLandscape_latest.png)\nAnd why not!\n\nKubernetes has reached the level of maturity that can be used with ease in controlled environments and at the same time, has gained tremendous strength from a community that is not afraid to re-engineer or re-architect the core components. The popularity of Kubernetes is enabling many meta-kubernetes projects like — kubespray, stackpointcloud, kubeless, heptio ksonnet, heptio ark,etc. And with these new projects and possibilities, many _Kubernetes — blue ocean — companies are on the rise!_\n\n—\n\nI am very bullish that Kubernetes is that magical ingredient that will renew the focus on HumanOps!\n\nOne inevitable aspect of being an infrastructure operations admin is to be prepared for smooth operations, scaling, maintaining and recovering from faults and disasters — which usually tend to put a lot of unwarranted pressure on the admins when dealing with their own management (business impact) and the vendors whose technology they used to build a “black-box” infrastructures. A “black-box” infrastructure that doesn’t comply to what they were told and assumed would do — and involves talking to people building those black-boxes often crossing company borders, leading into non-technical calls about blaming who is at fault. Such stressful conditions also exist within an organizations where there is crunch for resources.\n\nKubernetes and the meta-kubernetes projects are helping administrators build — what I call “white-box” infrastructures. Often professed and hardly-prevailed aspect of Infrastructure is the [_HumanOps _](https://blog.serverdensity.com/humanops/)_— “_ technology affects the well being of humans just as humans affect the reliable operation of technology*”* — which can be achieved by building “white-box” infrastructures that are easy to operate and reduce the dependency on specialists that tend to be over-worked in an organization. _The “white-box” infrastructures are built with API-driven Open Source Micro-Services._\n\nThe key to the widespread adoption of Kubernetes in such a short time is the inclusive nature of it, which was well captured by this slide from the KubeCon:\n![](https://cdn-images-1.medium.com/max/800/1*IXods_RnXRco2z7UcngePw.png)[https://schd.ws/hosted*files/kccncna17/ac/KubeCon_2017*-\\_Kernels_and_Distros.pdf](https://schd.ws/hosted_files/kccncna17/ac/KubeCon_2017_-_Kernels_and_Distros.pdf)\n\n### **_Kubernetes is more than an orchestration engine → It is the new kernel for building clustered infrastructures._**\n\nI consider this shift towards making Kubernetes a Kernel that can be extended by custom solutions that can be downloaded and installed as a true enabler for driving innovation — which is inline with the Psyche of keeping “Community First and Company Next!”.\n\n—\n\nThis past year, saw the rise in user awareness for securing Containers. Different teams started tackling this issue from different perspectives — from providing secure container runtime like Kata Containers to using different types of Service Meshes to better access control and more.\n\nService Mesh was definitely a buzzword in 2017! The options — linkerd, envoy, istio and conduit — all of which are (or will be) accepted into CNCF sooner or later, provide a glimpse of interesting trend. For instance, [conduit ](https://buoyant.io/2017/12/05/introducing-conduit/)is from the same team that built Linkerd. Conduit provides similar capabilities like Linkerd for managing the communication between micro-services, but seems better suited for Kubernetes environment that can run across clouds and with low resource constraints.\n\nLike Service Mesh, the other infrastructure components — logging, monitoring, tracing, and networking are all being containerized (re-engineered) to work well with Kubernetes primitives (resources, pods, policies, federations, labels, taints, tolerations, affinity and anti-affinity, CR, CRDs, Custom Controllers, etc.)\n\n### **_Kubernetes has become a powerful set of nuts and bolts, that is changing the way people should think about infrastructures and how systems are built._**\n\n—\n\nStorage is no different. How data is stored and managed is also being transformed by the possibilities afforded by Kubernetes. Like Service Mesh of initial days, a lot of incumbent storage vendors are providing a patched (which some view as cloud washed or container plugged) solutions that will result in operations and developers spending endless hours firefighting to make them work with cloud native environments.\n\nThe key for any infrastructure component to be called container native will be characterized by being hardware agnostic and usable at scale! The past few months, there is an active workgroup team grappling with defining — [_Cloud Native Storage (WIP White Paper by CNCF Storage Workgroup)_](https://docs.google.com/document/d/1cJLgOAIWbi-Ya27BY7mjH61yoO3oWcO5tOZYteaDVgI/edit#heading=h.ik4inq9mv6b4)\n\nWhile deliberations are ongoing about what Cloud Native Storage is, which I think will finally be about users adoption, the talks at KubeCon suggest the community sees three distinct storage options for Kubernetes:\n\n- Persistence Volumes from External Storage Providers\n- Local/Ephemeral Storage for Containers\n- Containerized Storage for Containers\n\n—\n\n**Persistence Storage from External Storage Providers**\n\nMost of the cloud providers and incumbent storage vendors want the users to opt for this option where storage is connected via in-tree or out-of-tree dynamic volume provisioners. Many vendors are coming together in helping shape the CSI [(Container Storage Interface)](https://github.com/container-storage-interface/spec), and the initial implementation are slated to get into beta stage in early 2018. There are constant improvements — or strides — being made in storage workflow automation via controllers and kubectl — dynamically provisioning volumes, resizing, and snapshots.\n\nI spoke to a number of storage users at KubeCon, including the team at GitHub who are at the forefront of putting Kubernetes in production. The users are still very wary with the state of storage w.r.t using the PVs to connected storage and the amount of work involved in rewriting their operational scripts and playbooks.\n\nAnother issue I heard users talk about that puts them off NAS or SAN — and this was a little surprising as I’ve spent years building a unified storage system that in some environments is really fundamental to the architectures of private clouds and hosting environments — is that they think shared underlying storage does not fit a microservices architecture. Of course if you read the 12 Factor definition it talks about storage if at all as an attached resource. However — it also is clear from 12 Factor approaches that _dev should be the same as possible as production and that the same people should be doing coding and deploys._ That’s just not the world of external arrays with special teams running storage and different arrays for dev, test, staging and production.\n\nIt is also worth noting and taking time to understand that these options of connecting to network storage have been around for more than couple of years, and the fact that Stateful workloads on Kubernetes aren’t yet as prevalent says something about user acceptance of the approach! _Users are waiting for better options to be made available — like the support for local storage or something else — but not NAS!_\n\nLearning from the HBO team that was streaming GoT using Kubernetes, it is interesting to see a solution like Rook being used on top of EBS, while EBS is provided as PVs themselves.\n![](https://cdn-images-1.medium.com/max/800/1*Zl5PPYzJpDZoXrK7DCL_0w.png)[https://www.youtube.com/watch?v=7skInj_vqN0](https://www.youtube.com/watch?v=7skInj_vqN0)\nRook also presented a pretty interesting study against using PVs from external storage to Pods in their talk [here](https://schd.ws/hosted_files/kccncna17/b3/Cloud%20storage-2.pdf). This is inline with what the teams at [PortWorx](https://portworx.com/ebs-stuck-attaching-state-docker-containers/), [StorageOS ](https://schd.ws/hosted_files/kccncna17/ca/2017-12-8-persistent-storage.pdf)and OpenEBS have been advocating as well.\n\n- Make static assignments of disks (physical or virtual) to nodes and use them as local storage — avoid detaching/attaching disks from nodes\n- As long as the applications can take care of replication and sustain longer downtime for nodes and cluster rebuilding times — use local PVs with the storage provisioned in the previous steps.\n- For workloads that don’t inherently support replication, snapshots, etc. use a containerized storage option.\n\n_I am a firm believer in CSI and what it was set to achieve and has already accomplished— Open Standard for interfacing with Storage. Something which SNIA should have done and couldn’t do in past two decades of my experience. OpenSDS seems to be an effort in that direction by SNIA, but is being received with the same cold response from vendors and in turn the community. FWIW, REX-Ray is also playing in the same space._\n\nAt the moment, the focus for CSI is on (simplifying a bit) provisioning and de-provisioning volume, but albeit a good start. But is it enough for the users to start using it? There was an interesting observation made in the F2F storage workgroup meeting at KubeCon that CSI discussions are mostly driven by vendors. Where are the users? Can we say that vendors represent the users, because they interact with their users?\n\nComing from a operational background, for me to consider using CSI to connect with external storage systems, CSI requires to evolve and include API for Day 2+ Operational Usecases that involve — ease of debugging, snapshots, backups, migration and most importantly, a unified monitoring system of the Kubernetes Clusters and the Storage Systems.\n\nDon;t get me wrong. We need storage, lots and lots of it and it will be served from external storage systems — cloud (EBS, GPD, etc., ) or on-premise SAN/NAS products. But these external storage systems weren’t designed to be used for micro-services environment but rather to provide volumes to Nodes (physical or virtual) that are long running and are not subject to rapid connects, disconnects and migrations.\n\n_I believe in the long run we will be using CSI with these external storage for what they were designed for — mainly to provision storage to the nodes rather than Pods._\n\n—\n\n**Local/Ephemeral Storage for containers (aka Direct Attached Storage — DAS)**\n\nKubernetes keeps improving the capabilities for managing the local/ephemeral storage. The recent advancements include:\n\n- Support for attaching [block devices](https://schd.ws/hosted_files/kccncna17/8e/Mitsuhiro_Tanino_Block_Volume_KC_CNC_NA17.pdf) to pods\n- Support for enforcing policies or [resource limits for ephemeral storage](https://schd.ws/hosted_files/kccncna17/3e/Kubecon_localstorage.pdf)\n- Enhance the UX for using [local storage for PVs](https://schd.ws/hosted_files/kccncna17/3c/2017%20Kubecon%20Storage%20-%20FINAL.pdf) — dynamic provisioning, hook into the scheduler for pods requiring local storage PVs etc.,\n\n_When using local storage for PVs, the applications using these PVs need to also own up some of the features like — data consistency, replication, snapshots, etc., that are typically taken care of by the storage controllers._\n\n_One of the ongoing issue with using the local storage in clouds are the quirks of disconnecting and connecting the disks to different instances. The local storage is really meant for using storage that is tied to the node — either physically inserted or hardwired to a VM instance._\n\n—\n\n**Containerized Storage for Containers (aka Container Attached Storage — CAS)**\n\nThe appeal for fully containerized storage for containers is in the possibilities that it opens up to the DevOps administrators who are interested in building on-demand programmable infrastructures, which include:\n\n- storage can be observed down to the bit using the same set of tools they use to monitor their compute and network.\n- storage can also be secured using the same tools used to secure application pods\n- storage can be made policy driven similar to networks\n- storage can be programmed and versioned — made an integral part of the work flows for developers and operations administrators\n- storage can also use federation features for cloud migration similar to application pods.\n\n_StorageOS presented at KubeCon on what we call Container Attached Storage — and on how to select which storage approach for which workload and environment. It was a good talk — slides are here: _[talk](https://schd.ws/hosted_files/kccncna17/ca/2017-12-8-persistent-storage.pdf)\n\n_Kubernetes can provide an unified infrastructure layer to the applications by pooling together nodes with compute, network, and \\***\\*storage as well\\*\\***._\n\nKubeCon showcased a demo of launching [glusterfs in containers](https://schd.ws/hosted_files/kccncna17/7b/KubeRunningYourStorage1208.pdf). While this is feasible, it might put some hard requirements on the amount of RAM and CPU required for running the software optimized for running in the nodes in containers.\n\nTo be container native storage, the storage software needs to be broken down into micro-services, just like how Kubernetes runs using micro-services. There has to be greater flexibility provided to the developers and operations to run seamlessly on their choice of hardware!\n\nOpenEBS does just that! OpenEBS provides all the enterprise grade storage features by its open-source containers that can run anywhere. _No kernel dependencies and vendor lock-in._ A typical data path using the OpenEBS Containers is as follows:\n![](https://cdn-images-1.medium.com/max/800/1*Ifsa-k-q4EnO7Fpg7E6jLA.png)[https://github.com/openebs/openebs/blob/master/contribute/design/OpenEBS%20Architecture%20and%20Design.pdf](https://github.com/openebs/openebs/blob/master/contribute/design/OpenEBS%20Architecture%20and%20Design.pdf)\nOpenEBS can consume any storage connected to the node and provide enterprise grade storage features (like snapshots, replication, data-consistency, cross-cloud migration, etc.) to Stateful workloads.\n\n2017 saw a steep rise in the community for building OpenEBS with users evaluating it for different types of storage workloads from Cassandra, Minio to MySQL and some users also rolling out services to their customers using Kubernetes and OpenEBS. _I am looking forward to more application work-flow focused automation of Stateful workloads using OpenEBS in 2018._\n\n—\n\nManaging Storage in an enterprise environment — whether it is cloud or on-premise has to be as seamless as interacting with your favorite bot! I know it is a bit far fetched, but it is definitely going to happen in 2018 with companies like MayaData leading from the front!\n\n2017 saw some major improvements to storage in Kubernetes, but there is a lot more to look forward to in 2018!\n\n- CSI spec will mature to encompass all the storage API and will be adopted by a large percentage of storage vendors.\n- Improved debuggability/observability of PV — Metrics and Alerts etc.\n- Make PVs accessible via namespaces and RBAC and extend the Policies to involve HumanOps!\n- Further improvements to resource constraints from the IOPS perspective\n- Support for host-supported file system types to be used on top of local storage\n\n_Programmable and Predictable Infrastructures are what the developers need while the administrators are looking for building infrastructures that can be easily versioned, built, and deployed anywhere — where the economics makes sense._\n\n—\n\nI take tremendous pride in having been associated with MayaData team that is at the forefront of making Storage Operations fade away by extending Kubernetes with containerized storage for containers.\n\nYour participation will shape and accelerate the movement of Stateful Workloads on Kubernetes. Do join us on Slack on either [Kubernetes sig-storage](http://slack.k8s.io/) or [OpenEBS users](http://slack.openebs.io/) or join the [CNCF storage events](https://calendar.google.com/calendar/embed?src=linuxfoundation.org_o5avjlvt2cae9bq7a95emc4740%40group.calendar.google.com)!\n\nLooking forward to an exciting 2018 for the Stateful Workloads on Kubernetes!\n","slug":"austin-kubecon-persistent-storage-roundup-and-looking-beyond"},{"id":35,"title":"Install OpenEBS using StackPointCloud Trusted Charts?","author":"Murat Karslioglu","author_info":"VP @OpenEBS & @MayaData_Inc. Lives to innovate! Opinions my own!","date":"07-01-2018","tags":["Digital-Ocean","Helm","Kubernetes","Solutions","Stackpointcloud"],"content":"\n#### What is StackPointCloud Trusted Charts?\n\n[StackPointCloud](https://stackpoint.io/) (SPC) introduced a concept of Trusted Charts, a list of validated [Helm](https://helm.sh/) Charts provided by its partners to quickly spin up a solution in a [Kubernetes](https://kubernetes.io/) cluster. Helm Charts helps you define, install, and upgrade even the most complex Kubernetes application.\n\nPreviously, I wrote about few different ways of getting OpenEBS up and running on different cloud vendors. Using Helm Chart is one of the available options to deploy OpenEBS. OpenEBS Helm Charts were available since v.5.0 both on [Github](https://github.com/openebs/openebs/tree/master/k8s/charts/openebs) and as a [packaged chart](https://openebs.github.io/charts/). Recently SPC included OpenEBS into their Trusted Charts repo and made it one-click easy for its customers.\n\nSPC Trusted Charts currently offer 23 solutions including databases, CI/CD, monitoring, storage and ingress solutions. Here is the list of Trusted Charts:\n\n### CI/CD\n\n- [Jenkins](https://jenkins-ci.org/)\n- [Gitlab Runner](https://docs.gitlab.com/runner/)\n- [Spinnaker](https://www.spinnaker.io/)\n\n### Databases\n\n- [CockroachDB](https://www.cockroachlabs.com/)\n- [Crunchy PostgreSQL Operator](https://github.com/CrunchyData/postgres-operator)\n- [Patroni](https://github.com/turbonomic/kubeturbo)\n- [Redis](https://redis.io)\n- [RethinkDB](https://www.rethinkdb.com/)\n- [MongoDB Replica Set](https://docs.mongodb.com/manual/replication/)\n\n### Ingress/Proxy/Load Balancer\n\n- [Nginx Ingress](https://github.com/kubernetes/ingress-nginx)\n- [Traefik](https://traefik.io/)\n\n### Messaging\n\n- [Kafka](https://kafka.apache.org/)\n- [Rabbitmq](https://www.rabbitmq.com)\n\n### Storage\n\n- [OpenEBS](https://openebs.io/)\n- [Minio](https://www.minio.io/)\n- [Etcd-operator](https://github.com/kubernetes/charts/tree/master/stable/etcd-operator)\n\n### Others\n\n- [Grafana](https://grafana.com/)\n- [Keel](https://keel.sh/)\n- [Kube-lego](https://github.com/jetstack/kube-lego)\n- [Kubeturbo](https://github.com/turbonomic/kubeturbo)\n- [Memcached](https://memcached.org/)\n- [Tensorflow Inception](https://github.com/tensorflow/models/tree/master/research/inception)\n\nI’ll go through the quick steps of deploying OpenEBS.\n\n### Prerequisites\n\nMinimum requirements for deploying your Kubernetes clusters on StackPointCloud:\n\n### Cloud Provider Account\n\n- [Amazon Web Services (AWS)](https://aws.amazon.com/) or\n- [DigitalOcean](https://www.digitalocean.com)\n\n### Deploy a New Kubernetes Cluster\n\nFirst, go to [stackpoint.io](https://stackpoint.io/) and click on **Launch a Cluster** button to start your free trial.\n![](https://cdn-images-1.medium.com/max/800/0*0cB3ttYmslFZgH1h.png)\nThen choose your cloud provider. In this example, I will use **Digital Ocean**.\n![](https://cdn-images-1.medium.com/max/800/0*21G24JgfuqlR6snZ.png)\n\n### Configure Access to Digital Ocean\n\nOn the next screen, we need to configure our provider. You need to provide Digital Ocean API Token and optionally your SSH Key.\n![](https://cdn-images-1.medium.com/max/800/0*wDcMg-_HTjIOFvgb.png)\nClick on **Add API Token **button.\n![](https://cdn-images-1.medium.com/max/800/0*53wGtQ7eUt18u6pS.png)\nAfter you add your credentials, click on **Submit**.\n\n### Configure K8s Cluster\n\nOn “Configure your cluster” page click the edit button on **Distribution** and choose **Ubuntu 16.04 LTS**.\n![](https://cdn-images-1.medium.com/max/800/0*NvtnryAA8GNi-fyN.png)\nChange the **Cluster Name** something meaningful like **OpenEBS Demo**.\n![](https://cdn-images-1.medium.com/max/800/0*LTa6zBooJdTsyqss.png)\nLeave everything else as default and click on **Submit**.\n\nIn about 10–15 minutes you will get your new cluster deployed.\n\n### Adding OpenEBS to Your Kubernetes Cluster\n\nFirst, make sure your cluster and all nodes are up.\n\nOn the **Control Plane** tab click on your recently created cluster.\n![](https://cdn-images-1.medium.com/max/800/0*RHQ9LbyxydjHkJSk.png)\nOnce the Kubernetes cluster is up on Digital Ocean with functional Helm, scroll down to the **Solutions** tab and click on **Add Solution** button.\n![](https://cdn-images-1.medium.com/max/800/0*sH0lzv23vHonV5Zk.png)\nClick on **Add Solutions**, and select **Trusted Charts**.\n![](https://cdn-images-1.medium.com/max/800/0*V6iP5PzNAzFk4sME.png)\nFrom the list above select **OpenEBS**.\n![](https://cdn-images-1.medium.com/max/800/0*CJkPrkJCS9Fp_GXu.png)\n**Release Name** is randomly generated every time. If you want to use OpenEBS example workloads provided in OpenEBS repos without any modification then use `default`as **NameSpace**. Otherwise, you need to modify the namespace for workloads you deploy and make sure to use the same name.\n\nClick on **Install** to deploy OpenEBS on your cluster.\n\n**Note:** Default settings assume that RBAC is enabled. If you disabled RBAC while you are configuring your provider previously then set `rbacEnable: false` otherwise use default values.\n\nState field should be green after OpenEBS is successfully added.\n![](https://cdn-images-1.medium.com/max/800/0*HzCZp3Z5LbT3Hsrh.png)\nNow your cluster is ready; you can run your workloads on `openebs-standard` and other predefined storage classes.\n\nTo confirm, click on **Kubernetes Dashboard. **This will bring up your Kubernetes Dashboard UI in a new window. You will find all predefined OpenEBS **Storage Classes **here under **Storage Classes **section.\n![](https://cdn-images-1.medium.com/max/800/0*mNU-nhwvNy9UB0W5.png)\nNow you are ready to deploy your stateful workloads.\n\nTake a look at my previous articles on step-by-step instructions for deploying few popular stateful workloads such as [Cassandra](http://containerized.me/how-to-deploy-a-cassandra-cluster-ring-on-kubernetes-openebs/), [Jenkins](http://containerized.me/how-to-deploy-jenkins-on-kubernetes-openebs/), and [Postgres](http://containerized.me/how-to-deploy-a-postgresql-cluster-on-kubernetes-openebs/) on OpenEBS persistent storage.\n\n---\n\n_Originally published at _[_Containerized Me_](http://containerized.me/install-openebs-using-stackpointcloud-trusted-charts/)_._\n","slug":"install-openebs-using-stackpointcloud-trusted-charts"},{"id":36,"title":"How we built multi-tenant ChatOps.. for MayaOnline!","author":"Satyam Zode","author_info":"Go Developer @openebs | Open Source Contributor | Avid Learner","date":"31-12-2017","tags":["Kubernetes","Slack","Chatbots","ChatOps","Chatbot-Design"],"content":"\n## What is Maya ChatOps?\n\nMaya-ChatOps is one of the core areas of [MayaOnline](https://mayaonline.io/), covering the storage operational support of kubernetes clusters. DevOps developers and admins get the alerts and analytics of their OpenEBS volumes deployed across multi-cloud kubernetes clusters right into their [slack](https://slack.com/) channels. Our vision of ChatOps extend beyond just simply providing alerts and providing a way to query any configuration and status from slack. It goes all the way to interact with DevOps developers and admins to manage the yaml config files in their CI/CD system.\n\n## What is MuleBot ?\n\n![](/content/images/2020/01/mule-bot.png)Mule Bot\nMuleBot is the name of the bot or slack application from Maya. MuleBot is a distributed slack application. MuleBot responds to user’s queries about configuration and status of the OpenEBS volumes. Sometimes, MuleBot tries to surprise you with smart alerts prior to a real situation happens.\n\n## How to use Maya ChatOps?\n\nYou can start using ChatOps by adding Slack integration in MayaOnline. The MuleBot slack application will be installed in your workspace. Subsequent steps involve configuration a single or multiple clusters to the desired slack channel. This mapping is maintained in the MO in the form of a “slack-card”.\n\nYou can add as many slack cards as you want for your clusters. Through this channel you will be able to interact with clusters imported in the MayaOnline.\n\n## What are we using underneath for powering our ChatOps?\n\nWell, this is why I am writing this blog, to tell you the various choices we had and why we ended up with a particular choice. Some of the design goals we kept while choosing the bot framework are:\n\n- Users of MayaOnline will be in thousands to begin with, so, the bot framework has to be multi-tenant\n- The bot has to be a micro service and suitable to run seamlessly on kubernetes\n- The bot framework has to have the NLP AI support for us to get that capability out to the users in the near future\n\nSo, we looked at [Hubot](https://hubot.github.com/), [StackStorm](https://github.com/StackStorm)/errBot and [BotMan](https://botman.io/)\n\nEach one of them had their benefits but none of them were multi-tenant. Then we looked at which is easiest to add the multi-tenant support to, BotMan came surprisingly easy to add this support to. BotMan is thin, and is written as a stateless application. The preliminary approach involved passing the user configuration in environment variables. All it needed was a thin shim to get user-config details dynamically and we had achieved multi-tenancy ! It is that simple.\n\nWe kept a combination of slack **\\*\\***team_id**\\*\\***, **\\*\\***channel-id**\\*\\*** as the key of the mulebot to manage the link between the slack user config and MayaOnline user config.\n![](/content/images/2020/01/bot-architecture.jpeg)Chat Ops Architecture\nWith the above design Maya ChatOps allows users to configure different slack channels for different kuberenetes clusters at MayaOline.\n\nNext steps:\n\n- In the coming weeks, we will try to post some example scenarios suggesting how smart our MuleBot can be 😄\n- We plan to extend the BotMan framework to provide Maya ChatOps API. A DevOps developer/admin can use these APIs to integrate better into their CI/CD\n- Currently it is integrated with Slack. PagerDuty is on our horizon.\n","slug":"how-we-built-multitenant-chatops-for-mayaonline"}]
